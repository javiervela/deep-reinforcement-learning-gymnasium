{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OBCPdFloZEXO"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from stable_baselines3 import DQN, PPO\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecMonitor\n",
        "from stable_baselines3.common.callbacks import (\n",
        "    EvalCallback,\n",
        "    StopTrainingOnRewardThreshold,\n",
        "    BaseCallback,\n",
        ")\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the LunarLander-v3 environment\n",
        "env = gym.make(\n",
        "    \"LunarLander-v3\",\n",
        "    # continuous=False,\n",
        "    # gravity=-10.0,\n",
        "    # enable_wind=False,\n",
        "    # wind_power=15.0,\n",
        "    # turbulence_power=1.5,\n",
        "    render_mode=\"rgb_array\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
        "\n",
        "eval_callback = EvalCallback(\n",
        "    env,\n",
        "    best_model_save_path=\"../logs/exercise_2/ppo/\",\n",
        "    log_path=\"../logs/exercise_2/ppo/\",\n",
        "    eval_freq=5_000,\n",
        "    deterministic=True,\n",
        "    render=False,\n",
        "    n_eval_episodes=50,\n",
        "    callback_on_new_best=stop_callback,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU8nrDkrVCGw",
        "outputId": "e7875497-4d2d-4c7c-986c-d10d5316e8b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "# Create PPO model\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    # learning_rate=1e-3,\n",
        "    seed=42,\n",
        "    verbose=1,\n",
        "    tensorboard_log=\"../logs/exercise_2/ppo/ppo_tensorboard/\",\n",
        "    device=\"cpu\",\n",
        ")\n",
        "# model = PPO( # TODO fix\n",
        "#     \"CnnPolicy\",\n",
        "#     env,\n",
        "#     seed=42,\n",
        "#     verbose=1,\n",
        "#     tensorboard_log=\"../logs/exercise_2/ppo_tensorboard/\",\n",
        "#     device=\"cuda\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Jy6O6s1ZusN",
        "outputId": "7631a5ee-d701-4312-c497-4b6ad3363806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logging to ../logs/exercise_2/ppo_tensorboard/PPO_11\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 86.7     |\n",
            "|    ep_rew_mean     | -165     |\n",
            "| time/              |          |\n",
            "|    fps             | 3746     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 0        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 91.3        |\n",
            "|    ep_rew_mean          | -155        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 2179        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 1           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007234047 |\n",
            "|    clip_fraction        | 0.00601     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.000897    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 658         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.004      |\n",
            "|    value_loss           | 1.29e+03    |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/javier/.cache/pypoetry/virtualenvs/deep-reinforcement-learning-gymnasium-u3px5S1O-py3.13/lib/python3.13/site-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=5000, episode_reward=-874.88 +/- 518.98\n",
            "Episode length: 176.80 +/- 56.59\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 177         |\n",
            "|    mean_reward          | -875        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 5000        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009534828 |\n",
            "|    clip_fraction        | 0.0389      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.37       |\n",
            "|    explained_variance   | -0.0122     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 687         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00877    |\n",
            "|    value_loss           | 1.14e+03    |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 95.6     |\n",
            "|    ep_rew_mean     | -167     |\n",
            "| time/              |          |\n",
            "|    fps             | 1213     |\n",
            "|    iterations      | 3        |\n",
            "|    time_elapsed    | 5        |\n",
            "|    total_timesteps | 6144     |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 100         |\n",
            "|    ep_rew_mean          | -175        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1373        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 5           |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010823179 |\n",
            "|    clip_fraction        | 0.0571      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.34       |\n",
            "|    explained_variance   | -0.000238   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 445         |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0104     |\n",
            "|    value_loss           | 1.05e+03    |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=-929.24 +/- 625.57\n",
            "Episode length: 131.78 +/- 62.15\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 132        |\n",
            "|    mean_reward          | -929       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 10000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01100634 |\n",
            "|    clip_fraction        | 0.0622     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.3       |\n",
            "|    explained_variance   | -0.0275    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 637        |\n",
            "|    n_updates            | 40         |\n",
            "|    policy_gradient_loss | -0.00836   |\n",
            "|    value_loss           | 1.23e+03   |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 106      |\n",
            "|    ep_rew_mean     | -176     |\n",
            "| time/              |          |\n",
            "|    fps             | 1138     |\n",
            "|    iterations      | 5        |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 10240    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 111          |\n",
            "|    ep_rew_mean          | -181         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1203         |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 10           |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059280638 |\n",
            "|    clip_fraction        | 0.0511       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | -0.00075     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 375          |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    value_loss           | 659          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | -178         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1213         |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 11           |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049635577 |\n",
            "|    clip_fraction        | 0.00303      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | -0.00195     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 286          |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    value_loss           | 642          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=15000, episode_reward=-1007.18 +/- 542.51\n",
            "Episode length: 152.40 +/- 56.78\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 152          |\n",
            "|    mean_reward          | -1.01e+03    |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 15000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065367087 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.33        |\n",
            "|    explained_variance   | 0.0188       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 227          |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.00774     |\n",
            "|    value_loss           | 626          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 131      |\n",
            "|    ep_rew_mean     | -184     |\n",
            "| time/              |          |\n",
            "|    fps             | 1115     |\n",
            "|    iterations      | 8        |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 16384    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | -187         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1149         |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 16           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075123957 |\n",
            "|    clip_fraction        | 0.118        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.27        |\n",
            "|    explained_variance   | -0.278       |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 199          |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00942     |\n",
            "|    value_loss           | 511          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=-694.81 +/- 255.27\n",
            "Episode length: 256.22 +/- 91.09\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 256         |\n",
            "|    mean_reward          | -695        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015705496 |\n",
            "|    clip_fraction        | 0.166       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.27       |\n",
            "|    explained_variance   | -0.0225     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 175         |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0133     |\n",
            "|    value_loss           | 338         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 139      |\n",
            "|    ep_rew_mean     | -167     |\n",
            "| time/              |          |\n",
            "|    fps             | 942      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 21       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 145          |\n",
            "|    ep_rew_mean          | -144         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 984          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 22           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065907105 |\n",
            "|    clip_fraction        | 0.0407       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.26        |\n",
            "|    explained_variance   | -0.0191      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 209          |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00548     |\n",
            "|    value_loss           | 431          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 147          |\n",
            "|    ep_rew_mean          | -125         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 1013         |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 24           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008729469 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | -3.21e-05    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 84.5         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00164     |\n",
            "|    value_loss           | 216          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=-570.69 +/- 173.63\n",
            "Episode length: 323.98 +/- 93.47\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 324         |\n",
            "|    mean_reward          | -571        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 25000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015455628 |\n",
            "|    clip_fraction        | 0.0887      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | -0.000156   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 114         |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00582    |\n",
            "|    value_loss           | 276         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 153      |\n",
            "|    ep_rew_mean     | -128     |\n",
            "| time/              |          |\n",
            "|    fps             | 847      |\n",
            "|    iterations      | 13       |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 26624    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 163         |\n",
            "|    ep_rew_mean          | -112        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 883         |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008850474 |\n",
            "|    clip_fraction        | 0.08        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.14       |\n",
            "|    explained_variance   | -0.000709   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 240         |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.00698    |\n",
            "|    value_loss           | 476         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=-467.22 +/- 142.83\n",
            "Episode length: 268.00 +/- 95.75\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 268         |\n",
            "|    mean_reward          | -467        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014100263 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | -5.88e-05   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 80          |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00705    |\n",
            "|    value_loss           | 179         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 168      |\n",
            "|    ep_rew_mean     | -113     |\n",
            "| time/              |          |\n",
            "|    fps             | 796      |\n",
            "|    iterations      | 15       |\n",
            "|    time_elapsed    | 38       |\n",
            "|    total_timesteps | 30720    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 185         |\n",
            "|    ep_rew_mean          | -105        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 813         |\n",
            "|    iterations           | 16          |\n",
            "|    time_elapsed         | 40          |\n",
            "|    total_timesteps      | 32768       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008183889 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.2        |\n",
            "|    explained_variance   | 0.000308    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 136         |\n",
            "|    n_updates            | 150         |\n",
            "|    policy_gradient_loss | -0.0127     |\n",
            "|    value_loss           | 321         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 198          |\n",
            "|    ep_rew_mean          | -104         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 822          |\n",
            "|    iterations           | 17           |\n",
            "|    time_elapsed         | 42           |\n",
            "|    total_timesteps      | 34816        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053899107 |\n",
            "|    clip_fraction        | 0.00972      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.24        |\n",
            "|    explained_variance   | -0.00607     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 64.1         |\n",
            "|    n_updates            | 160          |\n",
            "|    policy_gradient_loss | -0.00462     |\n",
            "|    value_loss           | 173          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=35000, episode_reward=-451.29 +/- 160.81\n",
            "Episode length: 410.20 +/- 180.19\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 410         |\n",
            "|    mean_reward          | -451        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 35000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006124774 |\n",
            "|    clip_fraction        | 0.0192      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.18       |\n",
            "|    explained_variance   | 0.116       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 119         |\n",
            "|    n_updates            | 170         |\n",
            "|    policy_gradient_loss | -0.0047     |\n",
            "|    value_loss           | 225         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 212      |\n",
            "|    ep_rew_mean     | -95.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 682      |\n",
            "|    iterations      | 18       |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 36864    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 223         |\n",
            "|    ep_rew_mean          | -89         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 698         |\n",
            "|    iterations           | 19          |\n",
            "|    time_elapsed         | 55          |\n",
            "|    total_timesteps      | 38912       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008384881 |\n",
            "|    clip_fraction        | 0.0477      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.254       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 56          |\n",
            "|    n_updates            | 180         |\n",
            "|    policy_gradient_loss | -0.00853    |\n",
            "|    value_loss           | 145         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=-829.67 +/- 311.55\n",
            "Episode length: 503.32 +/- 140.13\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 503        |\n",
            "|    mean_reward          | -830       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 40000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01353586 |\n",
            "|    clip_fraction        | 0.0632     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.17      |\n",
            "|    explained_variance   | 0.159      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 92.3       |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.00669   |\n",
            "|    value_loss           | 224        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 228      |\n",
            "|    ep_rew_mean     | -91.8    |\n",
            "| time/              |          |\n",
            "|    fps             | 593      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 68       |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 248         |\n",
            "|    ep_rew_mean          | -80.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 606         |\n",
            "|    iterations           | 21          |\n",
            "|    time_elapsed         | 70          |\n",
            "|    total_timesteps      | 43008       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007450519 |\n",
            "|    clip_fraction        | 0.0458      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.13       |\n",
            "|    explained_variance   | 0.141       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 123         |\n",
            "|    n_updates            | 200         |\n",
            "|    policy_gradient_loss | -0.00811    |\n",
            "|    value_loss           | 370         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=45000, episode_reward=-649.17 +/- 273.39\n",
            "Episode length: 597.98 +/- 216.48\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 598         |\n",
            "|    mean_reward          | -649        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 45000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005095748 |\n",
            "|    clip_fraction        | 0.0154      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.21       |\n",
            "|    explained_variance   | 0.482       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 32.6        |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.00634    |\n",
            "|    value_loss           | 106         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 259      |\n",
            "|    ep_rew_mean     | -77.4    |\n",
            "| time/              |          |\n",
            "|    fps             | 505      |\n",
            "|    iterations      | 22       |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 45056    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 273         |\n",
            "|    ep_rew_mean          | -76.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 520         |\n",
            "|    iterations           | 23          |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 47104       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008291641 |\n",
            "|    clip_fraction        | 0.06        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.11       |\n",
            "|    explained_variance   | 0.25        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 96.9        |\n",
            "|    n_updates            | 220         |\n",
            "|    policy_gradient_loss | -0.00588    |\n",
            "|    value_loss           | 174         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 291         |\n",
            "|    ep_rew_mean          | -72.1       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 532         |\n",
            "|    iterations           | 24          |\n",
            "|    time_elapsed         | 92          |\n",
            "|    total_timesteps      | 49152       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007694074 |\n",
            "|    clip_fraction        | 0.0797      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.591       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 54.7        |\n",
            "|    n_updates            | 230         |\n",
            "|    policy_gradient_loss | -0.00645    |\n",
            "|    value_loss           | 107         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=-943.51 +/- 167.59\n",
            "Episode length: 826.54 +/- 155.87\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 827         |\n",
            "|    mean_reward          | -944        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009787859 |\n",
            "|    clip_fraction        | 0.0697      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.15       |\n",
            "|    explained_variance   | 0.801       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 18.6        |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.00716    |\n",
            "|    value_loss           | 48.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 308      |\n",
            "|    ep_rew_mean     | -68.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 422      |\n",
            "|    iterations      | 25       |\n",
            "|    time_elapsed    | 121      |\n",
            "|    total_timesteps | 51200    |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 320        |\n",
            "|    ep_rew_mean          | -70.1      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 432        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 123        |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00909424 |\n",
            "|    clip_fraction        | 0.071      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.16      |\n",
            "|    explained_variance   | 0.712      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 17.2       |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.00529   |\n",
            "|    value_loss           | 69.2       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=55000, episode_reward=-508.57 +/- 110.15\n",
            "Episode length: 546.72 +/- 192.91\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 547         |\n",
            "|    mean_reward          | -509        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 55000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008217016 |\n",
            "|    clip_fraction        | 0.0722      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.07       |\n",
            "|    explained_variance   | 0.298       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 49.8        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00671    |\n",
            "|    value_loss           | 129         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 335      |\n",
            "|    ep_rew_mean     | -71.1    |\n",
            "| time/              |          |\n",
            "|    fps             | 397      |\n",
            "|    iterations      | 27       |\n",
            "|    time_elapsed    | 139      |\n",
            "|    total_timesteps | 55296    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 359          |\n",
            "|    ep_rew_mean          | -68.4        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 405          |\n",
            "|    iterations           | 28           |\n",
            "|    time_elapsed         | 141          |\n",
            "|    total_timesteps      | 57344        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056254463 |\n",
            "|    clip_fraction        | 0.027        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.05        |\n",
            "|    explained_variance   | 0.354        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40           |\n",
            "|    n_updates            | 270          |\n",
            "|    policy_gradient_loss | -0.0062      |\n",
            "|    value_loss           | 162          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 377          |\n",
            "|    ep_rew_mean          | -64.9        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 416          |\n",
            "|    iterations           | 29           |\n",
            "|    time_elapsed         | 142          |\n",
            "|    total_timesteps      | 59392        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077127204 |\n",
            "|    clip_fraction        | 0.0679       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -1.13        |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.8         |\n",
            "|    n_updates            | 280          |\n",
            "|    policy_gradient_loss | -0.00622     |\n",
            "|    value_loss           | 34.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=-458.88 +/- 183.00\n",
            "Episode length: 761.12 +/- 217.94\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 761         |\n",
            "|    mean_reward          | -459        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 60000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009321265 |\n",
            "|    clip_fraction        | 0.0834      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.153       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 69.4        |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0043     |\n",
            "|    value_loss           | 89.4        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 392      |\n",
            "|    ep_rew_mean     | -64      |\n",
            "| time/              |          |\n",
            "|    fps             | 363      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 169      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 404         |\n",
            "|    ep_rew_mean          | -63.8       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 372         |\n",
            "|    iterations           | 31          |\n",
            "|    time_elapsed         | 170         |\n",
            "|    total_timesteps      | 63488       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008623638 |\n",
            "|    clip_fraction        | 0.0777      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.99       |\n",
            "|    explained_variance   | 0.238       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 83.7        |\n",
            "|    n_updates            | 300         |\n",
            "|    policy_gradient_loss | -0.00707    |\n",
            "|    value_loss           | 97.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=65000, episode_reward=-473.47 +/- 150.27\n",
            "Episode length: 829.32 +/- 194.14\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 829         |\n",
            "|    mean_reward          | -473        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 65000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008721069 |\n",
            "|    clip_fraction        | 0.0674      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.982      |\n",
            "|    explained_variance   | 0.576       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 19.9        |\n",
            "|    n_updates            | 310         |\n",
            "|    policy_gradient_loss | -0.00478    |\n",
            "|    value_loss           | 88.2        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 426      |\n",
            "|    ep_rew_mean     | -61.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 323      |\n",
            "|    iterations      | 32       |\n",
            "|    time_elapsed    | 202      |\n",
            "|    total_timesteps | 65536    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 443         |\n",
            "|    ep_rew_mean          | -60         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 330         |\n",
            "|    iterations           | 33          |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 67584       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012681849 |\n",
            "|    clip_fraction        | 0.124       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.04       |\n",
            "|    explained_variance   | 0.727       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 23.1        |\n",
            "|    n_updates            | 320         |\n",
            "|    policy_gradient_loss | -0.00981    |\n",
            "|    value_loss           | 57          |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 460          |\n",
            "|    ep_rew_mean          | -56.7        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 337          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 206          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050803777 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.92        |\n",
            "|    explained_variance   | 0.684        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.7         |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.00341     |\n",
            "|    value_loss           | 39.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=-353.28 +/- 58.47\n",
            "Episode length: 871.72 +/- 109.71\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 872         |\n",
            "|    mean_reward          | -353        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 70000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006542194 |\n",
            "|    clip_fraction        | 0.0859      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.905      |\n",
            "|    explained_variance   | 0.876       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.44        |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.00467    |\n",
            "|    value_loss           | 14.3        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 475      |\n",
            "|    ep_rew_mean     | -56.3    |\n",
            "| time/              |          |\n",
            "|    fps             | 299      |\n",
            "|    iterations      | 35       |\n",
            "|    time_elapsed    | 239      |\n",
            "|    total_timesteps | 71680    |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 492        |\n",
            "|    ep_rew_mean          | -51.9      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 305        |\n",
            "|    iterations           | 36         |\n",
            "|    time_elapsed         | 241        |\n",
            "|    total_timesteps      | 73728      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00636645 |\n",
            "|    clip_fraction        | 0.0357     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.999     |\n",
            "|    explained_variance   | 0.598      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 11         |\n",
            "|    n_updates            | 350        |\n",
            "|    policy_gradient_loss | -0.00428   |\n",
            "|    value_loss           | 23.5       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=75000, episode_reward=-259.39 +/- 36.98\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -259        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 75000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009148204 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.973      |\n",
            "|    explained_variance   | 0.778       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.3        |\n",
            "|    n_updates            | 360         |\n",
            "|    policy_gradient_loss | -0.00783    |\n",
            "|    value_loss           | 17.9        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 510      |\n",
            "|    ep_rew_mean     | -50.4    |\n",
            "| time/              |          |\n",
            "|    fps             | 267      |\n",
            "|    iterations      | 37       |\n",
            "|    time_elapsed    | 283      |\n",
            "|    total_timesteps | 75776    |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 532        |\n",
            "|    ep_rew_mean          | -48.2      |\n",
            "| time/                   |            |\n",
            "|    fps                  | 273        |\n",
            "|    iterations           | 38         |\n",
            "|    time_elapsed         | 284        |\n",
            "|    total_timesteps      | 77824      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00674979 |\n",
            "|    clip_fraction        | 0.0792     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1         |\n",
            "|    explained_variance   | 0.682      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.4        |\n",
            "|    n_updates            | 370        |\n",
            "|    policy_gradient_loss | -0.00615   |\n",
            "|    value_loss           | 12.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 548         |\n",
            "|    ep_rew_mean          | -45.6       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 278         |\n",
            "|    iterations           | 39          |\n",
            "|    time_elapsed         | 287         |\n",
            "|    total_timesteps      | 79872       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018550783 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.887      |\n",
            "|    explained_variance   | 0.27        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 49          |\n",
            "|    n_updates            | 380         |\n",
            "|    policy_gradient_loss | -0.00881    |\n",
            "|    value_loss           | 105         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=-76.22 +/- 32.49\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | -76.2       |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 80000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005796413 |\n",
            "|    clip_fraction        | 0.0494      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.794      |\n",
            "|    explained_variance   | 0.71        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.41        |\n",
            "|    n_updates            | 390         |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    value_loss           | 23.5        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 561      |\n",
            "|    ep_rew_mean     | -41.5    |\n",
            "| time/              |          |\n",
            "|    fps             | 249      |\n",
            "|    iterations      | 40       |\n",
            "|    time_elapsed    | 328      |\n",
            "|    total_timesteps | 81920    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 577         |\n",
            "|    ep_rew_mean          | -31.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 253         |\n",
            "|    iterations           | 41          |\n",
            "|    time_elapsed         | 330         |\n",
            "|    total_timesteps      | 83968       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006751436 |\n",
            "|    clip_fraction        | 0.0533      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.803      |\n",
            "|    explained_variance   | 0.754       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.21        |\n",
            "|    n_updates            | 400         |\n",
            "|    policy_gradient_loss | -0.00308    |\n",
            "|    value_loss           | 18.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=85000, episode_reward=44.31 +/- 85.13\n",
            "Episode length: 962.68 +/- 67.54\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 963        |\n",
            "|    mean_reward          | 44.3       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 85000      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01599484 |\n",
            "|    clip_fraction        | 0.0736     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.847     |\n",
            "|    explained_variance   | 0.177      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 78.7       |\n",
            "|    n_updates            | 410        |\n",
            "|    policy_gradient_loss | -0.0081    |\n",
            "|    value_loss           | 136        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 591      |\n",
            "|    ep_rew_mean     | -19      |\n",
            "| time/              |          |\n",
            "|    fps             | 231      |\n",
            "|    iterations      | 42       |\n",
            "|    time_elapsed    | 371      |\n",
            "|    total_timesteps | 86016    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 604         |\n",
            "|    ep_rew_mean          | -8.16       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 235         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 373         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009111978 |\n",
            "|    clip_fraction        | 0.1         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.959      |\n",
            "|    explained_variance   | 0.0537      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 74.8        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.00659    |\n",
            "|    value_loss           | 169         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=120.24 +/- 95.50\n",
            "Episode length: 783.98 +/- 128.83\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 784         |\n",
            "|    mean_reward          | 120         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 90000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008599669 |\n",
            "|    clip_fraction        | 0.0297      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.819      |\n",
            "|    explained_variance   | 0.166       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 39.3        |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.00406    |\n",
            "|    value_loss           | 139         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 613      |\n",
            "|    ep_rew_mean     | 5.76     |\n",
            "| time/              |          |\n",
            "|    fps             | 224      |\n",
            "|    iterations      | 44       |\n",
            "|    time_elapsed    | 401      |\n",
            "|    total_timesteps | 90112    |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 619          |\n",
            "|    ep_rew_mean          | 18.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 228          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 402          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034808223 |\n",
            "|    clip_fraction        | 0.012        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.785       |\n",
            "|    explained_variance   | 0.233        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 52.8         |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000787    |\n",
            "|    value_loss           | 197          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 630          |\n",
            "|    ep_rew_mean          | 28.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 46           |\n",
            "|    time_elapsed         | 404          |\n",
            "|    total_timesteps      | 94208        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038533187 |\n",
            "|    clip_fraction        | 0.0236       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.861       |\n",
            "|    explained_variance   | 0.408        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 48.7         |\n",
            "|    n_updates            | 450          |\n",
            "|    policy_gradient_loss | -0.0024      |\n",
            "|    value_loss           | 126          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=95000, episode_reward=79.89 +/- 125.69\n",
            "Episode length: 658.84 +/- 105.82\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 659          |\n",
            "|    mean_reward          | 79.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 95000        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0073118047 |\n",
            "|    clip_fraction        | 0.0721       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.827       |\n",
            "|    explained_variance   | 0.524        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 45.9         |\n",
            "|    n_updates            | 460          |\n",
            "|    policy_gradient_loss | -0.00553     |\n",
            "|    value_loss           | 71.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 627      |\n",
            "|    ep_rew_mean     | 37.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 226      |\n",
            "|    iterations      | 47       |\n",
            "|    time_elapsed    | 425      |\n",
            "|    total_timesteps | 96256    |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 619       |\n",
            "|    ep_rew_mean          | 48.8      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 230       |\n",
            "|    iterations           | 48        |\n",
            "|    time_elapsed         | 426       |\n",
            "|    total_timesteps      | 98304     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0079598 |\n",
            "|    clip_fraction        | 0.0488    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.883    |\n",
            "|    explained_variance   | 0.115     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 91.8      |\n",
            "|    n_updates            | 470       |\n",
            "|    policy_gradient_loss | -0.00594  |\n",
            "|    value_loss           | 230       |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=81.36 +/- 108.94\n",
            "Episode length: 674.16 +/- 143.87\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 674         |\n",
            "|    mean_reward          | 81.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 100000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005420482 |\n",
            "|    clip_fraction        | 0.023       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.881      |\n",
            "|    explained_variance   | 0.093       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 140         |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.00626    |\n",
            "|    value_loss           | 310         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 634      |\n",
            "|    ep_rew_mean     | 52.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 223      |\n",
            "|    iterations      | 49       |\n",
            "|    time_elapsed    | 448      |\n",
            "|    total_timesteps | 100352   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 636         |\n",
            "|    ep_rew_mean          | 57.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 227         |\n",
            "|    iterations           | 50          |\n",
            "|    time_elapsed         | 449         |\n",
            "|    total_timesteps      | 102400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011313997 |\n",
            "|    clip_fraction        | 0.143       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.803      |\n",
            "|    explained_variance   | 0.301       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 79.9        |\n",
            "|    n_updates            | 490         |\n",
            "|    policy_gradient_loss | -0.00898    |\n",
            "|    value_loss           | 109         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 650          |\n",
            "|    ep_rew_mean          | 68.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 51           |\n",
            "|    time_elapsed         | 450          |\n",
            "|    total_timesteps      | 104448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048805336 |\n",
            "|    clip_fraction        | 0.0196       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.897       |\n",
            "|    explained_variance   | 0.159        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 96.4         |\n",
            "|    n_updates            | 500          |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    value_loss           | 200          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=105000, episode_reward=53.98 +/- 116.50\n",
            "Episode length: 847.40 +/- 164.01\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 847          |\n",
            "|    mean_reward          | 54           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 105000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066965558 |\n",
            "|    clip_fraction        | 0.0947       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.856       |\n",
            "|    explained_variance   | 0.201        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 72.4         |\n",
            "|    n_updates            | 510          |\n",
            "|    policy_gradient_loss | -0.00527     |\n",
            "|    value_loss           | 107          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 662      |\n",
            "|    ep_rew_mean     | 85.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 219      |\n",
            "|    iterations      | 52       |\n",
            "|    time_elapsed    | 486      |\n",
            "|    total_timesteps | 106496   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 658          |\n",
            "|    ep_rew_mean          | 90.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 222          |\n",
            "|    iterations           | 53           |\n",
            "|    time_elapsed         | 487          |\n",
            "|    total_timesteps      | 108544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068793083 |\n",
            "|    clip_fraction        | 0.033        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.836       |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 39.7         |\n",
            "|    n_updates            | 520          |\n",
            "|    policy_gradient_loss | -0.00279     |\n",
            "|    value_loss           | 73.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=110000, episode_reward=65.32 +/- 124.36\n",
            "Episode length: 813.66 +/- 180.77\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 814          |\n",
            "|    mean_reward          | 65.3         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 110000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068081254 |\n",
            "|    clip_fraction        | 0.0824       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.799       |\n",
            "|    explained_variance   | 0.655        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.7         |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    value_loss           | 68.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 668      |\n",
            "|    ep_rew_mean     | 99.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 214      |\n",
            "|    iterations      | 54       |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 110592   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 673          |\n",
            "|    ep_rew_mean          | 113          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 217          |\n",
            "|    iterations           | 55           |\n",
            "|    time_elapsed         | 518          |\n",
            "|    total_timesteps      | 112640       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019977228 |\n",
            "|    clip_fraction        | 0.0192       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.894       |\n",
            "|    explained_variance   | 0.531        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 124          |\n",
            "|    n_updates            | 540          |\n",
            "|    policy_gradient_loss | -0.00428     |\n",
            "|    value_loss           | 124          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 658          |\n",
            "|    ep_rew_mean          | 119          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 220          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 520          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056226556 |\n",
            "|    clip_fraction        | 0.0333       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.82        |\n",
            "|    explained_variance   | 0.757        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 46.3         |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    value_loss           | 63.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=115000, episode_reward=108.63 +/- 109.76\n",
            "Episode length: 781.22 +/- 107.84\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 781         |\n",
            "|    mean_reward          | 109         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 115000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003703089 |\n",
            "|    clip_fraction        | 0.0376      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | 0.467       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37.4        |\n",
            "|    n_updates            | 560         |\n",
            "|    policy_gradient_loss | -0.00655    |\n",
            "|    value_loss           | 151         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 646      |\n",
            "|    ep_rew_mean     | 128      |\n",
            "| time/              |          |\n",
            "|    fps             | 213      |\n",
            "|    iterations      | 57       |\n",
            "|    time_elapsed    | 546      |\n",
            "|    total_timesteps | 116736   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 626         |\n",
            "|    ep_rew_mean          | 136         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 216         |\n",
            "|    iterations           | 58          |\n",
            "|    time_elapsed         | 548         |\n",
            "|    total_timesteps      | 118784      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005022944 |\n",
            "|    clip_fraction        | 0.0516      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.862      |\n",
            "|    explained_variance   | 0.832       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 33.3        |\n",
            "|    n_updates            | 570         |\n",
            "|    policy_gradient_loss | -0.00428    |\n",
            "|    value_loss           | 41.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=120000, episode_reward=156.09 +/- 74.32\n",
            "Episode length: 697.04 +/- 82.52\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 697          |\n",
            "|    mean_reward          | 156          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 120000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051659523 |\n",
            "|    clip_fraction        | 0.0351       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.87        |\n",
            "|    explained_variance   | 0.357        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 231          |\n",
            "|    n_updates            | 580          |\n",
            "|    policy_gradient_loss | -0.00228     |\n",
            "|    value_loss           | 210          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 611      |\n",
            "|    ep_rew_mean     | 139      |\n",
            "| time/              |          |\n",
            "|    fps             | 212      |\n",
            "|    iterations      | 59       |\n",
            "|    time_elapsed    | 569      |\n",
            "|    total_timesteps | 120832   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 608          |\n",
            "|    ep_rew_mean          | 148          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 215          |\n",
            "|    iterations           | 60           |\n",
            "|    time_elapsed         | 570          |\n",
            "|    total_timesteps      | 122880       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040646386 |\n",
            "|    clip_fraction        | 0.0175       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.845       |\n",
            "|    explained_variance   | 0.134        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 98.6         |\n",
            "|    n_updates            | 590          |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 217          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 585         |\n",
            "|    ep_rew_mean          | 157         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 218         |\n",
            "|    iterations           | 61          |\n",
            "|    time_elapsed         | 572         |\n",
            "|    total_timesteps      | 124928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005329638 |\n",
            "|    clip_fraction        | 0.0328      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.742      |\n",
            "|    explained_variance   | 0.447       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 36.8        |\n",
            "|    n_updates            | 600         |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    value_loss           | 83          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=125000, episode_reward=156.20 +/- 77.25\n",
            "Episode length: 646.82 +/- 94.55\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 647         |\n",
            "|    mean_reward          | 156         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 125000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008018398 |\n",
            "|    clip_fraction        | 0.071       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.772      |\n",
            "|    explained_variance   | 0.807       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22.5        |\n",
            "|    n_updates            | 610         |\n",
            "|    policy_gradient_loss | -0.00453    |\n",
            "|    value_loss           | 54.8        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 559      |\n",
            "|    ep_rew_mean     | 164      |\n",
            "| time/              |          |\n",
            "|    fps             | 214      |\n",
            "|    iterations      | 62       |\n",
            "|    time_elapsed    | 592      |\n",
            "|    total_timesteps | 126976   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 536         |\n",
            "|    ep_rew_mean          | 171         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 217         |\n",
            "|    iterations           | 63          |\n",
            "|    time_elapsed         | 593         |\n",
            "|    total_timesteps      | 129024      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003857586 |\n",
            "|    clip_fraction        | 0.0435      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.841      |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.17        |\n",
            "|    n_updates            | 620         |\n",
            "|    policy_gradient_loss | -0.000482   |\n",
            "|    value_loss           | 30.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=130000, episode_reward=152.88 +/- 89.62\n",
            "Episode length: 645.02 +/- 104.23\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 645         |\n",
            "|    mean_reward          | 153         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 130000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007902872 |\n",
            "|    clip_fraction        | 0.0754      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.827      |\n",
            "|    explained_variance   | 0.9         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.09        |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | -0.00432    |\n",
            "|    value_loss           | 27          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 514      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    fps             | 213      |\n",
            "|    iterations      | 64       |\n",
            "|    time_elapsed    | 612      |\n",
            "|    total_timesteps | 131072   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 495          |\n",
            "|    ep_rew_mean          | 173          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 216          |\n",
            "|    iterations           | 65           |\n",
            "|    time_elapsed         | 614          |\n",
            "|    total_timesteps      | 133120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034876904 |\n",
            "|    clip_fraction        | 0.011        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.758       |\n",
            "|    explained_variance   | 0.413        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 59.5         |\n",
            "|    n_updates            | 640          |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    value_loss           | 207          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=135000, episode_reward=154.62 +/- 92.14\n",
            "Episode length: 569.48 +/- 70.63\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 569          |\n",
            "|    mean_reward          | 155          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 135000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070901196 |\n",
            "|    clip_fraction        | 0.0682       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.864       |\n",
            "|    explained_variance   | 0.52         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 19.3         |\n",
            "|    n_updates            | 650          |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    value_loss           | 138          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 486      |\n",
            "|    ep_rew_mean     | 172      |\n",
            "| time/              |          |\n",
            "|    fps             | 214      |\n",
            "|    iterations      | 66       |\n",
            "|    time_elapsed    | 630      |\n",
            "|    total_timesteps | 135168   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 483          |\n",
            "|    ep_rew_mean          | 168          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 217          |\n",
            "|    iterations           | 67           |\n",
            "|    time_elapsed         | 631          |\n",
            "|    total_timesteps      | 137216       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040249685 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.816       |\n",
            "|    explained_variance   | 0.59         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 126          |\n",
            "|    n_updates            | 660          |\n",
            "|    policy_gradient_loss | -0.00564     |\n",
            "|    value_loss           | 124          |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 486        |\n",
            "|    ep_rew_mean          | 168        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 220        |\n",
            "|    iterations           | 68         |\n",
            "|    time_elapsed         | 633        |\n",
            "|    total_timesteps      | 139264     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00371899 |\n",
            "|    clip_fraction        | 0.0342     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.859     |\n",
            "|    explained_variance   | 0.612      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 28.3       |\n",
            "|    n_updates            | 670        |\n",
            "|    policy_gradient_loss | -0.00457   |\n",
            "|    value_loss           | 157        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=140000, episode_reward=128.85 +/- 119.34\n",
            "Episode length: 550.50 +/- 41.51\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 550         |\n",
            "|    mean_reward          | 129         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 140000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006381677 |\n",
            "|    clip_fraction        | 0.0455      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.723       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.6        |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.0038     |\n",
            "|    value_loss           | 76          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 486      |\n",
            "|    ep_rew_mean     | 166      |\n",
            "| time/              |          |\n",
            "|    fps             | 218      |\n",
            "|    iterations      | 69       |\n",
            "|    time_elapsed    | 646      |\n",
            "|    total_timesteps | 141312   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 478          |\n",
            "|    ep_rew_mean          | 167          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 221          |\n",
            "|    iterations           | 70           |\n",
            "|    time_elapsed         | 648          |\n",
            "|    total_timesteps      | 143360       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042549763 |\n",
            "|    clip_fraction        | 0.0631       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.794       |\n",
            "|    explained_variance   | 0.359        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 63.2         |\n",
            "|    n_updates            | 690          |\n",
            "|    policy_gradient_loss | -0.00433     |\n",
            "|    value_loss           | 173          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=145000, episode_reward=170.62 +/- 93.24\n",
            "Episode length: 527.90 +/- 61.43\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 528          |\n",
            "|    mean_reward          | 171          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 145000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057160044 |\n",
            "|    clip_fraction        | 0.0616       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.768       |\n",
            "|    explained_variance   | 0.696        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.8         |\n",
            "|    n_updates            | 700          |\n",
            "|    policy_gradient_loss | -0.0043      |\n",
            "|    value_loss           | 120          |\n",
            "------------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 482      |\n",
            "|    ep_rew_mean     | 163      |\n",
            "| time/              |          |\n",
            "|    fps             | 219      |\n",
            "|    iterations      | 71       |\n",
            "|    time_elapsed    | 661      |\n",
            "|    total_timesteps | 145408   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 478         |\n",
            "|    ep_rew_mean          | 164         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 222         |\n",
            "|    iterations           | 72          |\n",
            "|    time_elapsed         | 662         |\n",
            "|    total_timesteps      | 147456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006581924 |\n",
            "|    clip_fraction        | 0.0501      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.742      |\n",
            "|    explained_variance   | 0.313       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 119         |\n",
            "|    n_updates            | 710         |\n",
            "|    policy_gradient_loss | -0.00722    |\n",
            "|    value_loss           | 224         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 473          |\n",
            "|    ep_rew_mean          | 165          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 225          |\n",
            "|    iterations           | 73           |\n",
            "|    time_elapsed         | 663          |\n",
            "|    total_timesteps      | 149504       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051741973 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.78        |\n",
            "|    explained_variance   | 0.699        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40.8         |\n",
            "|    n_updates            | 720          |\n",
            "|    policy_gradient_loss | -0.00134     |\n",
            "|    value_loss           | 134          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=150000, episode_reward=172.72 +/- 84.35\n",
            "Episode length: 524.72 +/- 76.92\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 525         |\n",
            "|    mean_reward          | 173         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 150000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007250333 |\n",
            "|    clip_fraction        | 0.0323      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.616      |\n",
            "|    explained_variance   | 0.674       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.4        |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.0022     |\n",
            "|    value_loss           | 138         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 473      |\n",
            "|    ep_rew_mean     | 162      |\n",
            "| time/              |          |\n",
            "|    fps             | 223      |\n",
            "|    iterations      | 74       |\n",
            "|    time_elapsed    | 676      |\n",
            "|    total_timesteps | 151552   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 468          |\n",
            "|    ep_rew_mean          | 160          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 226          |\n",
            "|    iterations           | 75           |\n",
            "|    time_elapsed         | 678          |\n",
            "|    total_timesteps      | 153600       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041963644 |\n",
            "|    clip_fraction        | 0.0406       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.821       |\n",
            "|    explained_variance   | 0.561        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12           |\n",
            "|    n_updates            | 740          |\n",
            "|    policy_gradient_loss | -0.00219     |\n",
            "|    value_loss           | 166          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=155000, episode_reward=152.64 +/- 99.61\n",
            "Episode length: 546.70 +/- 89.40\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 547          |\n",
            "|    mean_reward          | 153          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 155000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048425607 |\n",
            "|    clip_fraction        | 0.0394       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.801       |\n",
            "|    explained_variance   | 0.761        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 31.1         |\n",
            "|    n_updates            | 750          |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    value_loss           | 109          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 461      |\n",
            "|    ep_rew_mean     | 161      |\n",
            "| time/              |          |\n",
            "|    fps             | 224      |\n",
            "|    iterations      | 76       |\n",
            "|    time_elapsed    | 692      |\n",
            "|    total_timesteps | 155648   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 464          |\n",
            "|    ep_rew_mean          | 159          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 227          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 693          |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050930507 |\n",
            "|    clip_fraction        | 0.0832       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.763       |\n",
            "|    explained_variance   | 0.532        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 307          |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.00464     |\n",
            "|    value_loss           | 176          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 463          |\n",
            "|    ep_rew_mean          | 155          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 695          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068006325 |\n",
            "|    clip_fraction        | 0.0413       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.665       |\n",
            "|    explained_variance   | 0.331        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.6         |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    value_loss           | 127          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=160000, episode_reward=141.29 +/- 105.06\n",
            "Episode length: 620.50 +/- 124.24\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 620         |\n",
            "|    mean_reward          | 141         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 160000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005328808 |\n",
            "|    clip_fraction        | 0.0376      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.716      |\n",
            "|    explained_variance   | 0.15        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 73.2        |\n",
            "|    n_updates            | 780         |\n",
            "|    policy_gradient_loss | -0.00439    |\n",
            "|    value_loss           | 228         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 463      |\n",
            "|    ep_rew_mean     | 154      |\n",
            "| time/              |          |\n",
            "|    fps             | 227      |\n",
            "|    iterations      | 79       |\n",
            "|    time_elapsed    | 712      |\n",
            "|    total_timesteps | 161792   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 464         |\n",
            "|    ep_rew_mean          | 153         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 80          |\n",
            "|    time_elapsed         | 713         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006105514 |\n",
            "|    clip_fraction        | 0.0527      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.828      |\n",
            "|    explained_variance   | 0.516       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22.2        |\n",
            "|    n_updates            | 790         |\n",
            "|    policy_gradient_loss | -0.00409    |\n",
            "|    value_loss           | 114         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=165000, episode_reward=131.78 +/- 104.43\n",
            "Episode length: 611.20 +/- 92.05\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 611         |\n",
            "|    mean_reward          | 132         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 165000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004729253 |\n",
            "|    clip_fraction        | 0.0604      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.711      |\n",
            "|    explained_variance   | 0.626       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 26.9        |\n",
            "|    n_updates            | 800         |\n",
            "|    policy_gradient_loss | -0.00279    |\n",
            "|    value_loss           | 76          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 468      |\n",
            "|    ep_rew_mean     | 155      |\n",
            "| time/              |          |\n",
            "|    fps             | 227      |\n",
            "|    iterations      | 81       |\n",
            "|    time_elapsed    | 730      |\n",
            "|    total_timesteps | 165888   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | 156         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 82          |\n",
            "|    time_elapsed         | 731         |\n",
            "|    total_timesteps      | 167936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006618181 |\n",
            "|    clip_fraction        | 0.0374      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.729      |\n",
            "|    explained_variance   | 0.772       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.1        |\n",
            "|    n_updates            | 810         |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    value_loss           | 88          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 470         |\n",
            "|    ep_rew_mean          | 155         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 83          |\n",
            "|    time_elapsed         | 733         |\n",
            "|    total_timesteps      | 169984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006036143 |\n",
            "|    clip_fraction        | 0.0599      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.772      |\n",
            "|    explained_variance   | 0.753       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 73          |\n",
            "|    n_updates            | 820         |\n",
            "|    policy_gradient_loss | -0.00235    |\n",
            "|    value_loss           | 95.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=170000, episode_reward=114.92 +/- 128.69\n",
            "Episode length: 618.80 +/- 136.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 619         |\n",
            "|    mean_reward          | 115         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 170000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008247342 |\n",
            "|    clip_fraction        | 0.0653      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.781      |\n",
            "|    explained_variance   | 0.683       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.8        |\n",
            "|    n_updates            | 830         |\n",
            "|    policy_gradient_loss | -0.00367    |\n",
            "|    value_loss           | 92.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 471      |\n",
            "|    ep_rew_mean     | 153      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 84       |\n",
            "|    time_elapsed    | 750      |\n",
            "|    total_timesteps | 172032   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | 141         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 85          |\n",
            "|    time_elapsed         | 751         |\n",
            "|    total_timesteps      | 174080      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009412794 |\n",
            "|    clip_fraction        | 0.0803      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.783      |\n",
            "|    explained_variance   | 0.776       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 35.4        |\n",
            "|    n_updates            | 840         |\n",
            "|    policy_gradient_loss | -0.00257    |\n",
            "|    value_loss           | 96.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=175000, episode_reward=85.98 +/- 137.87\n",
            "Episode length: 621.08 +/- 154.94\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 621          |\n",
            "|    mean_reward          | 86           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 175000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034745398 |\n",
            "|    clip_fraction        | 0.0305       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.739       |\n",
            "|    explained_variance   | 0.739        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 46.7         |\n",
            "|    n_updates            | 850          |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    value_loss           | 174          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 473      |\n",
            "|    ep_rew_mean     | 135      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 86       |\n",
            "|    time_elapsed    | 768      |\n",
            "|    total_timesteps | 176128   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 468         |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 769         |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008337786 |\n",
            "|    clip_fraction        | 0.0527      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.657      |\n",
            "|    explained_variance   | 0.758       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 56          |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.00105    |\n",
            "|    value_loss           | 149         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=180000, episode_reward=65.57 +/- 141.88\n",
            "Episode length: 616.88 +/- 161.99\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 617          |\n",
            "|    mean_reward          | 65.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 180000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030057663 |\n",
            "|    clip_fraction        | 0.0563       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.77        |\n",
            "|    explained_variance   | 0.894        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.76         |\n",
            "|    n_updates            | 870          |\n",
            "|    policy_gradient_loss | -0.00146     |\n",
            "|    value_loss           | 43.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 466      |\n",
            "|    ep_rew_mean     | 134      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 88       |\n",
            "|    time_elapsed    | 786      |\n",
            "|    total_timesteps | 180224   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 469         |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 89          |\n",
            "|    time_elapsed         | 787         |\n",
            "|    total_timesteps      | 182272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005145761 |\n",
            "|    clip_fraction        | 0.0556      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.783      |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.3        |\n",
            "|    n_updates            | 880         |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    value_loss           | 90.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 472        |\n",
            "|    ep_rew_mean          | 132        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 233        |\n",
            "|    iterations           | 90         |\n",
            "|    time_elapsed         | 788        |\n",
            "|    total_timesteps      | 184320     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00335976 |\n",
            "|    clip_fraction        | 0.0309     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.765     |\n",
            "|    explained_variance   | 0.824      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 218        |\n",
            "|    n_updates            | 890        |\n",
            "|    policy_gradient_loss | -0.00199   |\n",
            "|    value_loss           | 171        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=185000, episode_reward=61.09 +/- 143.04\n",
            "Episode length: 638.66 +/- 175.88\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 639          |\n",
            "|    mean_reward          | 61.1         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 185000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046208957 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.734       |\n",
            "|    explained_variance   | 0.741        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 55.1         |\n",
            "|    n_updates            | 900          |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    value_loss           | 143          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 472      |\n",
            "|    ep_rew_mean     | 131      |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 91       |\n",
            "|    time_elapsed    | 807      |\n",
            "|    total_timesteps | 186368   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 473          |\n",
            "|    ep_rew_mean          | 127          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 808          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046334546 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.767       |\n",
            "|    explained_variance   | 0.879        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 60.9         |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 87.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=190000, episode_reward=10.33 +/- 140.72\n",
            "Episode length: 762.18 +/- 228.85\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 762          |\n",
            "|    mean_reward          | 10.3         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 190000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027899256 |\n",
            "|    clip_fraction        | 0.0268       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.784       |\n",
            "|    explained_variance   | 0.764        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.9         |\n",
            "|    n_updates            | 920          |\n",
            "|    policy_gradient_loss | -0.000741    |\n",
            "|    value_loss           | 138          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 474      |\n",
            "|    ep_rew_mean     | 129      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 93       |\n",
            "|    time_elapsed    | 831      |\n",
            "|    total_timesteps | 190464   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 474          |\n",
            "|    ep_rew_mean          | 135          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 94           |\n",
            "|    time_elapsed         | 832          |\n",
            "|    total_timesteps      | 192512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048576854 |\n",
            "|    clip_fraction        | 0.0547       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.706       |\n",
            "|    explained_variance   | 0.853        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 930          |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    value_loss           | 28           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 477         |\n",
            "|    ep_rew_mean          | 139         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 233         |\n",
            "|    iterations           | 95          |\n",
            "|    time_elapsed         | 834         |\n",
            "|    total_timesteps      | 194560      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005327641 |\n",
            "|    clip_fraction        | 0.0413      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.831      |\n",
            "|    explained_variance   | 0.883       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 71.2        |\n",
            "|    n_updates            | 940         |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    value_loss           | 83          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=195000, episode_reward=16.03 +/- 147.68\n",
            "Episode length: 627.78 +/- 234.54\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 628         |\n",
            "|    mean_reward          | 16          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 195000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008896989 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.744      |\n",
            "|    explained_variance   | 0.987       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.26        |\n",
            "|    n_updates            | 950         |\n",
            "|    policy_gradient_loss | -0.00606    |\n",
            "|    value_loss           | 14.8        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 482      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 96       |\n",
            "|    time_elapsed    | 851      |\n",
            "|    total_timesteps | 196608   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 479         |\n",
            "|    ep_rew_mean          | 143         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 97          |\n",
            "|    time_elapsed         | 852         |\n",
            "|    total_timesteps      | 198656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006250728 |\n",
            "|    clip_fraction        | 0.0318      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.758      |\n",
            "|    explained_variance   | 0.912       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 80.9        |\n",
            "|    n_updates            | 960         |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    value_loss           | 78.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=200000, episode_reward=-5.03 +/- 148.09\n",
            "Episode length: 637.08 +/- 213.10\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 637          |\n",
            "|    mean_reward          | -5.03        |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 200000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054189926 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.691       |\n",
            "|    explained_variance   | 0.684        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.7         |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00432     |\n",
            "|    value_loss           | 278          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 142      |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 98       |\n",
            "|    time_elapsed    | 871      |\n",
            "|    total_timesteps | 200704   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 492          |\n",
            "|    ep_rew_mean          | 141          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 873          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068222294 |\n",
            "|    clip_fraction        | 0.0402       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.808       |\n",
            "|    explained_variance   | 0.921        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.47         |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.000894    |\n",
            "|    value_loss           | 28           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 493         |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 234         |\n",
            "|    iterations           | 100         |\n",
            "|    time_elapsed         | 875         |\n",
            "|    total_timesteps      | 204800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003496794 |\n",
            "|    clip_fraction        | 0.0209      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.799      |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 21.6        |\n",
            "|    n_updates            | 990         |\n",
            "|    policy_gradient_loss | -0.00323    |\n",
            "|    value_loss           | 125         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=205000, episode_reward=86.54 +/- 128.87\n",
            "Episode length: 550.04 +/- 162.79\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 550          |\n",
            "|    mean_reward          | 86.5         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 205000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043868646 |\n",
            "|    clip_fraction        | 0.0374       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.596       |\n",
            "|    explained_variance   | 0.643        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 23.2         |\n",
            "|    n_updates            | 1000         |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    value_loss           | 167          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 101      |\n",
            "|    time_elapsed    | 889      |\n",
            "|    total_timesteps | 206848   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 478        |\n",
            "|    ep_rew_mean          | 133        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 234        |\n",
            "|    iterations           | 102        |\n",
            "|    time_elapsed         | 890        |\n",
            "|    total_timesteps      | 208896     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00458072 |\n",
            "|    clip_fraction        | 0.0616     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.749     |\n",
            "|    explained_variance   | 0.714      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 37.9       |\n",
            "|    n_updates            | 1010       |\n",
            "|    policy_gradient_loss | -0.0032    |\n",
            "|    value_loss           | 153        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=210000, episode_reward=91.20 +/- 125.51\n",
            "Episode length: 537.56 +/- 187.66\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 538          |\n",
            "|    mean_reward          | 91.2         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 210000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067022694 |\n",
            "|    clip_fraction        | 0.0771       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.733       |\n",
            "|    explained_variance   | 0.549        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 187          |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    value_loss           | 258          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 481      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 103      |\n",
            "|    time_elapsed    | 904      |\n",
            "|    total_timesteps | 210944   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 476          |\n",
            "|    ep_rew_mean          | 132          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 235          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 905          |\n",
            "|    total_timesteps      | 212992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049638343 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.746       |\n",
            "|    explained_variance   | 0.858        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 37.5         |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 75.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=215000, episode_reward=56.41 +/- 125.06\n",
            "Episode length: 620.02 +/- 202.23\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 620         |\n",
            "|    mean_reward          | 56.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 215000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006827278 |\n",
            "|    clip_fraction        | 0.0857      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.748      |\n",
            "|    explained_variance   | 0.887       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37          |\n",
            "|    n_updates            | 1040        |\n",
            "|    policy_gradient_loss | -0.00833    |\n",
            "|    value_loss           | 95.8        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 478      |\n",
            "|    ep_rew_mean     | 128      |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 105      |\n",
            "|    time_elapsed    | 922      |\n",
            "|    total_timesteps | 215040   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 481         |\n",
            "|    ep_rew_mean          | 128         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 234         |\n",
            "|    iterations           | 106         |\n",
            "|    time_elapsed         | 923         |\n",
            "|    total_timesteps      | 217088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007500803 |\n",
            "|    clip_fraction        | 0.0472      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.773      |\n",
            "|    explained_variance   | 0.448       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 104         |\n",
            "|    n_updates            | 1050        |\n",
            "|    policy_gradient_loss | -0.00282    |\n",
            "|    value_loss           | 225         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 476         |\n",
            "|    ep_rew_mean          | 126         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 236         |\n",
            "|    iterations           | 107         |\n",
            "|    time_elapsed         | 925         |\n",
            "|    total_timesteps      | 219136      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007228662 |\n",
            "|    clip_fraction        | 0.0573      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.782      |\n",
            "|    explained_variance   | 0.741       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 19.2        |\n",
            "|    n_updates            | 1060        |\n",
            "|    policy_gradient_loss | -0.00262    |\n",
            "|    value_loss           | 95.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=220000, episode_reward=87.54 +/- 136.24\n",
            "Episode length: 582.56 +/- 169.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 583         |\n",
            "|    mean_reward          | 87.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 220000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007850591 |\n",
            "|    clip_fraction        | 0.0633      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.699      |\n",
            "|    explained_variance   | 0.675       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 24.3        |\n",
            "|    n_updates            | 1070        |\n",
            "|    policy_gradient_loss | -0.00453    |\n",
            "|    value_loss           | 175         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 477      |\n",
            "|    ep_rew_mean     | 129      |\n",
            "| time/              |          |\n",
            "|    fps             | 235      |\n",
            "|    iterations      | 108      |\n",
            "|    time_elapsed    | 941      |\n",
            "|    total_timesteps | 221184   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 472         |\n",
            "|    ep_rew_mean          | 139         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 236         |\n",
            "|    iterations           | 109         |\n",
            "|    time_elapsed         | 942         |\n",
            "|    total_timesteps      | 223232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009260964 |\n",
            "|    clip_fraction        | 0.0939      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.844      |\n",
            "|    explained_variance   | 0.79        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 144         |\n",
            "|    n_updates            | 1080        |\n",
            "|    policy_gradient_loss | -0.00514    |\n",
            "|    value_loss           | 122         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=225000, episode_reward=80.35 +/- 116.97\n",
            "Episode length: 672.52 +/- 254.32\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 673         |\n",
            "|    mean_reward          | 80.3        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 225000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006247312 |\n",
            "|    clip_fraction        | 0.055       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.669      |\n",
            "|    explained_variance   | 0.751       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 15.4        |\n",
            "|    n_updates            | 1090        |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    value_loss           | 57.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 478      |\n",
            "|    ep_rew_mean     | 137      |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 110      |\n",
            "|    time_elapsed    | 962      |\n",
            "|    total_timesteps | 225280   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 486         |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 235         |\n",
            "|    iterations           | 111         |\n",
            "|    time_elapsed         | 964         |\n",
            "|    total_timesteps      | 227328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006976559 |\n",
            "|    clip_fraction        | 0.0693      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.713      |\n",
            "|    explained_variance   | 0.843       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.39        |\n",
            "|    n_updates            | 1100        |\n",
            "|    policy_gradient_loss | -0.00517    |\n",
            "|    value_loss           | 28.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 485          |\n",
            "|    ep_rew_mean          | 143          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 237          |\n",
            "|    iterations           | 112          |\n",
            "|    time_elapsed         | 965          |\n",
            "|    total_timesteps      | 229376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058105974 |\n",
            "|    clip_fraction        | 0.0502       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.831       |\n",
            "|    explained_variance   | 0.896        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.61         |\n",
            "|    n_updates            | 1110         |\n",
            "|    policy_gradient_loss | -0.00194     |\n",
            "|    value_loss           | 54.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=230000, episode_reward=121.13 +/- 116.26\n",
            "Episode length: 558.90 +/- 209.98\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 559         |\n",
            "|    mean_reward          | 121         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 230000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003921828 |\n",
            "|    clip_fraction        | 0.0285      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.568      |\n",
            "|    explained_variance   | 0.685       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 85.4        |\n",
            "|    n_updates            | 1120        |\n",
            "|    policy_gradient_loss | -0.00232    |\n",
            "|    value_loss           | 137         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 141      |\n",
            "| time/              |          |\n",
            "|    fps             | 236      |\n",
            "|    iterations      | 113      |\n",
            "|    time_elapsed    | 980      |\n",
            "|    total_timesteps | 231424   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 488         |\n",
            "|    ep_rew_mean          | 145         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 237         |\n",
            "|    iterations           | 114         |\n",
            "|    time_elapsed         | 981         |\n",
            "|    total_timesteps      | 233472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005527788 |\n",
            "|    clip_fraction        | 0.0637      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.797      |\n",
            "|    explained_variance   | 0.539       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 97.5        |\n",
            "|    n_updates            | 1130        |\n",
            "|    policy_gradient_loss | -0.00761    |\n",
            "|    value_loss           | 186         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=235000, episode_reward=113.75 +/- 112.82\n",
            "Episode length: 549.50 +/- 195.33\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 550         |\n",
            "|    mean_reward          | 114         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 235000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009630347 |\n",
            "|    clip_fraction        | 0.0712      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.756      |\n",
            "|    explained_variance   | 0.824       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.62        |\n",
            "|    n_updates            | 1140        |\n",
            "|    policy_gradient_loss | -0.00289    |\n",
            "|    value_loss           | 36.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 480      |\n",
            "|    ep_rew_mean     | 146      |\n",
            "| time/              |          |\n",
            "|    fps             | 236      |\n",
            "|    iterations      | 115      |\n",
            "|    time_elapsed    | 995      |\n",
            "|    total_timesteps | 235520   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 480          |\n",
            "|    ep_rew_mean          | 140          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 238          |\n",
            "|    iterations           | 116          |\n",
            "|    time_elapsed         | 997          |\n",
            "|    total_timesteps      | 237568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054830858 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.799       |\n",
            "|    explained_variance   | 0.614        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 57           |\n",
            "|    n_updates            | 1150         |\n",
            "|    policy_gradient_loss | -0.005       |\n",
            "|    value_loss           | 177          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 474          |\n",
            "|    ep_rew_mean          | 139          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 239          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 998          |\n",
            "|    total_timesteps      | 239616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067938906 |\n",
            "|    clip_fraction        | 0.0315       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.78        |\n",
            "|    explained_variance   | 0.568        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40.1         |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    value_loss           | 157          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=240000, episode_reward=111.83 +/- 116.87\n",
            "Episode length: 575.42 +/- 209.49\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 575          |\n",
            "|    mean_reward          | 112          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 240000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032289512 |\n",
            "|    clip_fraction        | 0.0319       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.682       |\n",
            "|    explained_variance   | 0.724        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.4         |\n",
            "|    n_updates            | 1170         |\n",
            "|    policy_gradient_loss | -0.00586     |\n",
            "|    value_loss           | 120          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 477      |\n",
            "|    ep_rew_mean     | 141      |\n",
            "| time/              |          |\n",
            "|    fps             | 238      |\n",
            "|    iterations      | 118      |\n",
            "|    time_elapsed    | 1014     |\n",
            "|    total_timesteps | 241664   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 470         |\n",
            "|    ep_rew_mean          | 134         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 239         |\n",
            "|    iterations           | 119         |\n",
            "|    time_elapsed         | 1015        |\n",
            "|    total_timesteps      | 243712      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004788762 |\n",
            "|    clip_fraction        | 0.0583      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.71       |\n",
            "|    explained_variance   | 0.876       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.2        |\n",
            "|    n_updates            | 1180        |\n",
            "|    policy_gradient_loss | -0.00289    |\n",
            "|    value_loss           | 65.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=245000, episode_reward=111.10 +/- 121.60\n",
            "Episode length: 623.66 +/- 233.45\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 624         |\n",
            "|    mean_reward          | 111         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 245000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006490728 |\n",
            "|    clip_fraction        | 0.0445      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.769      |\n",
            "|    explained_variance   | 0.511       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 56.9        |\n",
            "|    n_updates            | 1190        |\n",
            "|    policy_gradient_loss | -0.0025     |\n",
            "|    value_loss           | 288         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 462      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 237      |\n",
            "|    iterations      | 120      |\n",
            "|    time_elapsed    | 1033     |\n",
            "|    total_timesteps | 245760   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 456         |\n",
            "|    ep_rew_mean          | 140         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 239         |\n",
            "|    iterations           | 121         |\n",
            "|    time_elapsed         | 1035        |\n",
            "|    total_timesteps      | 247808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005773271 |\n",
            "|    clip_fraction        | 0.0506      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.717      |\n",
            "|    explained_variance   | 0.628       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 102         |\n",
            "|    n_updates            | 1200        |\n",
            "|    policy_gradient_loss | -0.00168    |\n",
            "|    value_loss           | 127         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 456          |\n",
            "|    ep_rew_mean          | 133          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 240          |\n",
            "|    iterations           | 122          |\n",
            "|    time_elapsed         | 1036         |\n",
            "|    total_timesteps      | 249856       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066697625 |\n",
            "|    clip_fraction        | 0.0639       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.759       |\n",
            "|    explained_variance   | 0.723        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.1         |\n",
            "|    n_updates            | 1210         |\n",
            "|    policy_gradient_loss | -0.00378     |\n",
            "|    value_loss           | 102          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=250000, episode_reward=102.87 +/- 107.27\n",
            "Episode length: 706.80 +/- 237.13\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 707        |\n",
            "|    mean_reward          | 103        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 250000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00525924 |\n",
            "|    clip_fraction        | 0.0357     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.759     |\n",
            "|    explained_variance   | 0.501      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 131        |\n",
            "|    n_updates            | 1220       |\n",
            "|    policy_gradient_loss | -0.00277   |\n",
            "|    value_loss           | 223        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 454      |\n",
            "|    ep_rew_mean     | 132      |\n",
            "| time/              |          |\n",
            "|    fps             | 237      |\n",
            "|    iterations      | 123      |\n",
            "|    time_elapsed    | 1059     |\n",
            "|    total_timesteps | 251904   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 462          |\n",
            "|    ep_rew_mean          | 134          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 239          |\n",
            "|    iterations           | 124          |\n",
            "|    time_elapsed         | 1061         |\n",
            "|    total_timesteps      | 253952       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061560003 |\n",
            "|    clip_fraction        | 0.0716       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.761       |\n",
            "|    explained_variance   | 0.699        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 43.9         |\n",
            "|    n_updates            | 1230         |\n",
            "|    policy_gradient_loss | -0.00337     |\n",
            "|    value_loss           | 147          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=255000, episode_reward=80.70 +/- 106.87\n",
            "Episode length: 658.22 +/- 266.63\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 658         |\n",
            "|    mean_reward          | 80.7        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 255000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007861397 |\n",
            "|    clip_fraction        | 0.0854      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.694      |\n",
            "|    explained_variance   | 0.862       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22.3        |\n",
            "|    n_updates            | 1240        |\n",
            "|    policy_gradient_loss | -0.00194    |\n",
            "|    value_loss           | 59.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 474      |\n",
            "|    ep_rew_mean     | 139      |\n",
            "| time/              |          |\n",
            "|    fps             | 236      |\n",
            "|    iterations      | 125      |\n",
            "|    time_elapsed    | 1083     |\n",
            "|    total_timesteps | 256000   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 480          |\n",
            "|    ep_rew_mean          | 136          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 237          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 1085         |\n",
            "|    total_timesteps      | 258048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048428085 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.79        |\n",
            "|    explained_variance   | 0.837        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.62         |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    value_loss           | 75.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=260000, episode_reward=49.62 +/- 109.78\n",
            "Episode length: 692.32 +/- 250.26\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 692          |\n",
            "|    mean_reward          | 49.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 260000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055539804 |\n",
            "|    clip_fraction        | 0.091        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.67        |\n",
            "|    explained_variance   | 0.896        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.5         |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | -0.00217     |\n",
            "|    value_loss           | 16.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 482      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 234      |\n",
            "|    iterations      | 127      |\n",
            "|    time_elapsed    | 1109     |\n",
            "|    total_timesteps | 260096   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 486          |\n",
            "|    ep_rew_mean          | 134          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 235          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 1110         |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042520133 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.839       |\n",
            "|    explained_variance   | 0.877        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 80.5         |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    value_loss           | 68           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 477         |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 237         |\n",
            "|    iterations           | 129         |\n",
            "|    time_elapsed         | 1112        |\n",
            "|    total_timesteps      | 264192      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007777714 |\n",
            "|    clip_fraction        | 0.0722      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.859      |\n",
            "|    explained_variance   | 0.703       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 98.1        |\n",
            "|    n_updates            | 1280        |\n",
            "|    policy_gradient_loss | -0.00374    |\n",
            "|    value_loss           | 120         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=265000, episode_reward=53.64 +/- 103.72\n",
            "Episode length: 738.48 +/- 255.54\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 738          |\n",
            "|    mean_reward          | 53.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 265000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034056774 |\n",
            "|    clip_fraction        | 0.00972      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.766       |\n",
            "|    explained_variance   | 0.387        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 84           |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -0.00311     |\n",
            "|    value_loss           | 226          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 485      |\n",
            "|    ep_rew_mean     | 135      |\n",
            "| time/              |          |\n",
            "|    fps             | 234      |\n",
            "|    iterations      | 130      |\n",
            "|    time_elapsed    | 1136     |\n",
            "|    total_timesteps | 266240   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 495         |\n",
            "|    ep_rew_mean          | 135         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 235         |\n",
            "|    iterations           | 131         |\n",
            "|    time_elapsed         | 1137        |\n",
            "|    total_timesteps      | 268288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007711064 |\n",
            "|    clip_fraction        | 0.0612      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.777      |\n",
            "|    explained_variance   | 0.882       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.4        |\n",
            "|    n_updates            | 1300        |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    value_loss           | 34.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=270000, episode_reward=80.82 +/- 100.99\n",
            "Episode length: 765.98 +/- 224.43\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 766          |\n",
            "|    mean_reward          | 80.8         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 270000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050708153 |\n",
            "|    clip_fraction        | 0.047        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.736       |\n",
            "|    explained_variance   | 0.887        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.31         |\n",
            "|    n_updates            | 1310         |\n",
            "|    policy_gradient_loss | -3.05e-05    |\n",
            "|    value_loss           | 24.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 494      |\n",
            "|    ep_rew_mean     | 139      |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 132      |\n",
            "|    time_elapsed    | 1163     |\n",
            "|    total_timesteps | 270336   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 507          |\n",
            "|    ep_rew_mean          | 137          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 1164         |\n",
            "|    total_timesteps      | 272384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038731305 |\n",
            "|    clip_fraction        | 0.0328       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.817       |\n",
            "|    explained_variance   | 0.82         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.6          |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.0017      |\n",
            "|    value_loss           | 63.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 517         |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 235         |\n",
            "|    iterations           | 134         |\n",
            "|    time_elapsed         | 1166        |\n",
            "|    total_timesteps      | 274432      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008064806 |\n",
            "|    clip_fraction        | 0.0961      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.817      |\n",
            "|    explained_variance   | 0.96        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.49        |\n",
            "|    n_updates            | 1330        |\n",
            "|    policy_gradient_loss | -0.0046     |\n",
            "|    value_loss           | 12.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=275000, episode_reward=95.41 +/- 96.30\n",
            "Episode length: 782.30 +/- 216.38\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 782          |\n",
            "|    mean_reward          | 95.4         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 275000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041872743 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | 0.907        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.93         |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00244     |\n",
            "|    value_loss           | 50.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 507      |\n",
            "|    ep_rew_mean     | 131      |\n",
            "| time/              |          |\n",
            "|    fps             | 231      |\n",
            "|    iterations      | 135      |\n",
            "|    time_elapsed    | 1192     |\n",
            "|    total_timesteps | 276480   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 508          |\n",
            "|    ep_rew_mean          | 122          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 136          |\n",
            "|    time_elapsed         | 1194         |\n",
            "|    total_timesteps      | 278528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021251198 |\n",
            "|    clip_fraction        | 0.0157       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.822       |\n",
            "|    explained_variance   | 0.477        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 48.5         |\n",
            "|    n_updates            | 1350         |\n",
            "|    policy_gradient_loss | 0.000109     |\n",
            "|    value_loss           | 158          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=280000, episode_reward=43.91 +/- 104.37\n",
            "Episode length: 834.90 +/- 223.71\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 835          |\n",
            "|    mean_reward          | 43.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 280000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068505933 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.81        |\n",
            "|    explained_variance   | 0.573        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.2         |\n",
            "|    n_updates            | 1360         |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    value_loss           | 143          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 518      |\n",
            "|    ep_rew_mean     | 123      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 137      |\n",
            "|    time_elapsed    | 1223     |\n",
            "|    total_timesteps | 280576   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 518         |\n",
            "|    ep_rew_mean          | 122         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 230         |\n",
            "|    iterations           | 138         |\n",
            "|    time_elapsed         | 1225        |\n",
            "|    total_timesteps      | 282624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003034349 |\n",
            "|    clip_fraction        | 0.00435     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.864      |\n",
            "|    explained_variance   | 0.711       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.76        |\n",
            "|    n_updates            | 1370        |\n",
            "|    policy_gradient_loss | -0.000515   |\n",
            "|    value_loss           | 47.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 521         |\n",
            "|    ep_rew_mean          | 120         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 139         |\n",
            "|    time_elapsed         | 1227        |\n",
            "|    total_timesteps      | 284672      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006817952 |\n",
            "|    clip_fraction        | 0.0475      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.835      |\n",
            "|    explained_variance   | 0.754       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 57.1        |\n",
            "|    n_updates            | 1380        |\n",
            "|    policy_gradient_loss | -0.00189    |\n",
            "|    value_loss           | 91.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=285000, episode_reward=55.94 +/- 112.41\n",
            "Episode length: 730.26 +/- 260.38\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 730          |\n",
            "|    mean_reward          | 55.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 285000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056426916 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.765       |\n",
            "|    explained_variance   | 0.729        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 71.8         |\n",
            "|    n_updates            | 1390         |\n",
            "|    policy_gradient_loss | -0.0018      |\n",
            "|    value_loss           | 112          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 527      |\n",
            "|    ep_rew_mean     | 115      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 140      |\n",
            "|    time_elapsed    | 1250     |\n",
            "|    total_timesteps | 286720   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 533          |\n",
            "|    ep_rew_mean          | 114          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 1252         |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072150063 |\n",
            "|    clip_fraction        | 0.0554       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.848       |\n",
            "|    explained_variance   | 0.694        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26.8         |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    value_loss           | 142          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=290000, episode_reward=95.53 +/- 112.19\n",
            "Episode length: 695.46 +/- 250.86\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 695         |\n",
            "|    mean_reward          | 95.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 290000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008186863 |\n",
            "|    clip_fraction        | 0.0909      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.836      |\n",
            "|    explained_variance   | 0.736       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 70.7        |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.00585    |\n",
            "|    value_loss           | 101         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 532      |\n",
            "|    ep_rew_mean     | 117      |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 142      |\n",
            "|    time_elapsed    | 1274     |\n",
            "|    total_timesteps | 290816   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 543        |\n",
            "|    ep_rew_mean          | 119        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 229        |\n",
            "|    iterations           | 143        |\n",
            "|    time_elapsed         | 1276       |\n",
            "|    total_timesteps      | 292864     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00666289 |\n",
            "|    clip_fraction        | 0.0559     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.794     |\n",
            "|    explained_variance   | 0.853      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.27       |\n",
            "|    n_updates            | 1420       |\n",
            "|    policy_gradient_loss | -0.00157   |\n",
            "|    value_loss           | 39         |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 550          |\n",
            "|    ep_rew_mean          | 121          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 144          |\n",
            "|    time_elapsed         | 1277         |\n",
            "|    total_timesteps      | 294912       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064765345 |\n",
            "|    clip_fraction        | 0.0736       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.738       |\n",
            "|    explained_variance   | 0.895        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.85         |\n",
            "|    n_updates            | 1430         |\n",
            "|    policy_gradient_loss | -0.00392     |\n",
            "|    value_loss           | 32.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=295000, episode_reward=93.59 +/- 107.95\n",
            "Episode length: 751.78 +/- 229.09\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 752          |\n",
            "|    mean_reward          | 93.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 295000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055767028 |\n",
            "|    clip_fraction        | 0.0441       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.769       |\n",
            "|    explained_variance   | 0.926        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.3         |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    value_loss           | 32.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 547      |\n",
            "|    ep_rew_mean     | 116      |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 145      |\n",
            "|    time_elapsed    | 1302     |\n",
            "|    total_timesteps | 296960   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 557        |\n",
            "|    ep_rew_mean          | 124        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 229        |\n",
            "|    iterations           | 146        |\n",
            "|    time_elapsed         | 1304       |\n",
            "|    total_timesteps      | 299008     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00513835 |\n",
            "|    clip_fraction        | 0.0759     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.819     |\n",
            "|    explained_variance   | 0.658      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 24.2       |\n",
            "|    n_updates            | 1450       |\n",
            "|    policy_gradient_loss | -0.00346   |\n",
            "|    value_loss           | 116        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=300000, episode_reward=64.90 +/- 113.22\n",
            "Episode length: 733.18 +/- 265.22\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 733          |\n",
            "|    mean_reward          | 64.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 300000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053112875 |\n",
            "|    clip_fraction        | 0.0653       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.737       |\n",
            "|    explained_variance   | 0.899        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.2         |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.00503     |\n",
            "|    value_loss           | 33.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 572      |\n",
            "|    ep_rew_mean     | 123      |\n",
            "| time/              |          |\n",
            "|    fps             | 226      |\n",
            "|    iterations      | 147      |\n",
            "|    time_elapsed    | 1328     |\n",
            "|    total_timesteps | 301056   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 575          |\n",
            "|    ep_rew_mean          | 120          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 227          |\n",
            "|    iterations           | 148          |\n",
            "|    time_elapsed         | 1330         |\n",
            "|    total_timesteps      | 303104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060926406 |\n",
            "|    clip_fraction        | 0.0781       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.78        |\n",
            "|    explained_variance   | 0.898        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 55.6         |\n",
            "|    n_updates            | 1470         |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    value_loss           | 47.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=305000, episode_reward=84.75 +/- 105.06\n",
            "Episode length: 741.16 +/- 250.04\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 741          |\n",
            "|    mean_reward          | 84.8         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 305000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075509334 |\n",
            "|    clip_fraction        | 0.0496       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.848       |\n",
            "|    explained_variance   | 0.764        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.4         |\n",
            "|    n_updates            | 1480         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 107          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 582      |\n",
            "|    ep_rew_mean     | 122      |\n",
            "| time/              |          |\n",
            "|    fps             | 225      |\n",
            "|    iterations      | 149      |\n",
            "|    time_elapsed    | 1353     |\n",
            "|    total_timesteps | 305152   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 589          |\n",
            "|    ep_rew_mean          | 122          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 226          |\n",
            "|    iterations           | 150          |\n",
            "|    time_elapsed         | 1354         |\n",
            "|    total_timesteps      | 307200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076670824 |\n",
            "|    clip_fraction        | 0.0845       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.759       |\n",
            "|    explained_variance   | 0.931        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 38.5         |\n",
            "|    n_updates            | 1490         |\n",
            "|    policy_gradient_loss | -0.00394     |\n",
            "|    value_loss           | 35.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 588          |\n",
            "|    ep_rew_mean          | 120          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 227          |\n",
            "|    iterations           | 151          |\n",
            "|    time_elapsed         | 1356         |\n",
            "|    total_timesteps      | 309248       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058314186 |\n",
            "|    clip_fraction        | 0.0596       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.736       |\n",
            "|    explained_variance   | 0.926        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.64         |\n",
            "|    n_updates            | 1500         |\n",
            "|    policy_gradient_loss | -0.0026      |\n",
            "|    value_loss           | 36           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=310000, episode_reward=45.15 +/- 117.28\n",
            "Episode length: 609.04 +/- 254.96\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 609         |\n",
            "|    mean_reward          | 45.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 310000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007144067 |\n",
            "|    clip_fraction        | 0.0526      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.808      |\n",
            "|    explained_variance   | 0.549       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 19.7        |\n",
            "|    n_updates            | 1510        |\n",
            "|    policy_gradient_loss | -0.0061     |\n",
            "|    value_loss           | 267         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 595      |\n",
            "|    ep_rew_mean     | 123      |\n",
            "| time/              |          |\n",
            "|    fps             | 226      |\n",
            "|    iterations      | 152      |\n",
            "|    time_elapsed    | 1374     |\n",
            "|    total_timesteps | 311296   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 598          |\n",
            "|    ep_rew_mean          | 124          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 227          |\n",
            "|    iterations           | 153          |\n",
            "|    time_elapsed         | 1376         |\n",
            "|    total_timesteps      | 313344       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075083612 |\n",
            "|    clip_fraction        | 0.07         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.858       |\n",
            "|    explained_variance   | 0.866        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.29         |\n",
            "|    n_updates            | 1520         |\n",
            "|    policy_gradient_loss | -0.0047      |\n",
            "|    value_loss           | 30.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=315000, episode_reward=102.53 +/- 107.84\n",
            "Episode length: 638.86 +/- 222.41\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 639         |\n",
            "|    mean_reward          | 103         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 315000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011704162 |\n",
            "|    clip_fraction        | 0.0969      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.781      |\n",
            "|    explained_variance   | 0.944       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.05        |\n",
            "|    n_updates            | 1530        |\n",
            "|    policy_gradient_loss | -0.00674    |\n",
            "|    value_loss           | 16.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 590      |\n",
            "|    ep_rew_mean     | 123      |\n",
            "| time/              |          |\n",
            "|    fps             | 226      |\n",
            "|    iterations      | 154      |\n",
            "|    time_elapsed    | 1394     |\n",
            "|    total_timesteps | 315392   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 585         |\n",
            "|    ep_rew_mean          | 127         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 227         |\n",
            "|    iterations           | 155         |\n",
            "|    time_elapsed         | 1396        |\n",
            "|    total_timesteps      | 317440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004036142 |\n",
            "|    clip_fraction        | 0.0343      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.751      |\n",
            "|    explained_variance   | 0.64        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 120         |\n",
            "|    n_updates            | 1540        |\n",
            "|    policy_gradient_loss | -0.00286    |\n",
            "|    value_loss           | 168         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 582         |\n",
            "|    ep_rew_mean          | 123         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 228         |\n",
            "|    iterations           | 156         |\n",
            "|    time_elapsed         | 1397        |\n",
            "|    total_timesteps      | 319488      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007900962 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.796      |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.57        |\n",
            "|    n_updates            | 1550        |\n",
            "|    policy_gradient_loss | -0.00469    |\n",
            "|    value_loss           | 26.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=320000, episode_reward=65.65 +/- 122.19\n",
            "Episode length: 478.96 +/- 191.04\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 479       |\n",
            "|    mean_reward          | 65.7      |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 320000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0048115 |\n",
            "|    clip_fraction        | 0.0487    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.755    |\n",
            "|    explained_variance   | 0.672     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.7       |\n",
            "|    n_updates            | 1560      |\n",
            "|    policy_gradient_loss | -0.00197  |\n",
            "|    value_loss           | 114       |\n",
            "---------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 583      |\n",
            "|    ep_rew_mean     | 128      |\n",
            "| time/              |          |\n",
            "|    fps             | 227      |\n",
            "|    iterations      | 157      |\n",
            "|    time_elapsed    | 1410     |\n",
            "|    total_timesteps | 321536   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 578         |\n",
            "|    ep_rew_mean          | 121         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 158         |\n",
            "|    time_elapsed         | 1411        |\n",
            "|    total_timesteps      | 323584      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007536901 |\n",
            "|    clip_fraction        | 0.0636      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.699      |\n",
            "|    explained_variance   | 0.722       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.5        |\n",
            "|    n_updates            | 1570        |\n",
            "|    policy_gradient_loss | -0.00285    |\n",
            "|    value_loss           | 62.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=325000, episode_reward=113.87 +/- 114.44\n",
            "Episode length: 507.38 +/- 198.41\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 507          |\n",
            "|    mean_reward          | 114          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 325000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053216647 |\n",
            "|    clip_fraction        | 0.0611       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.724       |\n",
            "|    explained_variance   | 0.619        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.2         |\n",
            "|    n_updates            | 1580         |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    value_loss           | 226          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 569      |\n",
            "|    ep_rew_mean     | 115      |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 159      |\n",
            "|    time_elapsed    | 1423     |\n",
            "|    total_timesteps | 325632   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 545          |\n",
            "|    ep_rew_mean          | 112          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 160          |\n",
            "|    time_elapsed         | 1425         |\n",
            "|    total_timesteps      | 327680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026896482 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.732       |\n",
            "|    explained_variance   | 0.612        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 50.8         |\n",
            "|    n_updates            | 1590         |\n",
            "|    policy_gradient_loss | -0.00271     |\n",
            "|    value_loss           | 167          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 543         |\n",
            "|    ep_rew_mean          | 114         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 161         |\n",
            "|    time_elapsed         | 1426        |\n",
            "|    total_timesteps      | 329728      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005512731 |\n",
            "|    clip_fraction        | 0.0414      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.708      |\n",
            "|    explained_variance   | 0.679       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 97.2        |\n",
            "|    n_updates            | 1600        |\n",
            "|    policy_gradient_loss | -0.00291    |\n",
            "|    value_loss           | 157         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=330000, episode_reward=91.94 +/- 109.72\n",
            "Episode length: 600.88 +/- 259.14\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 601       |\n",
            "|    mean_reward          | 91.9      |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 330000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0065286 |\n",
            "|    clip_fraction        | 0.0433    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.699    |\n",
            "|    explained_variance   | 0.747     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 24.1      |\n",
            "|    n_updates            | 1610      |\n",
            "|    policy_gradient_loss | -0.00291  |\n",
            "|    value_loss           | 112       |\n",
            "---------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 538      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 162      |\n",
            "|    time_elapsed    | 1444     |\n",
            "|    total_timesteps | 331776   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 521        |\n",
            "|    ep_rew_mean          | 117        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 230        |\n",
            "|    iterations           | 163        |\n",
            "|    time_elapsed         | 1445       |\n",
            "|    total_timesteps      | 333824     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00607682 |\n",
            "|    clip_fraction        | 0.0756     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.786     |\n",
            "|    explained_variance   | 0.828      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 28.9       |\n",
            "|    n_updates            | 1620       |\n",
            "|    policy_gradient_loss | -0.00514   |\n",
            "|    value_loss           | 113        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=335000, episode_reward=51.20 +/- 127.09\n",
            "Episode length: 569.94 +/- 275.25\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 570          |\n",
            "|    mean_reward          | 51.2         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 335000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049018376 |\n",
            "|    clip_fraction        | 0.031        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.693       |\n",
            "|    explained_variance   | 0.69         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14           |\n",
            "|    n_updates            | 1630         |\n",
            "|    policy_gradient_loss | -0.00464     |\n",
            "|    value_loss           | 180          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 518      |\n",
            "|    ep_rew_mean     | 115      |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 164      |\n",
            "|    time_elapsed    | 1461     |\n",
            "|    total_timesteps | 335872   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 514          |\n",
            "|    ep_rew_mean          | 118          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 165          |\n",
            "|    time_elapsed         | 1462         |\n",
            "|    total_timesteps      | 337920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042949524 |\n",
            "|    clip_fraction        | 0.0431       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.731       |\n",
            "|    explained_variance   | 0.816        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 58.3         |\n",
            "|    n_updates            | 1640         |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    value_loss           | 69.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 514         |\n",
            "|    ep_rew_mean          | 115         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 166         |\n",
            "|    time_elapsed         | 1464        |\n",
            "|    total_timesteps      | 339968      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005671308 |\n",
            "|    clip_fraction        | 0.0949      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.775      |\n",
            "|    explained_variance   | 0.536       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 38.4        |\n",
            "|    n_updates            | 1650        |\n",
            "|    policy_gradient_loss | -0.00215    |\n",
            "|    value_loss           | 112         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=340000, episode_reward=78.92 +/- 120.94\n",
            "Episode length: 622.86 +/- 241.15\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 623         |\n",
            "|    mean_reward          | 78.9        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 340000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018535111 |\n",
            "|    clip_fraction        | 0.0746      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.681      |\n",
            "|    explained_variance   | 0.751       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.56        |\n",
            "|    n_updates            | 1660        |\n",
            "|    policy_gradient_loss | -0.0065     |\n",
            "|    value_loss           | 124         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 510      |\n",
            "|    ep_rew_mean     | 109      |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 167      |\n",
            "|    time_elapsed    | 1482     |\n",
            "|    total_timesteps | 342016   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 508         |\n",
            "|    ep_rew_mean          | 105         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 168         |\n",
            "|    time_elapsed         | 1483        |\n",
            "|    total_timesteps      | 344064      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007410194 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.774      |\n",
            "|    explained_variance   | 0.772       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.4        |\n",
            "|    n_updates            | 1670        |\n",
            "|    policy_gradient_loss | -0.00692    |\n",
            "|    value_loss           | 139         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=345000, episode_reward=54.59 +/- 123.58\n",
            "Episode length: 667.96 +/- 293.56\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 668          |\n",
            "|    mean_reward          | 54.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 345000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060104616 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.693       |\n",
            "|    explained_variance   | 0.799        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.1          |\n",
            "|    n_updates            | 1680         |\n",
            "|    policy_gradient_loss | -0.00298     |\n",
            "|    value_loss           | 101          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 504      |\n",
            "|    ep_rew_mean     | 102      |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 169      |\n",
            "|    time_elapsed    | 1504     |\n",
            "|    total_timesteps | 346112   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 501          |\n",
            "|    ep_rew_mean          | 98.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 170          |\n",
            "|    time_elapsed         | 1505         |\n",
            "|    total_timesteps      | 348160       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043803602 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.756       |\n",
            "|    explained_variance   | 0.559        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.5         |\n",
            "|    n_updates            | 1690         |\n",
            "|    policy_gradient_loss | -0.00192     |\n",
            "|    value_loss           | 136          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=350000, episode_reward=37.83 +/- 107.52\n",
            "Episode length: 702.86 +/- 295.13\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 703         |\n",
            "|    mean_reward          | 37.8        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 350000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002600865 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.698      |\n",
            "|    explained_variance   | 0.693       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 65.6        |\n",
            "|    n_updates            | 1700        |\n",
            "|    policy_gradient_loss | -0.00201    |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 486      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 171      |\n",
            "|    time_elapsed    | 1527     |\n",
            "|    total_timesteps | 350208   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 482         |\n",
            "|    ep_rew_mean          | 93          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 230         |\n",
            "|    iterations           | 172         |\n",
            "|    time_elapsed         | 1528        |\n",
            "|    total_timesteps      | 352256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006339556 |\n",
            "|    clip_fraction        | 0.0703      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.743      |\n",
            "|    explained_variance   | 0.858       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 21.2        |\n",
            "|    n_updates            | 1710        |\n",
            "|    policy_gradient_loss | -0.00606    |\n",
            "|    value_loss           | 91.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 482         |\n",
            "|    ep_rew_mean          | 88.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 173         |\n",
            "|    time_elapsed         | 1529        |\n",
            "|    total_timesteps      | 354304      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003088943 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.73       |\n",
            "|    explained_variance   | 0.73        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 104         |\n",
            "|    n_updates            | 1720        |\n",
            "|    policy_gradient_loss | -0.00348    |\n",
            "|    value_loss           | 145         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=355000, episode_reward=74.27 +/- 110.03\n",
            "Episode length: 648.24 +/- 253.02\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 648       |\n",
            "|    mean_reward          | 74.3      |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 355000    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0100048 |\n",
            "|    clip_fraction        | 0.119     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.76     |\n",
            "|    explained_variance   | 0.868     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.42      |\n",
            "|    n_updates            | 1730      |\n",
            "|    policy_gradient_loss | -0.00168  |\n",
            "|    value_loss           | 29.1      |\n",
            "---------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 481      |\n",
            "|    ep_rew_mean     | 90.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 174      |\n",
            "|    time_elapsed    | 1548     |\n",
            "|    total_timesteps | 356352   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 478          |\n",
            "|    ep_rew_mean          | 86.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 175          |\n",
            "|    time_elapsed         | 1550         |\n",
            "|    total_timesteps      | 358400       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044631353 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.74        |\n",
            "|    explained_variance   | 0.86         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.8         |\n",
            "|    n_updates            | 1740         |\n",
            "|    policy_gradient_loss | -0.00351     |\n",
            "|    value_loss           | 65.1         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=360000, episode_reward=40.07 +/- 118.60\n",
            "Episode length: 592.44 +/- 262.57\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 592         |\n",
            "|    mean_reward          | 40.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 360000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002533223 |\n",
            "|    clip_fraction        | 0.0162      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.47        |\n",
            "|    n_updates            | 1750        |\n",
            "|    policy_gradient_loss | -0.00187    |\n",
            "|    value_loss           | 95.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 468      |\n",
            "|    ep_rew_mean     | 86.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 176      |\n",
            "|    time_elapsed    | 1566     |\n",
            "|    total_timesteps | 360448   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 473          |\n",
            "|    ep_rew_mean          | 83.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 177          |\n",
            "|    time_elapsed         | 1568         |\n",
            "|    total_timesteps      | 362496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040470418 |\n",
            "|    clip_fraction        | 0.0466       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.715       |\n",
            "|    explained_variance   | 0.807        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.7         |\n",
            "|    n_updates            | 1760         |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    value_loss           | 131          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 478          |\n",
            "|    ep_rew_mean          | 77.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 178          |\n",
            "|    time_elapsed         | 1570         |\n",
            "|    total_timesteps      | 364544       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053981813 |\n",
            "|    clip_fraction        | 0.0622       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.685       |\n",
            "|    explained_variance   | 0.897        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.7          |\n",
            "|    n_updates            | 1770         |\n",
            "|    policy_gradient_loss | -0.00354     |\n",
            "|    value_loss           | 67.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=365000, episode_reward=45.71 +/- 113.78\n",
            "Episode length: 692.68 +/- 231.81\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 693         |\n",
            "|    mean_reward          | 45.7        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 365000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007656562 |\n",
            "|    clip_fraction        | 0.0401      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.765      |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20          |\n",
            "|    n_updates            | 1780        |\n",
            "|    policy_gradient_loss | -0.00214    |\n",
            "|    value_loss           | 85.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 475      |\n",
            "|    ep_rew_mean     | 80       |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 179      |\n",
            "|    time_elapsed    | 1592     |\n",
            "|    total_timesteps | 366592   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 469         |\n",
            "|    ep_rew_mean          | 77.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 180         |\n",
            "|    time_elapsed         | 1593        |\n",
            "|    total_timesteps      | 368640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011025451 |\n",
            "|    clip_fraction        | 0.081       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.758      |\n",
            "|    explained_variance   | 0.791       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 18.1        |\n",
            "|    n_updates            | 1790        |\n",
            "|    policy_gradient_loss | -0.00368    |\n",
            "|    value_loss           | 85.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=370000, episode_reward=29.90 +/- 106.94\n",
            "Episode length: 709.30 +/- 277.66\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 709          |\n",
            "|    mean_reward          | 29.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 370000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027389824 |\n",
            "|    clip_fraction        | 0.0312       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.717       |\n",
            "|    explained_variance   | 0.625        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 31.1         |\n",
            "|    n_updates            | 1800         |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 174          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 475      |\n",
            "|    ep_rew_mean     | 83.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 181      |\n",
            "|    time_elapsed    | 1617     |\n",
            "|    total_timesteps | 370688   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 483          |\n",
            "|    ep_rew_mean          | 84.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 182          |\n",
            "|    time_elapsed         | 1618         |\n",
            "|    total_timesteps      | 372736       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0069701592 |\n",
            "|    clip_fraction        | 0.0695       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.757       |\n",
            "|    explained_variance   | 0.872        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.78         |\n",
            "|    n_updates            | 1810         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 49.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 490          |\n",
            "|    ep_rew_mean          | 85.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 183          |\n",
            "|    time_elapsed         | 1620         |\n",
            "|    total_timesteps      | 374784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048673265 |\n",
            "|    clip_fraction        | 0.0588       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.828       |\n",
            "|    explained_variance   | 0.876        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 64           |\n",
            "|    n_updates            | 1820         |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    value_loss           | 73.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=375000, episode_reward=21.89 +/- 109.52\n",
            "Episode length: 742.84 +/- 230.61\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 743          |\n",
            "|    mean_reward          | 21.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 375000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070144143 |\n",
            "|    clip_fraction        | 0.0765       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.635       |\n",
            "|    explained_variance   | 0.847        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 36.1         |\n",
            "|    n_updates            | 1830         |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 62.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 499      |\n",
            "|    ep_rew_mean     | 88.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 184      |\n",
            "|    time_elapsed    | 1645     |\n",
            "|    total_timesteps | 376832   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 501         |\n",
            "|    ep_rew_mean          | 90.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 230         |\n",
            "|    iterations           | 185         |\n",
            "|    time_elapsed         | 1646        |\n",
            "|    total_timesteps      | 378880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009260357 |\n",
            "|    clip_fraction        | 0.0683      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.675      |\n",
            "|    explained_variance   | 0.894       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.59        |\n",
            "|    n_updates            | 1840        |\n",
            "|    policy_gradient_loss | -0.00339    |\n",
            "|    value_loss           | 55.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=380000, episode_reward=48.66 +/- 106.34\n",
            "Episode length: 737.16 +/- 239.22\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 737         |\n",
            "|    mean_reward          | 48.7        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 380000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010716815 |\n",
            "|    clip_fraction        | 0.0878      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.7        |\n",
            "|    n_updates            | 1850        |\n",
            "|    policy_gradient_loss | -0.00326    |\n",
            "|    value_loss           | 76.5        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 505      |\n",
            "|    ep_rew_mean     | 91.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 186      |\n",
            "|    time_elapsed    | 1670     |\n",
            "|    total_timesteps | 380928   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 509          |\n",
            "|    ep_rew_mean          | 93.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 187          |\n",
            "|    time_elapsed         | 1671         |\n",
            "|    total_timesteps      | 382976       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045400783 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.697       |\n",
            "|    explained_variance   | 0.809        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 19.6         |\n",
            "|    n_updates            | 1860         |\n",
            "|    policy_gradient_loss | -0.00115     |\n",
            "|    value_loss           | 35.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=385000, episode_reward=72.54 +/- 126.87\n",
            "Episode length: 639.84 +/- 209.95\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 640          |\n",
            "|    mean_reward          | 72.5         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 385000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067733685 |\n",
            "|    clip_fraction        | 0.0625       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.749       |\n",
            "|    explained_variance   | 0.88         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.5          |\n",
            "|    n_updates            | 1870         |\n",
            "|    policy_gradient_loss | -0.00408     |\n",
            "|    value_loss           | 64.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 516      |\n",
            "|    ep_rew_mean     | 89.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 227      |\n",
            "|    iterations      | 188      |\n",
            "|    time_elapsed    | 1689     |\n",
            "|    total_timesteps | 385024   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 523         |\n",
            "|    ep_rew_mean          | 84.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 228         |\n",
            "|    iterations           | 189         |\n",
            "|    time_elapsed         | 1691        |\n",
            "|    total_timesteps      | 387072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005031633 |\n",
            "|    clip_fraction        | 0.0651      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.735      |\n",
            "|    explained_variance   | 0.78        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 34.8        |\n",
            "|    n_updates            | 1880        |\n",
            "|    policy_gradient_loss | -0.00306    |\n",
            "|    value_loss           | 124         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 531          |\n",
            "|    ep_rew_mean          | 87.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 190          |\n",
            "|    time_elapsed         | 1693         |\n",
            "|    total_timesteps      | 389120       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0071871774 |\n",
            "|    clip_fraction        | 0.0875       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.75        |\n",
            "|    explained_variance   | 0.896        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.7         |\n",
            "|    n_updates            | 1890         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    value_loss           | 61.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=390000, episode_reward=51.02 +/- 119.06\n",
            "Episode length: 696.28 +/- 221.70\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 696         |\n",
            "|    mean_reward          | 51          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 390000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012358958 |\n",
            "|    clip_fraction        | 0.0855      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.744      |\n",
            "|    explained_variance   | 0.923       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.88        |\n",
            "|    n_updates            | 1900        |\n",
            "|    policy_gradient_loss | -0.00127    |\n",
            "|    value_loss           | 17.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 533      |\n",
            "|    ep_rew_mean     | 83.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 191      |\n",
            "|    time_elapsed    | 1715     |\n",
            "|    total_timesteps | 391168   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 532         |\n",
            "|    ep_rew_mean          | 81          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 228         |\n",
            "|    iterations           | 192         |\n",
            "|    time_elapsed         | 1717        |\n",
            "|    total_timesteps      | 393216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009467358 |\n",
            "|    clip_fraction        | 0.0697      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.801      |\n",
            "|    explained_variance   | 0.772       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 24.8        |\n",
            "|    n_updates            | 1910        |\n",
            "|    policy_gradient_loss | -0.00279    |\n",
            "|    value_loss           | 76.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=395000, episode_reward=39.80 +/- 125.43\n",
            "Episode length: 651.98 +/- 236.46\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 652         |\n",
            "|    mean_reward          | 39.8        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 395000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003744564 |\n",
            "|    clip_fraction        | 0.0431      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.74       |\n",
            "|    explained_variance   | 0.878       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 36.1        |\n",
            "|    n_updates            | 1920        |\n",
            "|    policy_gradient_loss | -0.00187    |\n",
            "|    value_loss           | 82.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 536      |\n",
            "|    ep_rew_mean     | 83.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 227      |\n",
            "|    iterations      | 193      |\n",
            "|    time_elapsed    | 1736     |\n",
            "|    total_timesteps | 395264   |\n",
            "---------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 535       |\n",
            "|    ep_rew_mean          | 89.9      |\n",
            "| time/                   |           |\n",
            "|    fps                  | 228       |\n",
            "|    iterations           | 194       |\n",
            "|    time_elapsed         | 1738      |\n",
            "|    total_timesteps      | 397312    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0072992 |\n",
            "|    clip_fraction        | 0.109     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.725    |\n",
            "|    explained_variance   | 0.894     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 18.1      |\n",
            "|    n_updates            | 1930      |\n",
            "|    policy_gradient_loss | -0.00193  |\n",
            "|    value_loss           | 48.6      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 539         |\n",
            "|    ep_rew_mean          | 88.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 195         |\n",
            "|    time_elapsed         | 1740        |\n",
            "|    total_timesteps      | 399360      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007234712 |\n",
            "|    clip_fraction        | 0.0762      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.736      |\n",
            "|    explained_variance   | 0.973       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.83        |\n",
            "|    n_updates            | 1940        |\n",
            "|    policy_gradient_loss | -0.00554    |\n",
            "|    value_loss           | 15.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=400000, episode_reward=32.74 +/- 128.86\n",
            "Episode length: 619.26 +/- 288.30\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 619         |\n",
            "|    mean_reward          | 32.7        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 400000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016674649 |\n",
            "|    clip_fraction        | 0.0981      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.712      |\n",
            "|    explained_variance   | 0.832       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 142         |\n",
            "|    n_updates            | 1950        |\n",
            "|    policy_gradient_loss | -0.00782    |\n",
            "|    value_loss           | 115         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 545      |\n",
            "|    ep_rew_mean     | 88.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 196      |\n",
            "|    time_elapsed    | 1758     |\n",
            "|    total_timesteps | 401408   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 543         |\n",
            "|    ep_rew_mean          | 80.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 229         |\n",
            "|    iterations           | 197         |\n",
            "|    time_elapsed         | 1759        |\n",
            "|    total_timesteps      | 403456      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009724895 |\n",
            "|    clip_fraction        | 0.0896      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.793      |\n",
            "|    explained_variance   | 0.913       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.08        |\n",
            "|    n_updates            | 1960        |\n",
            "|    policy_gradient_loss | -0.00121    |\n",
            "|    value_loss           | 52.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=405000, episode_reward=62.61 +/- 141.63\n",
            "Episode length: 526.54 +/- 251.03\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 527          |\n",
            "|    mean_reward          | 62.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 405000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035702824 |\n",
            "|    clip_fraction        | 0.046        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.749       |\n",
            "|    explained_variance   | 0.813        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 83.1         |\n",
            "|    n_updates            | 1970         |\n",
            "|    policy_gradient_loss | -0.00275     |\n",
            "|    value_loss           | 94.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 544      |\n",
            "|    ep_rew_mean     | 81.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 228      |\n",
            "|    iterations      | 198      |\n",
            "|    time_elapsed    | 1774     |\n",
            "|    total_timesteps | 405504   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 551          |\n",
            "|    ep_rew_mean          | 82.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 229          |\n",
            "|    iterations           | 199          |\n",
            "|    time_elapsed         | 1775         |\n",
            "|    total_timesteps      | 407552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053047277 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.784       |\n",
            "|    explained_variance   | 0.617        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 56.8         |\n",
            "|    n_updates            | 1980         |\n",
            "|    policy_gradient_loss | -0.00314     |\n",
            "|    value_loss           | 112          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 545         |\n",
            "|    ep_rew_mean          | 84.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 230         |\n",
            "|    iterations           | 200         |\n",
            "|    time_elapsed         | 1777        |\n",
            "|    total_timesteps      | 409600      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010078056 |\n",
            "|    clip_fraction        | 0.0707      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.816      |\n",
            "|    explained_variance   | 0.907       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.17        |\n",
            "|    n_updates            | 1990        |\n",
            "|    policy_gradient_loss | -0.00346    |\n",
            "|    value_loss           | 36.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=410000, episode_reward=21.85 +/- 127.33\n",
            "Episode length: 540.48 +/- 270.01\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 540         |\n",
            "|    mean_reward          | 21.8        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 410000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008223645 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.759      |\n",
            "|    explained_variance   | 0.929       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.4        |\n",
            "|    n_updates            | 2000        |\n",
            "|    policy_gradient_loss | -0.00839    |\n",
            "|    value_loss           | 47.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 549      |\n",
            "|    ep_rew_mean     | 82.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 229      |\n",
            "|    iterations      | 201      |\n",
            "|    time_elapsed    | 1792     |\n",
            "|    total_timesteps | 411648   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 543          |\n",
            "|    ep_rew_mean          | 78.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 230          |\n",
            "|    iterations           | 202          |\n",
            "|    time_elapsed         | 1794         |\n",
            "|    total_timesteps      | 413696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031647836 |\n",
            "|    clip_fraction        | 0.0179       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 0.807        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.6         |\n",
            "|    n_updates            | 2010         |\n",
            "|    policy_gradient_loss | -0.00139     |\n",
            "|    value_loss           | 111          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=415000, episode_reward=9.20 +/- 127.27\n",
            "Episode length: 431.58 +/- 200.82\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 432          |\n",
            "|    mean_reward          | 9.2          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 415000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056640003 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.788       |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.9         |\n",
            "|    n_updates            | 2020         |\n",
            "|    policy_gradient_loss | -0.00132     |\n",
            "|    value_loss           | 74.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 547      |\n",
            "|    ep_rew_mean     | 78.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 203      |\n",
            "|    time_elapsed    | 1804     |\n",
            "|    total_timesteps | 415744   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 541          |\n",
            "|    ep_rew_mean          | 76.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 204          |\n",
            "|    time_elapsed         | 1805         |\n",
            "|    total_timesteps      | 417792       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075478796 |\n",
            "|    clip_fraction        | 0.0928       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.761       |\n",
            "|    explained_variance   | 0.759        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.7         |\n",
            "|    n_updates            | 2030         |\n",
            "|    policy_gradient_loss | -0.00396     |\n",
            "|    value_loss           | 121          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 540         |\n",
            "|    ep_rew_mean          | 68.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 205         |\n",
            "|    time_elapsed         | 1807        |\n",
            "|    total_timesteps      | 419840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005509716 |\n",
            "|    clip_fraction        | 0.0717      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.743      |\n",
            "|    explained_variance   | 0.884       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.2        |\n",
            "|    n_updates            | 2040        |\n",
            "|    policy_gradient_loss | -0.00289    |\n",
            "|    value_loss           | 72.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=420000, episode_reward=38.59 +/- 123.84\n",
            "Episode length: 617.26 +/- 253.40\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 617          |\n",
            "|    mean_reward          | 38.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 420000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065355874 |\n",
            "|    clip_fraction        | 0.0732       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.829       |\n",
            "|    explained_variance   | 0.742        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 43.1         |\n",
            "|    n_updates            | 2050         |\n",
            "|    policy_gradient_loss | -0.005       |\n",
            "|    value_loss           | 66.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 546      |\n",
            "|    ep_rew_mean     | 71.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 231      |\n",
            "|    iterations      | 206      |\n",
            "|    time_elapsed    | 1824     |\n",
            "|    total_timesteps | 421888   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 547          |\n",
            "|    ep_rew_mean          | 71.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 207          |\n",
            "|    time_elapsed         | 1826         |\n",
            "|    total_timesteps      | 423936       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0067952983 |\n",
            "|    clip_fraction        | 0.0395       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.743       |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 65           |\n",
            "|    n_updates            | 2060         |\n",
            "|    policy_gradient_loss | -0.00174     |\n",
            "|    value_loss           | 121          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=425000, episode_reward=16.12 +/- 107.97\n",
            "Episode length: 647.04 +/- 293.06\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 647          |\n",
            "|    mean_reward          | 16.1         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 425000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070949197 |\n",
            "|    clip_fraction        | 0.0526       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.697       |\n",
            "|    explained_variance   | 0.847        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 19.9         |\n",
            "|    n_updates            | 2070         |\n",
            "|    policy_gradient_loss | -0.00479     |\n",
            "|    value_loss           | 80           |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 538      |\n",
            "|    ep_rew_mean     | 69.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 208      |\n",
            "|    time_elapsed    | 1845     |\n",
            "|    total_timesteps | 425984   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 544        |\n",
            "|    ep_rew_mean          | 71.7       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 231        |\n",
            "|    iterations           | 209        |\n",
            "|    time_elapsed         | 1847       |\n",
            "|    total_timesteps      | 428032     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01227868 |\n",
            "|    clip_fraction        | 0.0886     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.736     |\n",
            "|    explained_variance   | 0.644      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 161        |\n",
            "|    n_updates            | 2080       |\n",
            "|    policy_gradient_loss | -0.00308   |\n",
            "|    value_loss           | 208        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=430000, episode_reward=18.15 +/- 103.13\n",
            "Episode length: 667.78 +/- 275.53\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 668          |\n",
            "|    mean_reward          | 18.2         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 430000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054656146 |\n",
            "|    clip_fraction        | 0.0794       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.749       |\n",
            "|    explained_variance   | 0.897        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.46         |\n",
            "|    n_updates            | 2090         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    value_loss           | 19.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 545      |\n",
            "|    ep_rew_mean     | 69.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 210      |\n",
            "|    time_elapsed    | 1868     |\n",
            "|    total_timesteps | 430080   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 543          |\n",
            "|    ep_rew_mean          | 60.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 211          |\n",
            "|    time_elapsed         | 1869         |\n",
            "|    total_timesteps      | 432128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070944796 |\n",
            "|    clip_fraction        | 0.0787       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.76        |\n",
            "|    explained_variance   | 0.891        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 65.5         |\n",
            "|    n_updates            | 2100         |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    value_loss           | 62.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 535          |\n",
            "|    ep_rew_mean          | 54.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 212          |\n",
            "|    time_elapsed         | 1871         |\n",
            "|    total_timesteps      | 434176       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050661582 |\n",
            "|    clip_fraction        | 0.029        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.709       |\n",
            "|    explained_variance   | 0.731        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 30           |\n",
            "|    n_updates            | 2110         |\n",
            "|    policy_gradient_loss | -0.00143     |\n",
            "|    value_loss           | 149          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=435000, episode_reward=22.29 +/- 99.91\n",
            "Episode length: 679.78 +/- 276.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 680         |\n",
            "|    mean_reward          | 22.3        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 435000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011722759 |\n",
            "|    clip_fraction        | 0.0853      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.733      |\n",
            "|    explained_variance   | 0.658       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 53.3        |\n",
            "|    n_updates            | 2120        |\n",
            "|    policy_gradient_loss | -0.00586    |\n",
            "|    value_loss           | 118         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 544      |\n",
            "|    ep_rew_mean     | 50.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 213      |\n",
            "|    time_elapsed    | 1892     |\n",
            "|    total_timesteps | 436224   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 546         |\n",
            "|    ep_rew_mean          | 56.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 214         |\n",
            "|    time_elapsed         | 1894        |\n",
            "|    total_timesteps      | 438272      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015894629 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.786      |\n",
            "|    explained_variance   | 0.845       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.65        |\n",
            "|    n_updates            | 2130        |\n",
            "|    policy_gradient_loss | -0.00682    |\n",
            "|    value_loss           | 37.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=440000, episode_reward=38.08 +/- 121.20\n",
            "Episode length: 638.96 +/- 262.36\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 639         |\n",
            "|    mean_reward          | 38.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 440000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003503159 |\n",
            "|    clip_fraction        | 0.05        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.706      |\n",
            "|    explained_variance   | 0.793       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.1        |\n",
            "|    n_updates            | 2140        |\n",
            "|    policy_gradient_loss | -0.0032     |\n",
            "|    value_loss           | 77.4        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 545      |\n",
            "|    ep_rew_mean     | 51.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 215      |\n",
            "|    time_elapsed    | 1914     |\n",
            "|    total_timesteps | 440320   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 550        |\n",
            "|    ep_rew_mean          | 55.8       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 230        |\n",
            "|    iterations           | 216        |\n",
            "|    time_elapsed         | 1915       |\n",
            "|    total_timesteps      | 442368     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00563551 |\n",
            "|    clip_fraction        | 0.0544     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.671     |\n",
            "|    explained_variance   | 0.661      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 100        |\n",
            "|    n_updates            | 2150       |\n",
            "|    policy_gradient_loss | -0.00775   |\n",
            "|    value_loss           | 120        |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 550          |\n",
            "|    ep_rew_mean          | 53.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 217          |\n",
            "|    time_elapsed         | 1917         |\n",
            "|    total_timesteps      | 444416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077644335 |\n",
            "|    clip_fraction        | 0.0756       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.841       |\n",
            "|    explained_variance   | 0.883        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.67         |\n",
            "|    n_updates            | 2160         |\n",
            "|    policy_gradient_loss | -0.00239     |\n",
            "|    value_loss           | 32.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=445000, episode_reward=69.97 +/- 106.51\n",
            "Episode length: 652.38 +/- 259.81\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 652          |\n",
            "|    mean_reward          | 70           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 445000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027626292 |\n",
            "|    clip_fraction        | 0.0689       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.811       |\n",
            "|    explained_variance   | 0.844        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.7         |\n",
            "|    n_updates            | 2170         |\n",
            "|    policy_gradient_loss | -0.000659    |\n",
            "|    value_loss           | 62.7         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 551      |\n",
            "|    ep_rew_mean     | 60.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 218      |\n",
            "|    time_elapsed    | 1934     |\n",
            "|    total_timesteps | 446464   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 557         |\n",
            "|    ep_rew_mean          | 61.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 231         |\n",
            "|    iterations           | 219         |\n",
            "|    time_elapsed         | 1936        |\n",
            "|    total_timesteps      | 448512      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007299451 |\n",
            "|    clip_fraction        | 0.0821      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.779      |\n",
            "|    explained_variance   | 0.962       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.28        |\n",
            "|    n_updates            | 2180        |\n",
            "|    policy_gradient_loss | -0.00339    |\n",
            "|    value_loss           | 13.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=450000, episode_reward=77.60 +/- 108.91\n",
            "Episode length: 670.12 +/- 262.14\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 670          |\n",
            "|    mean_reward          | 77.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 450000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063357726 |\n",
            "|    clip_fraction        | 0.0663       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.855       |\n",
            "|    explained_variance   | 0.908        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.08         |\n",
            "|    n_updates            | 2190         |\n",
            "|    policy_gradient_loss | -0.00114     |\n",
            "|    value_loss           | 27.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 560      |\n",
            "|    ep_rew_mean     | 60.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 230      |\n",
            "|    iterations      | 220      |\n",
            "|    time_elapsed    | 1954     |\n",
            "|    total_timesteps | 450560   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 560          |\n",
            "|    ep_rew_mean          | 59.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 231          |\n",
            "|    iterations           | 221          |\n",
            "|    time_elapsed         | 1956         |\n",
            "|    total_timesteps      | 452608       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027389247 |\n",
            "|    clip_fraction        | 0.0133       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.694       |\n",
            "|    explained_variance   | 0.836        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.76         |\n",
            "|    n_updates            | 2200         |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    value_loss           | 41.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 557         |\n",
            "|    ep_rew_mean          | 57.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 222         |\n",
            "|    time_elapsed         | 1957        |\n",
            "|    total_timesteps      | 454656      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004002787 |\n",
            "|    clip_fraction        | 0.0208      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.735      |\n",
            "|    explained_variance   | 0.625       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27.6        |\n",
            "|    n_updates            | 2210        |\n",
            "|    policy_gradient_loss | -0.00149    |\n",
            "|    value_loss           | 150         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=455000, episode_reward=98.02 +/- 100.49\n",
            "Episode length: 582.76 +/- 249.22\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 583          |\n",
            "|    mean_reward          | 98           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 455000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045110644 |\n",
            "|    clip_fraction        | 0.0567       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.812       |\n",
            "|    explained_variance   | 0.866        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.08         |\n",
            "|    n_updates            | 2220         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    value_loss           | 64.7         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 546      |\n",
            "|    ep_rew_mean     | 66       |\n",
            "| time/              |          |\n",
            "|    fps             | 231      |\n",
            "|    iterations      | 223      |\n",
            "|    time_elapsed    | 1972     |\n",
            "|    total_timesteps | 456704   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 560          |\n",
            "|    ep_rew_mean          | 69.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 232          |\n",
            "|    iterations           | 224          |\n",
            "|    time_elapsed         | 1974         |\n",
            "|    total_timesteps      | 458752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051564407 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.708       |\n",
            "|    explained_variance   | 0.857        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.5         |\n",
            "|    n_updates            | 2230         |\n",
            "|    policy_gradient_loss | -0.00162     |\n",
            "|    value_loss           | 78.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=460000, episode_reward=45.58 +/- 118.94\n",
            "Episode length: 634.44 +/- 260.73\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 634          |\n",
            "|    mean_reward          | 45.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 460000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0079916045 |\n",
            "|    clip_fraction        | 0.076        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.683       |\n",
            "|    explained_variance   | 0.875        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.6          |\n",
            "|    n_updates            | 2240         |\n",
            "|    policy_gradient_loss | 0.000384     |\n",
            "|    value_loss           | 21.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 547      |\n",
            "|    ep_rew_mean     | 73.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 231      |\n",
            "|    iterations      | 225      |\n",
            "|    time_elapsed    | 1991     |\n",
            "|    total_timesteps | 460800   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 549         |\n",
            "|    ep_rew_mean          | 74.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 226         |\n",
            "|    time_elapsed         | 1993        |\n",
            "|    total_timesteps      | 462848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008014525 |\n",
            "|    clip_fraction        | 0.0852      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.751      |\n",
            "|    explained_variance   | 0.825       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.5        |\n",
            "|    n_updates            | 2250        |\n",
            "|    policy_gradient_loss | -0.00139    |\n",
            "|    value_loss           | 85          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 552         |\n",
            "|    ep_rew_mean          | 75.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 233         |\n",
            "|    iterations           | 227         |\n",
            "|    time_elapsed         | 1994        |\n",
            "|    total_timesteps      | 464896      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005435865 |\n",
            "|    clip_fraction        | 0.0565      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.703      |\n",
            "|    explained_variance   | 0.951       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.79        |\n",
            "|    n_updates            | 2260        |\n",
            "|    policy_gradient_loss | -0.002      |\n",
            "|    value_loss           | 27.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=465000, episode_reward=123.89 +/- 96.03\n",
            "Episode length: 602.30 +/- 262.63\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 602         |\n",
            "|    mean_reward          | 124         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 465000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008112716 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.846      |\n",
            "|    explained_variance   | 0.957       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.22        |\n",
            "|    n_updates            | 2270        |\n",
            "|    policy_gradient_loss | -0.0033     |\n",
            "|    value_loss           | 18.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 554      |\n",
            "|    ep_rew_mean     | 70.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 228      |\n",
            "|    time_elapsed    | 2010     |\n",
            "|    total_timesteps | 466944   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 558          |\n",
            "|    ep_rew_mean          | 79.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 229          |\n",
            "|    time_elapsed         | 2012         |\n",
            "|    total_timesteps      | 468992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068285093 |\n",
            "|    clip_fraction        | 0.0426       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.749       |\n",
            "|    explained_variance   | 0.667        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.3         |\n",
            "|    n_updates            | 2280         |\n",
            "|    policy_gradient_loss | -0.0057      |\n",
            "|    value_loss           | 89.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=470000, episode_reward=95.56 +/- 108.80\n",
            "Episode length: 586.86 +/- 267.63\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 587         |\n",
            "|    mean_reward          | 95.6        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 470000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005527098 |\n",
            "|    clip_fraction        | 0.043       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.709      |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.67        |\n",
            "|    n_updates            | 2290        |\n",
            "|    policy_gradient_loss | -0.00261    |\n",
            "|    value_loss           | 17.4        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 556      |\n",
            "|    ep_rew_mean     | 86.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 230      |\n",
            "|    time_elapsed    | 2028     |\n",
            "|    total_timesteps | 471040   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 564          |\n",
            "|    ep_rew_mean          | 89           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 231          |\n",
            "|    time_elapsed         | 2029         |\n",
            "|    total_timesteps      | 473088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055852504 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.682       |\n",
            "|    explained_variance   | 0.884        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.7         |\n",
            "|    n_updates            | 2300         |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    value_loss           | 47.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=475000, episode_reward=112.01 +/- 95.02\n",
            "Episode length: 647.00 +/- 255.43\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 647          |\n",
            "|    mean_reward          | 112          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 475000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046723033 |\n",
            "|    clip_fraction        | 0.11         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | 0.914        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 25.5         |\n",
            "|    n_updates            | 2310         |\n",
            "|    policy_gradient_loss | -0.00437     |\n",
            "|    value_loss           | 32           |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 564      |\n",
            "|    ep_rew_mean     | 93.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 232      |\n",
            "|    time_elapsed    | 2047     |\n",
            "|    total_timesteps | 475136   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 564         |\n",
            "|    ep_rew_mean          | 96.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 232         |\n",
            "|    iterations           | 233         |\n",
            "|    time_elapsed         | 2049        |\n",
            "|    total_timesteps      | 477184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010597652 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.703      |\n",
            "|    explained_variance   | 0.867       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.74        |\n",
            "|    n_updates            | 2320        |\n",
            "|    policy_gradient_loss | -0.00677    |\n",
            "|    value_loss           | 42.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 559         |\n",
            "|    ep_rew_mean          | 100         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 233         |\n",
            "|    iterations           | 234         |\n",
            "|    time_elapsed         | 2051        |\n",
            "|    total_timesteps      | 479232      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005729084 |\n",
            "|    clip_fraction        | 0.0683      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.736      |\n",
            "|    explained_variance   | 0.922       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.2        |\n",
            "|    n_updates            | 2330        |\n",
            "|    policy_gradient_loss | 2.34e-05    |\n",
            "|    value_loss           | 45.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=480000, episode_reward=102.01 +/- 116.92\n",
            "Episode length: 564.98 +/- 231.22\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 565          |\n",
            "|    mean_reward          | 102          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 480000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041512577 |\n",
            "|    clip_fraction        | 0.0246       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.591       |\n",
            "|    explained_variance   | 0.842        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 23.1         |\n",
            "|    n_updates            | 2340         |\n",
            "|    policy_gradient_loss | -0.00237     |\n",
            "|    value_loss           | 80           |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 561      |\n",
            "|    ep_rew_mean     | 99.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 232      |\n",
            "|    iterations      | 235      |\n",
            "|    time_elapsed    | 2066     |\n",
            "|    total_timesteps | 481280   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 545         |\n",
            "|    ep_rew_mean          | 92          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 233         |\n",
            "|    iterations           | 236         |\n",
            "|    time_elapsed         | 2068        |\n",
            "|    total_timesteps      | 483328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012187944 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.636      |\n",
            "|    explained_variance   | 0.896       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.3        |\n",
            "|    n_updates            | 2350        |\n",
            "|    policy_gradient_loss | -0.00126    |\n",
            "|    value_loss           | 65.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=485000, episode_reward=126.38 +/- 101.74\n",
            "Episode length: 563.30 +/- 220.86\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 563          |\n",
            "|    mean_reward          | 126          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 485000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052193915 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.708       |\n",
            "|    explained_variance   | 0.875        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.54         |\n",
            "|    n_updates            | 2360         |\n",
            "|    policy_gradient_loss | -0.00121     |\n",
            "|    value_loss           | 87.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 545      |\n",
            "|    ep_rew_mean     | 90.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 237      |\n",
            "|    time_elapsed    | 2082     |\n",
            "|    total_timesteps | 485376   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 550          |\n",
            "|    ep_rew_mean          | 90.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 233          |\n",
            "|    iterations           | 238          |\n",
            "|    time_elapsed         | 2084         |\n",
            "|    total_timesteps      | 487424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048935106 |\n",
            "|    clip_fraction        | 0.0207       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.721       |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17           |\n",
            "|    n_updates            | 2370         |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    value_loss           | 177          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 545         |\n",
            "|    ep_rew_mean          | 95.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 234         |\n",
            "|    iterations           | 239         |\n",
            "|    time_elapsed         | 2086        |\n",
            "|    total_timesteps      | 489472      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010736137 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 0.87        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 19.8        |\n",
            "|    n_updates            | 2380        |\n",
            "|    policy_gradient_loss | -0.00445    |\n",
            "|    value_loss           | 63.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=490000, episode_reward=96.28 +/- 107.22\n",
            "Episode length: 637.56 +/- 252.42\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 638          |\n",
            "|    mean_reward          | 96.3         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 490000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064378805 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.597       |\n",
            "|    explained_variance   | 0.752        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 125          |\n",
            "|    n_updates            | 2390         |\n",
            "|    policy_gradient_loss | -0.00366     |\n",
            "|    value_loss           | 151          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 549      |\n",
            "|    ep_rew_mean     | 100      |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 240      |\n",
            "|    time_elapsed    | 2103     |\n",
            "|    total_timesteps | 491520   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 544          |\n",
            "|    ep_rew_mean          | 99.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 234          |\n",
            "|    iterations           | 241          |\n",
            "|    time_elapsed         | 2105         |\n",
            "|    total_timesteps      | 493568       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035820934 |\n",
            "|    clip_fraction        | 0.0256       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.611       |\n",
            "|    explained_variance   | 0.685        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 68.4         |\n",
            "|    n_updates            | 2400         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 97.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=495000, episode_reward=135.70 +/- 95.81\n",
            "Episode length: 572.22 +/- 187.95\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 572         |\n",
            "|    mean_reward          | 136         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 495000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.048654325 |\n",
            "|    clip_fraction        | 0.133       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.594      |\n",
            "|    explained_variance   | 0.818       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14.1        |\n",
            "|    n_updates            | 2410        |\n",
            "|    policy_gradient_loss | -0.00775    |\n",
            "|    value_loss           | 62.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 554      |\n",
            "|    ep_rew_mean     | 103      |\n",
            "| time/              |          |\n",
            "|    fps             | 233      |\n",
            "|    iterations      | 242      |\n",
            "|    time_elapsed    | 2119     |\n",
            "|    total_timesteps | 495616   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 544          |\n",
            "|    ep_rew_mean          | 104          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 234          |\n",
            "|    iterations           | 243          |\n",
            "|    time_elapsed         | 2120         |\n",
            "|    total_timesteps      | 497664       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064443806 |\n",
            "|    clip_fraction        | 0.0709       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.693       |\n",
            "|    explained_variance   | 0.884        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.27         |\n",
            "|    n_updates            | 2420         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    value_loss           | 38.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 541          |\n",
            "|    ep_rew_mean          | 110          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 235          |\n",
            "|    iterations           | 244          |\n",
            "|    time_elapsed         | 2121         |\n",
            "|    total_timesteps      | 499712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0083076665 |\n",
            "|    clip_fraction        | 0.0755       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.773       |\n",
            "|    explained_variance   | 0.895        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.5          |\n",
            "|    n_updates            | 2430         |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    value_loss           | 51.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=500000, episode_reward=117.45 +/- 113.25\n",
            "Episode length: 527.80 +/- 183.93\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 528          |\n",
            "|    mean_reward          | 117          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 500000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047934665 |\n",
            "|    clip_fraction        | 0.0685       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.726       |\n",
            "|    explained_variance   | 0.96         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.73         |\n",
            "|    n_updates            | 2440         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    value_loss           | 18.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 540      |\n",
            "|    ep_rew_mean     | 115      |\n",
            "| time/              |          |\n",
            "|    fps             | 235      |\n",
            "|    iterations      | 245      |\n",
            "|    time_elapsed    | 2135     |\n",
            "|    total_timesteps | 501760   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 523          |\n",
            "|    ep_rew_mean          | 114          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 235          |\n",
            "|    iterations           | 246          |\n",
            "|    time_elapsed         | 2136         |\n",
            "|    total_timesteps      | 503808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044504665 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.716       |\n",
            "|    explained_variance   | 0.892        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.04         |\n",
            "|    n_updates            | 2450         |\n",
            "|    policy_gradient_loss | -0.00259     |\n",
            "|    value_loss           | 41.8         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=505000, episode_reward=130.08 +/- 108.81\n",
            "Episode length: 547.12 +/- 164.80\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 547         |\n",
            "|    mean_reward          | 130         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 505000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006095709 |\n",
            "|    clip_fraction        | 0.0759      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.73       |\n",
            "|    explained_variance   | 0.927       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.2        |\n",
            "|    n_updates            | 2460        |\n",
            "|    policy_gradient_loss | -0.00189    |\n",
            "|    value_loss           | 47.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 535      |\n",
            "|    ep_rew_mean     | 114      |\n",
            "| time/              |          |\n",
            "|    fps             | 235      |\n",
            "|    iterations      | 247      |\n",
            "|    time_elapsed    | 2149     |\n",
            "|    total_timesteps | 505856   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 532          |\n",
            "|    ep_rew_mean          | 118          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 236          |\n",
            "|    iterations           | 248          |\n",
            "|    time_elapsed         | 2151         |\n",
            "|    total_timesteps      | 507904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029411945 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.739       |\n",
            "|    explained_variance   | 0.893        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.68         |\n",
            "|    n_updates            | 2470         |\n",
            "|    policy_gradient_loss | 0.000832     |\n",
            "|    value_loss           | 44.9         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 536         |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 236         |\n",
            "|    iterations           | 249         |\n",
            "|    time_elapsed         | 2152        |\n",
            "|    total_timesteps      | 509952      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002545591 |\n",
            "|    clip_fraction        | 0.0277      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.745       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.4        |\n",
            "|    n_updates            | 2480        |\n",
            "|    policy_gradient_loss | -0.0016     |\n",
            "|    value_loss           | 105         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=510000, episode_reward=106.89 +/- 108.79\n",
            "Episode length: 551.98 +/- 225.98\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 552         |\n",
            "|    mean_reward          | 107         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 510000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005337332 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.513      |\n",
            "|    explained_variance   | 0.792       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 35.2        |\n",
            "|    n_updates            | 2490        |\n",
            "|    policy_gradient_loss | -0.00124    |\n",
            "|    value_loss           | 113         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 544      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 236      |\n",
            "|    iterations      | 250      |\n",
            "|    time_elapsed    | 2166     |\n",
            "|    total_timesteps | 512000   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 545         |\n",
            "|    ep_rew_mean          | 119         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 237         |\n",
            "|    iterations           | 251         |\n",
            "|    time_elapsed         | 2167        |\n",
            "|    total_timesteps      | 514048      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013165094 |\n",
            "|    clip_fraction        | 0.123       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.735      |\n",
            "|    explained_variance   | 0.911       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.5        |\n",
            "|    n_updates            | 2500        |\n",
            "|    policy_gradient_loss | -0.00212    |\n",
            "|    value_loss           | 26.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=515000, episode_reward=137.34 +/- 107.00\n",
            "Episode length: 534.72 +/- 188.66\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 535          |\n",
            "|    mean_reward          | 137          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 515000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050600073 |\n",
            "|    clip_fraction        | 0.0596       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.716       |\n",
            "|    explained_variance   | 0.857        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.68         |\n",
            "|    n_updates            | 2510         |\n",
            "|    policy_gradient_loss | -0.00026     |\n",
            "|    value_loss           | 77.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 548      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 236      |\n",
            "|    iterations      | 252      |\n",
            "|    time_elapsed    | 2180     |\n",
            "|    total_timesteps | 516096   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 540         |\n",
            "|    ep_rew_mean          | 120         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 237         |\n",
            "|    iterations           | 253         |\n",
            "|    time_elapsed         | 2181        |\n",
            "|    total_timesteps      | 518144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006563265 |\n",
            "|    clip_fraction        | 0.051       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.706      |\n",
            "|    explained_variance   | 0.775       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 59.5        |\n",
            "|    n_updates            | 2520        |\n",
            "|    policy_gradient_loss | -0.00254    |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=520000, episode_reward=147.14 +/- 104.28\n",
            "Episode length: 492.28 +/- 165.60\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 492          |\n",
            "|    mean_reward          | 147          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 520000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023371398 |\n",
            "|    clip_fraction        | 0.0234       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.722       |\n",
            "|    explained_variance   | 0.882        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 35.5         |\n",
            "|    n_updates            | 2530         |\n",
            "|    policy_gradient_loss | -0.000323    |\n",
            "|    value_loss           | 80.7         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 528      |\n",
            "|    ep_rew_mean     | 122      |\n",
            "| time/              |          |\n",
            "|    fps             | 237      |\n",
            "|    iterations      | 254      |\n",
            "|    time_elapsed    | 2193     |\n",
            "|    total_timesteps | 520192   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 533        |\n",
            "|    ep_rew_mean          | 119        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 237        |\n",
            "|    iterations           | 255        |\n",
            "|    time_elapsed         | 2194       |\n",
            "|    total_timesteps      | 522240     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00994063 |\n",
            "|    clip_fraction        | 0.0613     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.703     |\n",
            "|    explained_variance   | 0.853      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 41.3       |\n",
            "|    n_updates            | 2540       |\n",
            "|    policy_gradient_loss | -0.00095   |\n",
            "|    value_loss           | 77.8       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 526         |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 238         |\n",
            "|    iterations           | 256         |\n",
            "|    time_elapsed         | 2195        |\n",
            "|    total_timesteps      | 524288      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008231844 |\n",
            "|    clip_fraction        | 0.0394      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.709      |\n",
            "|    explained_variance   | 0.791       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.82        |\n",
            "|    n_updates            | 2550        |\n",
            "|    policy_gradient_loss | -0.000964   |\n",
            "|    value_loss           | 63.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=525000, episode_reward=114.61 +/- 117.48\n",
            "Episode length: 504.52 +/- 190.92\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 505          |\n",
            "|    mean_reward          | 115          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 525000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046706274 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.685       |\n",
            "|    explained_variance   | 0.861        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 53           |\n",
            "|    n_updates            | 2560         |\n",
            "|    policy_gradient_loss | -0.00249     |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 525      |\n",
            "|    ep_rew_mean     | 118      |\n",
            "| time/              |          |\n",
            "|    fps             | 238      |\n",
            "|    iterations      | 257      |\n",
            "|    time_elapsed    | 2207     |\n",
            "|    total_timesteps | 526336   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 521         |\n",
            "|    ep_rew_mean          | 118         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 239         |\n",
            "|    iterations           | 258         |\n",
            "|    time_elapsed         | 2208        |\n",
            "|    total_timesteps      | 528384      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005525401 |\n",
            "|    clip_fraction        | 0.0491      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.749      |\n",
            "|    explained_variance   | 0.879       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27          |\n",
            "|    n_updates            | 2570        |\n",
            "|    policy_gradient_loss | -0.00108    |\n",
            "|    value_loss           | 51.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=530000, episode_reward=75.41 +/- 127.57\n",
            "Episode length: 457.04 +/- 158.02\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 457          |\n",
            "|    mean_reward          | 75.4         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 530000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061483984 |\n",
            "|    clip_fraction        | 0.0712       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.656       |\n",
            "|    explained_variance   | 0.894        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17           |\n",
            "|    n_updates            | 2580         |\n",
            "|    policy_gradient_loss | -0.0024      |\n",
            "|    value_loss           | 62.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 522      |\n",
            "|    ep_rew_mean     | 116      |\n",
            "| time/              |          |\n",
            "|    fps             | 238      |\n",
            "|    iterations      | 259      |\n",
            "|    time_elapsed    | 2219     |\n",
            "|    total_timesteps | 530432   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 508        |\n",
            "|    ep_rew_mean          | 113        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 239        |\n",
            "|    iterations           | 260        |\n",
            "|    time_elapsed         | 2220       |\n",
            "|    total_timesteps      | 532480     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01272862 |\n",
            "|    clip_fraction        | 0.0863     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.657     |\n",
            "|    explained_variance   | 0.889      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 31.6       |\n",
            "|    n_updates            | 2590       |\n",
            "|    policy_gradient_loss | -0.00224   |\n",
            "|    value_loss           | 60.7       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 513          |\n",
            "|    ep_rew_mean          | 119          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 240          |\n",
            "|    iterations           | 261          |\n",
            "|    time_elapsed         | 2221         |\n",
            "|    total_timesteps      | 534528       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045843422 |\n",
            "|    clip_fraction        | 0.0429       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.671       |\n",
            "|    explained_variance   | 0.761        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 51           |\n",
            "|    n_updates            | 2600         |\n",
            "|    policy_gradient_loss | -0.00488     |\n",
            "|    value_loss           | 155          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=535000, episode_reward=117.87 +/- 108.72\n",
            "Episode length: 573.54 +/- 216.56\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 574         |\n",
            "|    mean_reward          | 118         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 535000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006366154 |\n",
            "|    clip_fraction        | 0.0601      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 0.719       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 69          |\n",
            "|    n_updates            | 2610        |\n",
            "|    policy_gradient_loss | -0.00246    |\n",
            "|    value_loss           | 136         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 512      |\n",
            "|    ep_rew_mean     | 125      |\n",
            "| time/              |          |\n",
            "|    fps             | 239      |\n",
            "|    iterations      | 262      |\n",
            "|    time_elapsed    | 2236     |\n",
            "|    total_timesteps | 536576   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 513         |\n",
            "|    ep_rew_mean          | 127         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 240         |\n",
            "|    iterations           | 263         |\n",
            "|    time_elapsed         | 2237        |\n",
            "|    total_timesteps      | 538624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007646182 |\n",
            "|    clip_fraction        | 0.0803      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.646      |\n",
            "|    explained_variance   | 0.841       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 2620        |\n",
            "|    policy_gradient_loss | -0.00327    |\n",
            "|    value_loss           | 78.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=540000, episode_reward=102.91 +/- 115.76\n",
            "Episode length: 536.28 +/- 189.92\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 536         |\n",
            "|    mean_reward          | 103         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 540000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011093305 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.694      |\n",
            "|    explained_variance   | 0.824       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 33.9        |\n",
            "|    n_updates            | 2630        |\n",
            "|    policy_gradient_loss | -0.00472    |\n",
            "|    value_loss           | 50.2        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 516      |\n",
            "|    ep_rew_mean     | 131      |\n",
            "| time/              |          |\n",
            "|    fps             | 240      |\n",
            "|    iterations      | 264      |\n",
            "|    time_elapsed    | 2251     |\n",
            "|    total_timesteps | 540672   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 512          |\n",
            "|    ep_rew_mean          | 127          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 240          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 2252         |\n",
            "|    total_timesteps      | 542720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045678895 |\n",
            "|    clip_fraction        | 0.0472       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.925        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.7          |\n",
            "|    n_updates            | 2640         |\n",
            "|    policy_gradient_loss | -0.00112     |\n",
            "|    value_loss           | 25.1         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 504          |\n",
            "|    ep_rew_mean          | 132          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 241          |\n",
            "|    iterations           | 266          |\n",
            "|    time_elapsed         | 2254         |\n",
            "|    total_timesteps      | 544768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058159186 |\n",
            "|    clip_fraction        | 0.055        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.761       |\n",
            "|    explained_variance   | 0.772        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.77         |\n",
            "|    n_updates            | 2650         |\n",
            "|    policy_gradient_loss | -0.000289    |\n",
            "|    value_loss           | 91.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=545000, episode_reward=117.09 +/- 109.33\n",
            "Episode length: 536.74 +/- 172.69\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 537         |\n",
            "|    mean_reward          | 117         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 545000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005212046 |\n",
            "|    clip_fraction        | 0.0528      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.662      |\n",
            "|    explained_variance   | 0.869       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.91        |\n",
            "|    n_updates            | 2660        |\n",
            "|    policy_gradient_loss | -0.00151    |\n",
            "|    value_loss           | 36.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 502      |\n",
            "|    ep_rew_mean     | 134      |\n",
            "| time/              |          |\n",
            "|    fps             | 241      |\n",
            "|    iterations      | 267      |\n",
            "|    time_elapsed    | 2268     |\n",
            "|    total_timesteps | 546816   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 501         |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 241         |\n",
            "|    iterations           | 268         |\n",
            "|    time_elapsed         | 2269        |\n",
            "|    total_timesteps      | 548864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008884456 |\n",
            "|    clip_fraction        | 0.0638      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.722      |\n",
            "|    explained_variance   | 0.88        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27.7        |\n",
            "|    n_updates            | 2670        |\n",
            "|    policy_gradient_loss | -0.00342    |\n",
            "|    value_loss           | 52.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=550000, episode_reward=123.65 +/- 109.17\n",
            "Episode length: 530.92 +/- 159.14\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 531         |\n",
            "|    mean_reward          | 124         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 550000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006648548 |\n",
            "|    clip_fraction        | 0.0568      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.69       |\n",
            "|    explained_variance   | 0.92        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 35.6        |\n",
            "|    n_updates            | 2680        |\n",
            "|    policy_gradient_loss | -0.00232    |\n",
            "|    value_loss           | 45.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 498      |\n",
            "|    ep_rew_mean     | 128      |\n",
            "| time/              |          |\n",
            "|    fps             | 241      |\n",
            "|    iterations      | 269      |\n",
            "|    time_elapsed    | 2281     |\n",
            "|    total_timesteps | 550912   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 501          |\n",
            "|    ep_rew_mean          | 127          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 242          |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 2283         |\n",
            "|    total_timesteps      | 552960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040386277 |\n",
            "|    clip_fraction        | 0.0366       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.66        |\n",
            "|    explained_variance   | 0.757        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26.9         |\n",
            "|    n_updates            | 2690         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 128          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=555000, episode_reward=119.16 +/- 106.60\n",
            "Episode length: 537.98 +/- 180.01\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 538          |\n",
            "|    mean_reward          | 119          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 555000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054973094 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0.787        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.4         |\n",
            "|    n_updates            | 2700         |\n",
            "|    policy_gradient_loss | -0.00404     |\n",
            "|    value_loss           | 85.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 492      |\n",
            "|    ep_rew_mean     | 127      |\n",
            "| time/              |          |\n",
            "|    fps             | 241      |\n",
            "|    iterations      | 271      |\n",
            "|    time_elapsed    | 2296     |\n",
            "|    total_timesteps | 555008   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 496         |\n",
            "|    ep_rew_mean          | 127         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 242         |\n",
            "|    iterations           | 272         |\n",
            "|    time_elapsed         | 2297        |\n",
            "|    total_timesteps      | 557056      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007932887 |\n",
            "|    clip_fraction        | 0.0797      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.734      |\n",
            "|    explained_variance   | 0.846       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.49        |\n",
            "|    n_updates            | 2710        |\n",
            "|    policy_gradient_loss | -0.0012     |\n",
            "|    value_loss           | 74.2        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 502          |\n",
            "|    ep_rew_mean          | 129          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 243          |\n",
            "|    iterations           | 273          |\n",
            "|    time_elapsed         | 2299         |\n",
            "|    total_timesteps      | 559104       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055555324 |\n",
            "|    clip_fraction        | 0.0489       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.657       |\n",
            "|    explained_variance   | 0.811        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.39         |\n",
            "|    n_updates            | 2720         |\n",
            "|    policy_gradient_loss | -0.000333    |\n",
            "|    value_loss           | 43           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=560000, episode_reward=88.62 +/- 120.80\n",
            "Episode length: 496.78 +/- 169.09\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 497          |\n",
            "|    mean_reward          | 88.6         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 560000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054863654 |\n",
            "|    clip_fraction        | 0.0373       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.71        |\n",
            "|    explained_variance   | 0.895        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.46         |\n",
            "|    n_updates            | 2730         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    value_loss           | 28.7         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 497      |\n",
            "|    ep_rew_mean     | 129      |\n",
            "| time/              |          |\n",
            "|    fps             | 242      |\n",
            "|    iterations      | 274      |\n",
            "|    time_elapsed    | 2311     |\n",
            "|    total_timesteps | 561152   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 488          |\n",
            "|    ep_rew_mean          | 129          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 243          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 2312         |\n",
            "|    total_timesteps      | 563200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061824527 |\n",
            "|    clip_fraction        | 0.0408       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | 0.799        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.6         |\n",
            "|    n_updates            | 2740         |\n",
            "|    policy_gradient_loss | -0.00213     |\n",
            "|    value_loss           | 79.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=565000, episode_reward=138.09 +/- 99.24\n",
            "Episode length: 547.50 +/- 154.42\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 548          |\n",
            "|    mean_reward          | 138          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 565000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040780357 |\n",
            "|    clip_fraction        | 0.0374       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.707       |\n",
            "|    explained_variance   | 0.752        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.04         |\n",
            "|    n_updates            | 2750         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    value_loss           | 90.2         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 124      |\n",
            "| time/              |          |\n",
            "|    fps             | 242      |\n",
            "|    iterations      | 276      |\n",
            "|    time_elapsed    | 2326     |\n",
            "|    total_timesteps | 565248   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 497         |\n",
            "|    ep_rew_mean          | 120         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 243         |\n",
            "|    iterations           | 277         |\n",
            "|    time_elapsed         | 2327        |\n",
            "|    total_timesteps      | 567296      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007924662 |\n",
            "|    clip_fraction        | 0.0572      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.685      |\n",
            "|    explained_variance   | 0.537       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 53          |\n",
            "|    n_updates            | 2760        |\n",
            "|    policy_gradient_loss | -0.00493    |\n",
            "|    value_loss           | 133         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 494         |\n",
            "|    ep_rew_mean          | 113         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 244         |\n",
            "|    iterations           | 278         |\n",
            "|    time_elapsed         | 2329        |\n",
            "|    total_timesteps      | 569344      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005764993 |\n",
            "|    clip_fraction        | 0.0617      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.712      |\n",
            "|    explained_variance   | 0.59        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 15.7        |\n",
            "|    n_updates            | 2770        |\n",
            "|    policy_gradient_loss | -0.0036     |\n",
            "|    value_loss           | 74.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=570000, episode_reward=107.00 +/- 115.81\n",
            "Episode length: 493.68 +/- 156.08\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 494          |\n",
            "|    mean_reward          | 107          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 570000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028832515 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.719       |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 50.9         |\n",
            "|    n_updates            | 2780         |\n",
            "|    policy_gradient_loss | -0.00185     |\n",
            "|    value_loss           | 97.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 490      |\n",
            "|    ep_rew_mean     | 113      |\n",
            "| time/              |          |\n",
            "|    fps             | 244      |\n",
            "|    iterations      | 279      |\n",
            "|    time_elapsed    | 2341     |\n",
            "|    total_timesteps | 571392   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 497         |\n",
            "|    ep_rew_mean          | 112         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 244         |\n",
            "|    iterations           | 280         |\n",
            "|    time_elapsed         | 2342        |\n",
            "|    total_timesteps      | 573440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005312984 |\n",
            "|    clip_fraction        | 0.0711      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.699      |\n",
            "|    explained_variance   | 0.768       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 64.5        |\n",
            "|    n_updates            | 2790        |\n",
            "|    policy_gradient_loss | -0.00306    |\n",
            "|    value_loss           | 85.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=575000, episode_reward=106.55 +/- 118.87\n",
            "Episode length: 499.18 +/- 185.25\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 499          |\n",
            "|    mean_reward          | 107          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 575000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052591176 |\n",
            "|    clip_fraction        | 0.0646       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.727       |\n",
            "|    explained_variance   | 0.86         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 30.5         |\n",
            "|    n_updates            | 2800         |\n",
            "|    policy_gradient_loss | -0.00445     |\n",
            "|    value_loss           | 89.2         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 489      |\n",
            "|    ep_rew_mean     | 106      |\n",
            "| time/              |          |\n",
            "|    fps             | 244      |\n",
            "|    iterations      | 281      |\n",
            "|    time_elapsed    | 2353     |\n",
            "|    total_timesteps | 575488   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 489         |\n",
            "|    ep_rew_mean          | 103         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 245         |\n",
            "|    iterations           | 282         |\n",
            "|    time_elapsed         | 2355        |\n",
            "|    total_timesteps      | 577536      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008022293 |\n",
            "|    clip_fraction        | 0.0584      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.765      |\n",
            "|    explained_variance   | 0.816       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.13        |\n",
            "|    n_updates            | 2810        |\n",
            "|    policy_gradient_loss | -0.000511   |\n",
            "|    value_loss           | 67.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 481          |\n",
            "|    ep_rew_mean          | 96.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 245          |\n",
            "|    iterations           | 283          |\n",
            "|    time_elapsed         | 2356         |\n",
            "|    total_timesteps      | 579584       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048834663 |\n",
            "|    clip_fraction        | 0.047        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.72        |\n",
            "|    explained_variance   | 0.736        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17           |\n",
            "|    n_updates            | 2820         |\n",
            "|    policy_gradient_loss | -0.00142     |\n",
            "|    value_loss           | 118          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=580000, episode_reward=113.96 +/- 114.36\n",
            "Episode length: 561.76 +/- 173.37\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 562          |\n",
            "|    mean_reward          | 114          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 580000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056584496 |\n",
            "|    clip_fraction        | 0.053        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.731       |\n",
            "|    explained_variance   | 0.889        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 74.6         |\n",
            "|    n_updates            | 2830         |\n",
            "|    policy_gradient_loss | -0.00554     |\n",
            "|    value_loss           | 78.2         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 494      |\n",
            "|    ep_rew_mean     | 101      |\n",
            "| time/              |          |\n",
            "|    fps             | 245      |\n",
            "|    iterations      | 284      |\n",
            "|    time_elapsed    | 2370     |\n",
            "|    total_timesteps | 581632   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 493          |\n",
            "|    ep_rew_mean          | 101          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 246          |\n",
            "|    iterations           | 285          |\n",
            "|    time_elapsed         | 2371         |\n",
            "|    total_timesteps      | 583680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068876687 |\n",
            "|    clip_fraction        | 0.0751       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.737       |\n",
            "|    explained_variance   | 0.805        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28.4         |\n",
            "|    n_updates            | 2840         |\n",
            "|    policy_gradient_loss | -0.00348     |\n",
            "|    value_loss           | 90.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=585000, episode_reward=104.99 +/- 117.38\n",
            "Episode length: 553.72 +/- 180.85\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 554          |\n",
            "|    mean_reward          | 105          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 585000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044638515 |\n",
            "|    clip_fraction        | 0.0449       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.673       |\n",
            "|    explained_variance   | 0.861        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 44.7         |\n",
            "|    n_updates            | 2850         |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    value_loss           | 82.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 487      |\n",
            "|    ep_rew_mean     | 96.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 245      |\n",
            "|    iterations      | 286      |\n",
            "|    time_elapsed    | 2385     |\n",
            "|    total_timesteps | 585728   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 478          |\n",
            "|    ep_rew_mean          | 98.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 246          |\n",
            "|    iterations           | 287          |\n",
            "|    time_elapsed         | 2386         |\n",
            "|    total_timesteps      | 587776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063771964 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | 0.83         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 49.3         |\n",
            "|    n_updates            | 2860         |\n",
            "|    policy_gradient_loss | -0.00465     |\n",
            "|    value_loss           | 90.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 472         |\n",
            "|    ep_rew_mean          | 97.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 247         |\n",
            "|    iterations           | 288         |\n",
            "|    time_elapsed         | 2387        |\n",
            "|    total_timesteps      | 589824      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004423017 |\n",
            "|    clip_fraction        | 0.0328      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.616      |\n",
            "|    explained_variance   | 0.885       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 38.9        |\n",
            "|    n_updates            | 2870        |\n",
            "|    policy_gradient_loss | -0.00115    |\n",
            "|    value_loss           | 92.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=590000, episode_reward=108.68 +/- 120.97\n",
            "Episode length: 519.06 +/- 182.54\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 519         |\n",
            "|    mean_reward          | 109         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 590000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005993954 |\n",
            "|    clip_fraction        | 0.0598      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.721      |\n",
            "|    explained_variance   | 0.807       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 26.2        |\n",
            "|    n_updates            | 2880        |\n",
            "|    policy_gradient_loss | -0.00254    |\n",
            "|    value_loss           | 107         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 474      |\n",
            "|    ep_rew_mean     | 92.1     |\n",
            "| time/              |          |\n",
            "|    fps             | 246      |\n",
            "|    iterations      | 289      |\n",
            "|    time_elapsed    | 2400     |\n",
            "|    total_timesteps | 591872   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 473          |\n",
            "|    ep_rew_mean          | 88.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 247          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 2401         |\n",
            "|    total_timesteps      | 593920       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075499807 |\n",
            "|    clip_fraction        | 0.0902       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.709       |\n",
            "|    explained_variance   | 0.894        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 14.3         |\n",
            "|    n_updates            | 2890         |\n",
            "|    policy_gradient_loss | -0.00568     |\n",
            "|    value_loss           | 59.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=595000, episode_reward=108.94 +/- 109.16\n",
            "Episode length: 548.32 +/- 146.79\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 548         |\n",
            "|    mean_reward          | 109         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 595000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011153974 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.656      |\n",
            "|    explained_variance   | 0.902       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.69        |\n",
            "|    n_updates            | 2900        |\n",
            "|    policy_gradient_loss | -0.00249    |\n",
            "|    value_loss           | 50.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 474      |\n",
            "|    ep_rew_mean     | 87.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 246      |\n",
            "|    iterations      | 291      |\n",
            "|    time_elapsed    | 2415     |\n",
            "|    total_timesteps | 595968   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | 84          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 247         |\n",
            "|    iterations           | 292         |\n",
            "|    time_elapsed         | 2416        |\n",
            "|    total_timesteps      | 598016      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006916994 |\n",
            "|    clip_fraction        | 0.0772      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | 0.915       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.33        |\n",
            "|    n_updates            | 2910        |\n",
            "|    policy_gradient_loss | -0.003      |\n",
            "|    value_loss           | 49.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=600000, episode_reward=84.24 +/- 115.10\n",
            "Episode length: 501.46 +/- 203.71\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 501         |\n",
            "|    mean_reward          | 84.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 600000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005592169 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.629      |\n",
            "|    explained_variance   | 0.663       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20          |\n",
            "|    n_updates            | 2920        |\n",
            "|    policy_gradient_loss | -0.00235    |\n",
            "|    value_loss           | 164         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 477      |\n",
            "|    ep_rew_mean     | 84.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 247      |\n",
            "|    iterations      | 293      |\n",
            "|    time_elapsed    | 2428     |\n",
            "|    total_timesteps | 600064   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 481         |\n",
            "|    ep_rew_mean          | 86          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 247         |\n",
            "|    iterations           | 294         |\n",
            "|    time_elapsed         | 2429        |\n",
            "|    total_timesteps      | 602112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012075115 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.615      |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.36        |\n",
            "|    n_updates            | 2930        |\n",
            "|    policy_gradient_loss | -0.00137    |\n",
            "|    value_loss           | 41.1        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 480        |\n",
            "|    ep_rew_mean          | 83.1       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 248        |\n",
            "|    iterations           | 295        |\n",
            "|    time_elapsed         | 2430       |\n",
            "|    total_timesteps      | 604160     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01048512 |\n",
            "|    clip_fraction        | 0.064      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.613     |\n",
            "|    explained_variance   | 0.752      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 37.4       |\n",
            "|    n_updates            | 2940       |\n",
            "|    policy_gradient_loss | -0.0062    |\n",
            "|    value_loss           | 103        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=605000, episode_reward=100.30 +/- 122.45\n",
            "Episode length: 508.88 +/- 209.41\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 509          |\n",
            "|    mean_reward          | 100          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 605000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074868626 |\n",
            "|    clip_fraction        | 0.0737       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.727       |\n",
            "|    explained_variance   | 0.884        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.03         |\n",
            "|    n_updates            | 2950         |\n",
            "|    policy_gradient_loss | -0.00313     |\n",
            "|    value_loss           | 31.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 488      |\n",
            "|    ep_rew_mean     | 83.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 248      |\n",
            "|    iterations      | 296      |\n",
            "|    time_elapsed    | 2442     |\n",
            "|    total_timesteps | 606208   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 484         |\n",
            "|    ep_rew_mean          | 78.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 248         |\n",
            "|    iterations           | 297         |\n",
            "|    time_elapsed         | 2443        |\n",
            "|    total_timesteps      | 608256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008276256 |\n",
            "|    clip_fraction        | 0.0464      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.652      |\n",
            "|    explained_variance   | 0.334       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.4        |\n",
            "|    n_updates            | 2960        |\n",
            "|    policy_gradient_loss | -0.00215    |\n",
            "|    value_loss           | 143         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=610000, episode_reward=91.00 +/- 122.32\n",
            "Episode length: 498.90 +/- 205.65\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 499         |\n",
            "|    mean_reward          | 91          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 610000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010964081 |\n",
            "|    clip_fraction        | 0.0679      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.528      |\n",
            "|    explained_variance   | 0.606       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 79.9        |\n",
            "|    n_updates            | 2970        |\n",
            "|    policy_gradient_loss | -0.0057     |\n",
            "|    value_loss           | 143         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 488      |\n",
            "|    ep_rew_mean     | 74.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 248      |\n",
            "|    iterations      | 298      |\n",
            "|    time_elapsed    | 2456     |\n",
            "|    total_timesteps | 610304   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 488         |\n",
            "|    ep_rew_mean          | 74.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 249         |\n",
            "|    iterations           | 299         |\n",
            "|    time_elapsed         | 2457        |\n",
            "|    total_timesteps      | 612352      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005008309 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0.843       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 49.4        |\n",
            "|    n_updates            | 2980        |\n",
            "|    policy_gradient_loss | -0.000527   |\n",
            "|    value_loss           | 85.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 490         |\n",
            "|    ep_rew_mean          | 79.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 249         |\n",
            "|    iterations           | 300         |\n",
            "|    time_elapsed         | 2459        |\n",
            "|    total_timesteps      | 614400      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008665035 |\n",
            "|    clip_fraction        | 0.0736      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.687      |\n",
            "|    explained_variance   | 0.892       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.78        |\n",
            "|    n_updates            | 2990        |\n",
            "|    policy_gradient_loss | -0.00371    |\n",
            "|    value_loss           | 29.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=615000, episode_reward=129.54 +/- 108.17\n",
            "Episode length: 541.70 +/- 190.99\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 542          |\n",
            "|    mean_reward          | 130          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 615000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044729263 |\n",
            "|    clip_fraction        | 0.0411       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0.786        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.91         |\n",
            "|    n_updates            | 3000         |\n",
            "|    policy_gradient_loss | -0.00133     |\n",
            "|    value_loss           | 34.3         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 490      |\n",
            "|    ep_rew_mean     | 81.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 249      |\n",
            "|    iterations      | 301      |\n",
            "|    time_elapsed    | 2472     |\n",
            "|    total_timesteps | 616448   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 490          |\n",
            "|    ep_rew_mean          | 81.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 250          |\n",
            "|    iterations           | 302          |\n",
            "|    time_elapsed         | 2473         |\n",
            "|    total_timesteps      | 618496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039371173 |\n",
            "|    clip_fraction        | 0.0907       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.672       |\n",
            "|    explained_variance   | 0.592        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 53.3         |\n",
            "|    n_updates            | 3010         |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    value_loss           | 139          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=620000, episode_reward=114.34 +/- 108.93\n",
            "Episode length: 550.80 +/- 212.39\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 551          |\n",
            "|    mean_reward          | 114          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 620000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076044537 |\n",
            "|    clip_fraction        | 0.0761       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.674       |\n",
            "|    explained_variance   | 0.791        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 44.9         |\n",
            "|    n_updates            | 3020         |\n",
            "|    policy_gradient_loss | -0.00399     |\n",
            "|    value_loss           | 96.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 486      |\n",
            "|    ep_rew_mean     | 82.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 249      |\n",
            "|    iterations      | 303      |\n",
            "|    time_elapsed    | 2488     |\n",
            "|    total_timesteps | 620544   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 490          |\n",
            "|    ep_rew_mean          | 82           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 250          |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 2489         |\n",
            "|    total_timesteps      | 622592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044762264 |\n",
            "|    clip_fraction        | 0.0598       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.685       |\n",
            "|    explained_variance   | 0.77         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 30.2         |\n",
            "|    n_updates            | 3030         |\n",
            "|    policy_gradient_loss | -0.00463     |\n",
            "|    value_loss           | 77.7         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 496         |\n",
            "|    ep_rew_mean          | 88.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 250         |\n",
            "|    iterations           | 305         |\n",
            "|    time_elapsed         | 2490        |\n",
            "|    total_timesteps      | 624640      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008628005 |\n",
            "|    clip_fraction        | 0.0601      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.675      |\n",
            "|    explained_variance   | 0.849       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 24.1        |\n",
            "|    n_updates            | 3040        |\n",
            "|    policy_gradient_loss | -0.00424    |\n",
            "|    value_loss           | 99.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=625000, episode_reward=102.09 +/- 118.02\n",
            "Episode length: 547.50 +/- 225.37\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 548          |\n",
            "|    mean_reward          | 102          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 625000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056792796 |\n",
            "|    clip_fraction        | 0.0516       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.646       |\n",
            "|    explained_variance   | 0.835        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.34         |\n",
            "|    n_updates            | 3050         |\n",
            "|    policy_gradient_loss | -0.000258    |\n",
            "|    value_loss           | 55.7         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 492      |\n",
            "|    ep_rew_mean     | 88.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 250      |\n",
            "|    iterations      | 306      |\n",
            "|    time_elapsed    | 2504     |\n",
            "|    total_timesteps | 626688   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 501         |\n",
            "|    ep_rew_mean          | 93.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 250         |\n",
            "|    iterations           | 307         |\n",
            "|    time_elapsed         | 2505        |\n",
            "|    total_timesteps      | 628736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006719797 |\n",
            "|    clip_fraction        | 0.067       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.634      |\n",
            "|    explained_variance   | 0.722       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 48.9        |\n",
            "|    n_updates            | 3060        |\n",
            "|    policy_gradient_loss | -0.00391    |\n",
            "|    value_loss           | 191         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=630000, episode_reward=152.64 +/- 84.46\n",
            "Episode length: 597.04 +/- 206.83\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 597        |\n",
            "|    mean_reward          | 153        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 630000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00962819 |\n",
            "|    clip_fraction        | 0.0904     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.638     |\n",
            "|    explained_variance   | 0.877      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.64       |\n",
            "|    n_updates            | 3070       |\n",
            "|    policy_gradient_loss | -0.00286   |\n",
            "|    value_loss           | 39.4       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 501      |\n",
            "|    ep_rew_mean     | 96.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 250      |\n",
            "|    iterations      | 308      |\n",
            "|    time_elapsed    | 2520     |\n",
            "|    total_timesteps | 630784   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 499        |\n",
            "|    ep_rew_mean          | 96         |\n",
            "| time/                   |            |\n",
            "|    fps                  | 250        |\n",
            "|    iterations           | 309        |\n",
            "|    time_elapsed         | 2522       |\n",
            "|    total_timesteps      | 632832     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00360964 |\n",
            "|    clip_fraction        | 0.0485     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.702     |\n",
            "|    explained_variance   | 0.809      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 20.5       |\n",
            "|    n_updates            | 3080       |\n",
            "|    policy_gradient_loss | -0.0013    |\n",
            "|    value_loss           | 89.5       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 499         |\n",
            "|    ep_rew_mean          | 95.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 251         |\n",
            "|    iterations           | 310         |\n",
            "|    time_elapsed         | 2523        |\n",
            "|    total_timesteps      | 634880      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005426854 |\n",
            "|    clip_fraction        | 0.0745      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.686      |\n",
            "|    explained_variance   | 0.926       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.7        |\n",
            "|    n_updates            | 3090        |\n",
            "|    policy_gradient_loss | -0.00269    |\n",
            "|    value_loss           | 54.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=635000, episode_reward=86.50 +/- 133.48\n",
            "Episode length: 493.42 +/- 184.11\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 493         |\n",
            "|    mean_reward          | 86.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 635000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007058785 |\n",
            "|    clip_fraction        | 0.0578      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | 0.811       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 3100        |\n",
            "|    policy_gradient_loss | -0.00146    |\n",
            "|    value_loss           | 95.5        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 506      |\n",
            "|    ep_rew_mean     | 94.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 251      |\n",
            "|    iterations      | 311      |\n",
            "|    time_elapsed    | 2535     |\n",
            "|    total_timesteps | 636928   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 512        |\n",
            "|    ep_rew_mean          | 92.2       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 251        |\n",
            "|    iterations           | 312        |\n",
            "|    time_elapsed         | 2536       |\n",
            "|    total_timesteps      | 638976     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00421251 |\n",
            "|    clip_fraction        | 0.0456     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.637     |\n",
            "|    explained_variance   | 0.753      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.99       |\n",
            "|    n_updates            | 3110       |\n",
            "|    policy_gradient_loss | -0.00288   |\n",
            "|    value_loss           | 75         |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=640000, episode_reward=83.68 +/- 124.00\n",
            "Episode length: 498.96 +/- 197.50\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 499          |\n",
            "|    mean_reward          | 83.7         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 640000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066836057 |\n",
            "|    clip_fraction        | 0.0937       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.725       |\n",
            "|    explained_variance   | 0.752        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.3         |\n",
            "|    n_updates            | 3120         |\n",
            "|    policy_gradient_loss | -0.000143    |\n",
            "|    value_loss           | 65.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 510      |\n",
            "|    ep_rew_mean     | 88.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 251      |\n",
            "|    iterations      | 313      |\n",
            "|    time_elapsed    | 2549     |\n",
            "|    total_timesteps | 641024   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 501          |\n",
            "|    ep_rew_mean          | 89.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 252          |\n",
            "|    iterations           | 314          |\n",
            "|    time_elapsed         | 2550         |\n",
            "|    total_timesteps      | 643072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035585593 |\n",
            "|    clip_fraction        | 0.0442       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.648       |\n",
            "|    explained_variance   | 0.879        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 32.4         |\n",
            "|    n_updates            | 3130         |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    value_loss           | 135          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=645000, episode_reward=94.55 +/- 123.37\n",
            "Episode length: 513.54 +/- 203.95\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 514        |\n",
            "|    mean_reward          | 94.5       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 645000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00506887 |\n",
            "|    clip_fraction        | 0.0521     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.685     |\n",
            "|    explained_variance   | 0.774      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.42       |\n",
            "|    n_updates            | 3140       |\n",
            "|    policy_gradient_loss | -0.00247   |\n",
            "|    value_loss           | 109        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 504      |\n",
            "|    ep_rew_mean     | 88.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 251      |\n",
            "|    iterations      | 315      |\n",
            "|    time_elapsed    | 2563     |\n",
            "|    total_timesteps | 645120   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 504         |\n",
            "|    ep_rew_mean          | 89.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 252         |\n",
            "|    iterations           | 316         |\n",
            "|    time_elapsed         | 2564        |\n",
            "|    total_timesteps      | 647168      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006315847 |\n",
            "|    clip_fraction        | 0.0438      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.702      |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 52          |\n",
            "|    n_updates            | 3150        |\n",
            "|    policy_gradient_loss | -0.000573   |\n",
            "|    value_loss           | 97.4        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 485         |\n",
            "|    ep_rew_mean          | 87.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 253         |\n",
            "|    iterations           | 317         |\n",
            "|    time_elapsed         | 2565        |\n",
            "|    total_timesteps      | 649216      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006028034 |\n",
            "|    clip_fraction        | 0.0425      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 71.7        |\n",
            "|    n_updates            | 3160        |\n",
            "|    policy_gradient_loss | -0.00371    |\n",
            "|    value_loss           | 97.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=650000, episode_reward=99.38 +/- 126.26\n",
            "Episode length: 442.36 +/- 150.41\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 442         |\n",
            "|    mean_reward          | 99.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 650000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008750211 |\n",
            "|    clip_fraction        | 0.0638      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.636      |\n",
            "|    explained_variance   | 0.849       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 47.1        |\n",
            "|    n_updates            | 3170        |\n",
            "|    policy_gradient_loss | -0.00126    |\n",
            "|    value_loss           | 103         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 491      |\n",
            "|    ep_rew_mean     | 91.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 252      |\n",
            "|    iterations      | 318      |\n",
            "|    time_elapsed    | 2575     |\n",
            "|    total_timesteps | 651264   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 492         |\n",
            "|    ep_rew_mean          | 92          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 253         |\n",
            "|    iterations           | 319         |\n",
            "|    time_elapsed         | 2577        |\n",
            "|    total_timesteps      | 653312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011847096 |\n",
            "|    clip_fraction        | 0.0573      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.675      |\n",
            "|    explained_variance   | 0.839       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.3        |\n",
            "|    n_updates            | 3180        |\n",
            "|    policy_gradient_loss | -0.00107    |\n",
            "|    value_loss           | 80.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=655000, episode_reward=68.23 +/- 131.83\n",
            "Episode length: 438.78 +/- 146.86\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 439         |\n",
            "|    mean_reward          | 68.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 655000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006452676 |\n",
            "|    clip_fraction        | 0.0728      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.69       |\n",
            "|    explained_variance   | 0.876       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 66.8        |\n",
            "|    n_updates            | 3190        |\n",
            "|    policy_gradient_loss | 0.000585    |\n",
            "|    value_loss           | 72.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 478      |\n",
            "|    ep_rew_mean     | 88.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 253      |\n",
            "|    iterations      | 320      |\n",
            "|    time_elapsed    | 2586     |\n",
            "|    total_timesteps | 655360   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 475         |\n",
            "|    ep_rew_mean          | 93.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 254         |\n",
            "|    iterations           | 321         |\n",
            "|    time_elapsed         | 2587        |\n",
            "|    total_timesteps      | 657408      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004965686 |\n",
            "|    clip_fraction        | 0.0334      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.641      |\n",
            "|    explained_variance   | 0.712       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 153         |\n",
            "|    n_updates            | 3200        |\n",
            "|    policy_gradient_loss | -0.00132    |\n",
            "|    value_loss           | 270         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 466          |\n",
            "|    ep_rew_mean          | 87.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 254          |\n",
            "|    iterations           | 322          |\n",
            "|    time_elapsed         | 2588         |\n",
            "|    total_timesteps      | 659456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036689052 |\n",
            "|    clip_fraction        | 0.0382       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0.789        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 48.8         |\n",
            "|    n_updates            | 3210         |\n",
            "|    policy_gradient_loss | -0.000704    |\n",
            "|    value_loss           | 94.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=660000, episode_reward=128.07 +/- 118.48\n",
            "Episode length: 464.30 +/- 165.06\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 464          |\n",
            "|    mean_reward          | 128          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 660000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037733314 |\n",
            "|    clip_fraction        | 0.0316       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | 0.802        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 49.9         |\n",
            "|    n_updates            | 3220         |\n",
            "|    policy_gradient_loss | -0.00245     |\n",
            "|    value_loss           | 150          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 463      |\n",
            "|    ep_rew_mean     | 89.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 254      |\n",
            "|    iterations      | 323      |\n",
            "|    time_elapsed    | 2599     |\n",
            "|    total_timesteps | 661504   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 462         |\n",
            "|    ep_rew_mean          | 97.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 255         |\n",
            "|    iterations           | 324         |\n",
            "|    time_elapsed         | 2601        |\n",
            "|    total_timesteps      | 663552      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005297446 |\n",
            "|    clip_fraction        | 0.0389      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.665      |\n",
            "|    explained_variance   | 0.783       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 18.9        |\n",
            "|    n_updates            | 3230        |\n",
            "|    policy_gradient_loss | -0.000551   |\n",
            "|    value_loss           | 98          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=665000, episode_reward=108.39 +/- 124.30\n",
            "Episode length: 452.44 +/- 165.84\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 452         |\n",
            "|    mean_reward          | 108         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 665000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007534586 |\n",
            "|    clip_fraction        | 0.0732      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.631      |\n",
            "|    explained_variance   | 0.868       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37.6        |\n",
            "|    n_updates            | 3240        |\n",
            "|    policy_gradient_loss | -0.00272    |\n",
            "|    value_loss           | 101         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 470      |\n",
            "|    ep_rew_mean     | 99.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 254      |\n",
            "|    iterations      | 325      |\n",
            "|    time_elapsed    | 2610     |\n",
            "|    total_timesteps | 665600   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 468         |\n",
            "|    ep_rew_mean          | 97.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 255         |\n",
            "|    iterations           | 326         |\n",
            "|    time_elapsed         | 2611        |\n",
            "|    total_timesteps      | 667648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006009344 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.64       |\n",
            "|    explained_variance   | 0.814       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.4        |\n",
            "|    n_updates            | 3250        |\n",
            "|    policy_gradient_loss | -0.0042     |\n",
            "|    value_loss           | 66.3        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 461          |\n",
            "|    ep_rew_mean          | 102          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 256          |\n",
            "|    iterations           | 327          |\n",
            "|    time_elapsed         | 2613         |\n",
            "|    total_timesteps      | 669696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042257896 |\n",
            "|    clip_fraction        | 0.0561       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0.834        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 51.9         |\n",
            "|    n_updates            | 3260         |\n",
            "|    policy_gradient_loss | -0.00491     |\n",
            "|    value_loss           | 159          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=670000, episode_reward=111.52 +/- 112.35\n",
            "Episode length: 436.94 +/- 160.64\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 437         |\n",
            "|    mean_reward          | 112         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 670000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005847934 |\n",
            "|    clip_fraction        | 0.0659      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0.777       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 27.8        |\n",
            "|    n_updates            | 3270        |\n",
            "|    policy_gradient_loss | -0.00536    |\n",
            "|    value_loss           | 56.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 460      |\n",
            "|    ep_rew_mean     | 105      |\n",
            "| time/              |          |\n",
            "|    fps             | 256      |\n",
            "|    iterations      | 328      |\n",
            "|    time_elapsed    | 2623     |\n",
            "|    total_timesteps | 671744   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 455         |\n",
            "|    ep_rew_mean          | 112         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 256         |\n",
            "|    iterations           | 329         |\n",
            "|    time_elapsed         | 2624        |\n",
            "|    total_timesteps      | 673792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007841315 |\n",
            "|    clip_fraction        | 0.0477      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.644      |\n",
            "|    explained_variance   | 0.835       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 34.7        |\n",
            "|    n_updates            | 3280        |\n",
            "|    policy_gradient_loss | -0.00467    |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=675000, episode_reward=98.10 +/- 118.59\n",
            "Episode length: 438.14 +/- 205.34\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 438         |\n",
            "|    mean_reward          | 98.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 675000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005575048 |\n",
            "|    clip_fraction        | 0.0776      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.644      |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 26.9        |\n",
            "|    n_updates            | 3290        |\n",
            "|    policy_gradient_loss | -0.00233    |\n",
            "|    value_loss           | 30.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 451      |\n",
            "|    ep_rew_mean     | 113      |\n",
            "| time/              |          |\n",
            "|    fps             | 256      |\n",
            "|    iterations      | 330      |\n",
            "|    time_elapsed    | 2634     |\n",
            "|    total_timesteps | 675840   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 453         |\n",
            "|    ep_rew_mean          | 116         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 257         |\n",
            "|    iterations           | 331         |\n",
            "|    time_elapsed         | 2635        |\n",
            "|    total_timesteps      | 677888      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004677827 |\n",
            "|    clip_fraction        | 0.0548      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.598      |\n",
            "|    explained_variance   | 0.743       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 139         |\n",
            "|    n_updates            | 3300        |\n",
            "|    policy_gradient_loss | -0.00453    |\n",
            "|    value_loss           | 153         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 443         |\n",
            "|    ep_rew_mean          | 114         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 257         |\n",
            "|    iterations           | 332         |\n",
            "|    time_elapsed         | 2636        |\n",
            "|    total_timesteps      | 679936      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008524322 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.688      |\n",
            "|    explained_variance   | 0.935       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.31        |\n",
            "|    n_updates            | 3310        |\n",
            "|    policy_gradient_loss | 0.000353    |\n",
            "|    value_loss           | 41.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=680000, episode_reward=136.20 +/- 102.80\n",
            "Episode length: 490.36 +/- 201.28\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 490          |\n",
            "|    mean_reward          | 136          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 680000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029535282 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0.846        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 104          |\n",
            "|    n_updates            | 3320         |\n",
            "|    policy_gradient_loss | -0.00376     |\n",
            "|    value_loss           | 156          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 439      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 257      |\n",
            "|    iterations      | 333      |\n",
            "|    time_elapsed    | 2647     |\n",
            "|    total_timesteps | 681984   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 440         |\n",
            "|    ep_rew_mean          | 118         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 258         |\n",
            "|    iterations           | 334         |\n",
            "|    time_elapsed         | 2649        |\n",
            "|    total_timesteps      | 684032      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012723344 |\n",
            "|    clip_fraction        | 0.0947      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.63       |\n",
            "|    explained_variance   | 0.771       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.2        |\n",
            "|    n_updates            | 3330        |\n",
            "|    policy_gradient_loss | -0.00365    |\n",
            "|    value_loss           | 48.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=685000, episode_reward=100.64 +/- 118.94\n",
            "Episode length: 430.88 +/- 139.06\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 431         |\n",
            "|    mean_reward          | 101         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 685000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008986611 |\n",
            "|    clip_fraction        | 0.112       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.643      |\n",
            "|    explained_variance   | 0.879       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.31        |\n",
            "|    n_updates            | 3340        |\n",
            "|    policy_gradient_loss | -0.00232    |\n",
            "|    value_loss           | 25.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 450      |\n",
            "|    ep_rew_mean     | 118      |\n",
            "| time/              |          |\n",
            "|    fps             | 258      |\n",
            "|    iterations      | 335      |\n",
            "|    time_elapsed    | 2659     |\n",
            "|    total_timesteps | 686080   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 456          |\n",
            "|    ep_rew_mean          | 116          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 336          |\n",
            "|    time_elapsed         | 2660         |\n",
            "|    total_timesteps      | 688128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0063461275 |\n",
            "|    clip_fraction        | 0.0461       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 0.794        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27           |\n",
            "|    n_updates            | 3350         |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 94.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=690000, episode_reward=100.31 +/- 113.97\n",
            "Episode length: 482.58 +/- 193.53\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 483         |\n",
            "|    mean_reward          | 100         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 690000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004528451 |\n",
            "|    clip_fraction        | 0.0262      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.662      |\n",
            "|    explained_variance   | 0.754       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 74.4        |\n",
            "|    n_updates            | 3360        |\n",
            "|    policy_gradient_loss | -0.00143    |\n",
            "|    value_loss           | 160         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 461      |\n",
            "|    ep_rew_mean     | 120      |\n",
            "| time/              |          |\n",
            "|    fps             | 258      |\n",
            "|    iterations      | 337      |\n",
            "|    time_elapsed    | 2671     |\n",
            "|    total_timesteps | 690176   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 452          |\n",
            "|    ep_rew_mean          | 120          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 258          |\n",
            "|    iterations           | 338          |\n",
            "|    time_elapsed         | 2673         |\n",
            "|    total_timesteps      | 692224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051535075 |\n",
            "|    clip_fraction        | 0.048        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0.81         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 81.4         |\n",
            "|    n_updates            | 3370         |\n",
            "|    policy_gradient_loss | -0.00298     |\n",
            "|    value_loss           | 89.5         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 456          |\n",
            "|    ep_rew_mean          | 120          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 259          |\n",
            "|    iterations           | 339          |\n",
            "|    time_elapsed         | 2675         |\n",
            "|    total_timesteps      | 694272       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044238316 |\n",
            "|    clip_fraction        | 0.0481       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.67        |\n",
            "|    explained_variance   | 0.782        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26.1         |\n",
            "|    n_updates            | 3380         |\n",
            "|    policy_gradient_loss | -0.00203     |\n",
            "|    value_loss           | 137          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=695000, episode_reward=67.32 +/- 130.81\n",
            "Episode length: 412.64 +/- 144.51\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 413          |\n",
            "|    mean_reward          | 67.3         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 695000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050106263 |\n",
            "|    clip_fraction        | 0.0455       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.596       |\n",
            "|    explained_variance   | 0.839        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.1         |\n",
            "|    n_updates            | 3390         |\n",
            "|    policy_gradient_loss | -0.00173     |\n",
            "|    value_loss           | 102          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 455      |\n",
            "|    ep_rew_mean     | 116      |\n",
            "| time/              |          |\n",
            "|    fps             | 259      |\n",
            "|    iterations      | 340      |\n",
            "|    time_elapsed    | 2684     |\n",
            "|    total_timesteps | 696320   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 444         |\n",
            "|    ep_rew_mean          | 117         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 260         |\n",
            "|    iterations           | 341         |\n",
            "|    time_elapsed         | 2685        |\n",
            "|    total_timesteps      | 698368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004269965 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.633      |\n",
            "|    explained_variance   | 0.814       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 50.1        |\n",
            "|    n_updates            | 3400        |\n",
            "|    policy_gradient_loss | -0.00111    |\n",
            "|    value_loss           | 138         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=700000, episode_reward=82.23 +/- 126.50\n",
            "Episode length: 482.24 +/- 204.07\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 482         |\n",
            "|    mean_reward          | 82.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 700000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007575427 |\n",
            "|    clip_fraction        | 0.0806      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.609      |\n",
            "|    explained_variance   | 0.84        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.26        |\n",
            "|    n_updates            | 3410        |\n",
            "|    policy_gradient_loss | -0.00176    |\n",
            "|    value_loss           | 58.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 459      |\n",
            "|    ep_rew_mean     | 119      |\n",
            "| time/              |          |\n",
            "|    fps             | 259      |\n",
            "|    iterations      | 342      |\n",
            "|    time_elapsed    | 2696     |\n",
            "|    total_timesteps | 700416   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 461          |\n",
            "|    ep_rew_mean          | 124          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 260          |\n",
            "|    iterations           | 343          |\n",
            "|    time_elapsed         | 2698         |\n",
            "|    total_timesteps      | 702464       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054759574 |\n",
            "|    clip_fraction        | 0.0686       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.56        |\n",
            "|    explained_variance   | 0.892        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.65         |\n",
            "|    n_updates            | 3420         |\n",
            "|    policy_gradient_loss | -6.76e-05    |\n",
            "|    value_loss           | 17.8         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 459          |\n",
            "|    ep_rew_mean          | 121          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 260          |\n",
            "|    iterations           | 344          |\n",
            "|    time_elapsed         | 2700         |\n",
            "|    total_timesteps      | 704512       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042408844 |\n",
            "|    clip_fraction        | 0.0514       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0.728        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24.5         |\n",
            "|    n_updates            | 3430         |\n",
            "|    policy_gradient_loss | -0.00286     |\n",
            "|    value_loss           | 104          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=705000, episode_reward=79.21 +/- 123.89\n",
            "Episode length: 462.98 +/- 206.21\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 463         |\n",
            "|    mean_reward          | 79.2        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 705000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004175305 |\n",
            "|    clip_fraction        | 0.046       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.601      |\n",
            "|    explained_variance   | 0.78        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.7        |\n",
            "|    n_updates            | 3440        |\n",
            "|    policy_gradient_loss | -0.00225    |\n",
            "|    value_loss           | 73.1        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 470      |\n",
            "|    ep_rew_mean     | 127      |\n",
            "| time/              |          |\n",
            "|    fps             | 260      |\n",
            "|    iterations      | 345      |\n",
            "|    time_elapsed    | 2711     |\n",
            "|    total_timesteps | 706560   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 464         |\n",
            "|    ep_rew_mean          | 124         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 261         |\n",
            "|    iterations           | 346         |\n",
            "|    time_elapsed         | 2712        |\n",
            "|    total_timesteps      | 708608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004450105 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.642      |\n",
            "|    explained_variance   | 0.806       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37.6        |\n",
            "|    n_updates            | 3450        |\n",
            "|    policy_gradient_loss | -0.00206    |\n",
            "|    value_loss           | 65.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=710000, episode_reward=77.01 +/- 116.93\n",
            "Episode length: 501.06 +/- 182.27\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 501         |\n",
            "|    mean_reward          | 77          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 710000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004184085 |\n",
            "|    clip_fraction        | 0.0281      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.557      |\n",
            "|    explained_variance   | 0.863       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.2        |\n",
            "|    n_updates            | 3460        |\n",
            "|    policy_gradient_loss | -8.43e-05   |\n",
            "|    value_loss           | 73.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 471      |\n",
            "|    ep_rew_mean     | 122      |\n",
            "| time/              |          |\n",
            "|    fps             | 260      |\n",
            "|    iterations      | 347      |\n",
            "|    time_elapsed    | 2724     |\n",
            "|    total_timesteps | 710656   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 463          |\n",
            "|    ep_rew_mean          | 126          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 261          |\n",
            "|    iterations           | 348          |\n",
            "|    time_elapsed         | 2725         |\n",
            "|    total_timesteps      | 712704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043755895 |\n",
            "|    clip_fraction        | 0.0483       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.57        |\n",
            "|    explained_variance   | 0.829        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26.6         |\n",
            "|    n_updates            | 3470         |\n",
            "|    policy_gradient_loss | -0.00127     |\n",
            "|    value_loss           | 78.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 460          |\n",
            "|    ep_rew_mean          | 121          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 262          |\n",
            "|    iterations           | 349          |\n",
            "|    time_elapsed         | 2727         |\n",
            "|    total_timesteps      | 714752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043708025 |\n",
            "|    clip_fraction        | 0.0424       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 51.8         |\n",
            "|    n_updates            | 3480         |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    value_loss           | 71.1         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=715000, episode_reward=80.06 +/- 127.55\n",
            "Episode length: 457.88 +/- 141.53\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 458          |\n",
            "|    mean_reward          | 80.1         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 715000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036358626 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.665       |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 74.2         |\n",
            "|    n_updates            | 3490         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 115          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 457      |\n",
            "|    ep_rew_mean     | 112      |\n",
            "| time/              |          |\n",
            "|    fps             | 261      |\n",
            "|    iterations      | 350      |\n",
            "|    time_elapsed    | 2737     |\n",
            "|    total_timesteps | 716800   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 454         |\n",
            "|    ep_rew_mean          | 107         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 262         |\n",
            "|    iterations           | 351         |\n",
            "|    time_elapsed         | 2738        |\n",
            "|    total_timesteps      | 718848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005682935 |\n",
            "|    clip_fraction        | 0.0348      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.629      |\n",
            "|    explained_variance   | 0.788       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 47.8        |\n",
            "|    n_updates            | 3500        |\n",
            "|    policy_gradient_loss | -0.000929   |\n",
            "|    value_loss           | 161         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=720000, episode_reward=57.98 +/- 134.23\n",
            "Episode length: 455.52 +/- 186.56\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 456          |\n",
            "|    mean_reward          | 58           |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 720000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048130606 |\n",
            "|    clip_fraction        | 0.0462       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.606       |\n",
            "|    explained_variance   | 0.828        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 40.5         |\n",
            "|    n_updates            | 3510         |\n",
            "|    policy_gradient_loss | -0.00215     |\n",
            "|    value_loss           | 91.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 465      |\n",
            "|    ep_rew_mean     | 107      |\n",
            "| time/              |          |\n",
            "|    fps             | 262      |\n",
            "|    iterations      | 352      |\n",
            "|    time_elapsed    | 2749     |\n",
            "|    total_timesteps | 720896   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 469          |\n",
            "|    ep_rew_mean          | 106          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 262          |\n",
            "|    iterations           | 353          |\n",
            "|    time_elapsed         | 2750         |\n",
            "|    total_timesteps      | 722944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044444567 |\n",
            "|    clip_fraction        | 0.0566       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.618       |\n",
            "|    explained_variance   | 0.897        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.41         |\n",
            "|    n_updates            | 3520         |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    value_loss           | 70.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 469          |\n",
            "|    ep_rew_mean          | 99.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 263          |\n",
            "|    iterations           | 354          |\n",
            "|    time_elapsed         | 2751         |\n",
            "|    total_timesteps      | 724992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049813553 |\n",
            "|    clip_fraction        | 0.0733       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.631       |\n",
            "|    explained_variance   | 0.958        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.6         |\n",
            "|    n_updates            | 3530         |\n",
            "|    policy_gradient_loss | 0.000509     |\n",
            "|    value_loss           | 19.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=725000, episode_reward=41.41 +/- 121.58\n",
            "Episode length: 435.04 +/- 187.78\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 435         |\n",
            "|    mean_reward          | 41.4        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 725000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011519852 |\n",
            "|    clip_fraction        | 0.0996      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.633      |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 42.3        |\n",
            "|    n_updates            | 3540        |\n",
            "|    policy_gradient_loss | -6.84e-05   |\n",
            "|    value_loss           | 40.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 480      |\n",
            "|    ep_rew_mean     | 103      |\n",
            "| time/              |          |\n",
            "|    fps             | 263      |\n",
            "|    iterations      | 355      |\n",
            "|    time_elapsed    | 2761     |\n",
            "|    total_timesteps | 727040   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 472         |\n",
            "|    ep_rew_mean          | 95.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 263         |\n",
            "|    iterations           | 356         |\n",
            "|    time_elapsed         | 2762        |\n",
            "|    total_timesteps      | 729088      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007519334 |\n",
            "|    clip_fraction        | 0.0692      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.555      |\n",
            "|    explained_variance   | 0.854       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 48.4        |\n",
            "|    n_updates            | 3550        |\n",
            "|    policy_gradient_loss | -0.00573    |\n",
            "|    value_loss           | 87.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=730000, episode_reward=85.89 +/- 117.33\n",
            "Episode length: 469.54 +/- 203.58\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 470         |\n",
            "|    mean_reward          | 85.9        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 730000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008359086 |\n",
            "|    clip_fraction        | 0.0926      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.625      |\n",
            "|    explained_variance   | 0.754       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.9        |\n",
            "|    n_updates            | 3560        |\n",
            "|    policy_gradient_loss | -0.00514    |\n",
            "|    value_loss           | 176         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 462      |\n",
            "|    ep_rew_mean     | 96.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 263      |\n",
            "|    iterations      | 357      |\n",
            "|    time_elapsed    | 2773     |\n",
            "|    total_timesteps | 731136   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 465         |\n",
            "|    ep_rew_mean          | 95.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 264         |\n",
            "|    iterations           | 358         |\n",
            "|    time_elapsed         | 2775        |\n",
            "|    total_timesteps      | 733184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002858717 |\n",
            "|    clip_fraction        | 0.0427      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.564      |\n",
            "|    explained_variance   | 0.835       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 11.3        |\n",
            "|    n_updates            | 3570        |\n",
            "|    policy_gradient_loss | -0.00263    |\n",
            "|    value_loss           | 94.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=735000, episode_reward=100.61 +/- 116.37\n",
            "Episode length: 458.04 +/- 166.73\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 458          |\n",
            "|    mean_reward          | 101          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 735000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077757034 |\n",
            "|    clip_fraction        | 0.146        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.937        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.991        |\n",
            "|    n_updates            | 3580         |\n",
            "|    policy_gradient_loss | 0.00229      |\n",
            "|    value_loss           | 17.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 469      |\n",
            "|    ep_rew_mean     | 100      |\n",
            "| time/              |          |\n",
            "|    fps             | 263      |\n",
            "|    iterations      | 359      |\n",
            "|    time_elapsed    | 2786     |\n",
            "|    total_timesteps | 735232   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 463          |\n",
            "|    ep_rew_mean          | 95.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 264          |\n",
            "|    iterations           | 360          |\n",
            "|    time_elapsed         | 2787         |\n",
            "|    total_timesteps      | 737280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034229993 |\n",
            "|    clip_fraction        | 0.0296       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.588       |\n",
            "|    explained_variance   | 0.846        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 33.4         |\n",
            "|    n_updates            | 3590         |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    value_loss           | 95.1         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | 95.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 265         |\n",
            "|    iterations           | 361         |\n",
            "|    time_elapsed         | 2789        |\n",
            "|    total_timesteps      | 739328      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004308117 |\n",
            "|    clip_fraction        | 0.0295      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.61       |\n",
            "|    explained_variance   | 0.832       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.9        |\n",
            "|    n_updates            | 3600        |\n",
            "|    policy_gradient_loss | -0.00232    |\n",
            "|    value_loss           | 98.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=740000, episode_reward=78.91 +/- 123.89\n",
            "Episode length: 457.18 +/- 176.34\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 457          |\n",
            "|    mean_reward          | 78.9         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 740000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031471269 |\n",
            "|    clip_fraction        | 0.0262       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.604       |\n",
            "|    explained_variance   | 0.821        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28           |\n",
            "|    n_updates            | 3610         |\n",
            "|    policy_gradient_loss | -0.00195     |\n",
            "|    value_loss           | 51.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 469      |\n",
            "|    ep_rew_mean     | 89.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 264      |\n",
            "|    iterations      | 362      |\n",
            "|    time_elapsed    | 2799     |\n",
            "|    total_timesteps | 741376   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 471          |\n",
            "|    ep_rew_mean          | 92.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 265          |\n",
            "|    iterations           | 363          |\n",
            "|    time_elapsed         | 2801         |\n",
            "|    total_timesteps      | 743424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043630367 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 82.1         |\n",
            "|    n_updates            | 3620         |\n",
            "|    policy_gradient_loss | -0.00186     |\n",
            "|    value_loss           | 160          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=745000, episode_reward=74.86 +/- 113.95\n",
            "Episode length: 495.34 +/- 191.28\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 495         |\n",
            "|    mean_reward          | 74.9        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 745000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004104445 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.634      |\n",
            "|    explained_variance   | 0.764       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 3630        |\n",
            "|    policy_gradient_loss | -0.00144    |\n",
            "|    value_loss           | 72.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 468      |\n",
            "|    ep_rew_mean     | 88.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 265      |\n",
            "|    iterations      | 364      |\n",
            "|    time_elapsed    | 2813     |\n",
            "|    total_timesteps | 745472   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 457         |\n",
            "|    ep_rew_mean          | 87.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 265         |\n",
            "|    iterations           | 365         |\n",
            "|    time_elapsed         | 2814        |\n",
            "|    total_timesteps      | 747520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004251223 |\n",
            "|    clip_fraction        | 0.0414      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.561      |\n",
            "|    explained_variance   | 0.878       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.3        |\n",
            "|    n_updates            | 3640        |\n",
            "|    policy_gradient_loss | -0.000522   |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 456         |\n",
            "|    ep_rew_mean          | 84.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 266         |\n",
            "|    iterations           | 366         |\n",
            "|    time_elapsed         | 2815        |\n",
            "|    total_timesteps      | 749568      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004568072 |\n",
            "|    clip_fraction        | 0.0395      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.585      |\n",
            "|    explained_variance   | 0.745       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 63.2        |\n",
            "|    n_updates            | 3650        |\n",
            "|    policy_gradient_loss | -0.0029     |\n",
            "|    value_loss           | 107         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=750000, episode_reward=84.79 +/- 123.35\n",
            "Episode length: 455.82 +/- 134.00\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 456          |\n",
            "|    mean_reward          | 84.8         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 750000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0046950513 |\n",
            "|    clip_fraction        | 0.0542       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.651       |\n",
            "|    explained_variance   | 0.84         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.1         |\n",
            "|    n_updates            | 3660         |\n",
            "|    policy_gradient_loss | -0.00302     |\n",
            "|    value_loss           | 80.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 455      |\n",
            "|    ep_rew_mean     | 85.2     |\n",
            "| time/              |          |\n",
            "|    fps             | 266      |\n",
            "|    iterations      | 367      |\n",
            "|    time_elapsed    | 2825     |\n",
            "|    total_timesteps | 751616   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 462         |\n",
            "|    ep_rew_mean          | 83.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 266         |\n",
            "|    iterations           | 368         |\n",
            "|    time_elapsed         | 2826        |\n",
            "|    total_timesteps      | 753664      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.036567602 |\n",
            "|    clip_fraction        | 0.189       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.692      |\n",
            "|    explained_variance   | 0.923       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.72        |\n",
            "|    n_updates            | 3670        |\n",
            "|    policy_gradient_loss | -0.02       |\n",
            "|    value_loss           | 15.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=755000, episode_reward=91.04 +/- 118.24\n",
            "Episode length: 496.02 +/- 198.32\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 496         |\n",
            "|    mean_reward          | 91          |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 755000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007841443 |\n",
            "|    clip_fraction        | 0.067       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.646      |\n",
            "|    explained_variance   | 0.694       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 52.9        |\n",
            "|    n_updates            | 3680        |\n",
            "|    policy_gradient_loss | -0.00367    |\n",
            "|    value_loss           | 139         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 459      |\n",
            "|    ep_rew_mean     | 81.7     |\n",
            "| time/              |          |\n",
            "|    fps             | 266      |\n",
            "|    iterations      | 369      |\n",
            "|    time_elapsed    | 2838     |\n",
            "|    total_timesteps | 755712   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 463          |\n",
            "|    ep_rew_mean          | 83.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 266          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 2840         |\n",
            "|    total_timesteps      | 757760       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031163208 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.557       |\n",
            "|    explained_variance   | 0.811        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11.8         |\n",
            "|    n_updates            | 3690         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    value_loss           | 118          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 467         |\n",
            "|    ep_rew_mean          | 81.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 267         |\n",
            "|    iterations           | 371         |\n",
            "|    time_elapsed         | 2841        |\n",
            "|    total_timesteps      | 759808      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015636366 |\n",
            "|    clip_fraction        | 0.0634      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.908       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.24        |\n",
            "|    n_updates            | 3700        |\n",
            "|    policy_gradient_loss | -0.00424    |\n",
            "|    value_loss           | 41.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=760000, episode_reward=102.89 +/- 132.72\n",
            "Episode length: 505.68 +/- 158.11\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 506         |\n",
            "|    mean_reward          | 103         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 760000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004189471 |\n",
            "|    clip_fraction        | 0.0346      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.603      |\n",
            "|    explained_variance   | 0.729       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 60.8        |\n",
            "|    n_updates            | 3710        |\n",
            "|    policy_gradient_loss | -0.00113    |\n",
            "|    value_loss           | 134         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 466      |\n",
            "|    ep_rew_mean     | 88.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 266      |\n",
            "|    iterations      | 372      |\n",
            "|    time_elapsed    | 2853     |\n",
            "|    total_timesteps | 761856   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 476          |\n",
            "|    ep_rew_mean          | 88.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 267          |\n",
            "|    iterations           | 373          |\n",
            "|    time_elapsed         | 2855         |\n",
            "|    total_timesteps      | 763904       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043797884 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.852        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 33.9         |\n",
            "|    n_updates            | 3720         |\n",
            "|    policy_gradient_loss | -0.00129     |\n",
            "|    value_loss           | 72.7         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=765000, episode_reward=22.55 +/- 128.87\n",
            "Episode length: 401.20 +/- 142.73\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 401         |\n",
            "|    mean_reward          | 22.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 765000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008550739 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.67       |\n",
            "|    explained_variance   | 0.901       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.52        |\n",
            "|    n_updates            | 3730        |\n",
            "|    policy_gradient_loss | -0.00249    |\n",
            "|    value_loss           | 44.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 480      |\n",
            "|    ep_rew_mean     | 92.9     |\n",
            "| time/              |          |\n",
            "|    fps             | 267      |\n",
            "|    iterations      | 374      |\n",
            "|    time_elapsed    | 2863     |\n",
            "|    total_timesteps | 765952   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 488         |\n",
            "|    ep_rew_mean          | 90.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 268         |\n",
            "|    iterations           | 375         |\n",
            "|    time_elapsed         | 2865        |\n",
            "|    total_timesteps      | 768000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009332871 |\n",
            "|    clip_fraction        | 0.0701      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.514      |\n",
            "|    explained_variance   | 0.817       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 29.2        |\n",
            "|    n_updates            | 3740        |\n",
            "|    policy_gradient_loss | -0.00285    |\n",
            "|    value_loss           | 103         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=770000, episode_reward=75.54 +/- 126.01\n",
            "Episode length: 517.50 +/- 184.97\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 518         |\n",
            "|    mean_reward          | 75.5        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 770000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010909909 |\n",
            "|    clip_fraction        | 0.0987      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.586      |\n",
            "|    explained_variance   | 0.909       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.84        |\n",
            "|    n_updates            | 3750        |\n",
            "|    policy_gradient_loss | -0.00158    |\n",
            "|    value_loss           | 29.9        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 478      |\n",
            "|    ep_rew_mean     | 95.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 267      |\n",
            "|    iterations      | 376      |\n",
            "|    time_elapsed    | 2877     |\n",
            "|    total_timesteps | 770048   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 487          |\n",
            "|    ep_rew_mean          | 93.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 268          |\n",
            "|    iterations           | 377          |\n",
            "|    time_elapsed         | 2878         |\n",
            "|    total_timesteps      | 772096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047860597 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.619       |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18.6         |\n",
            "|    n_updates            | 3760         |\n",
            "|    policy_gradient_loss | 0.00049      |\n",
            "|    value_loss           | 77.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 488         |\n",
            "|    ep_rew_mean          | 93.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 268         |\n",
            "|    iterations           | 378         |\n",
            "|    time_elapsed         | 2880        |\n",
            "|    total_timesteps      | 774144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009671217 |\n",
            "|    clip_fraction        | 0.0596      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.617      |\n",
            "|    explained_variance   | 0.874       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 34.7        |\n",
            "|    n_updates            | 3770        |\n",
            "|    policy_gradient_loss | -0.00338    |\n",
            "|    value_loss           | 51.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=775000, episode_reward=66.82 +/- 116.07\n",
            "Episode length: 518.72 +/- 220.84\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 519          |\n",
            "|    mean_reward          | 66.8         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 775000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0058950675 |\n",
            "|    clip_fraction        | 0.0518       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 0.864        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 21.7         |\n",
            "|    n_updates            | 3780         |\n",
            "|    policy_gradient_loss | -0.00463     |\n",
            "|    value_loss           | 96.2         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 485      |\n",
            "|    ep_rew_mean     | 91       |\n",
            "| time/              |          |\n",
            "|    fps             | 268      |\n",
            "|    iterations      | 379      |\n",
            "|    time_elapsed    | 2892     |\n",
            "|    total_timesteps | 776192   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 488          |\n",
            "|    ep_rew_mean          | 88.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 268          |\n",
            "|    iterations           | 380          |\n",
            "|    time_elapsed         | 2894         |\n",
            "|    total_timesteps      | 778240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0065930868 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.529       |\n",
            "|    explained_variance   | 0.902        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.61         |\n",
            "|    n_updates            | 3790         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 48.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=780000, episode_reward=81.79 +/- 126.16\n",
            "Episode length: 536.84 +/- 222.83\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 537         |\n",
            "|    mean_reward          | 81.8        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 780000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007995464 |\n",
            "|    clip_fraction        | 0.0781      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.662      |\n",
            "|    explained_variance   | 0.86        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.44        |\n",
            "|    n_updates            | 3800        |\n",
            "|    policy_gradient_loss | -0.00315    |\n",
            "|    value_loss           | 58          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 482      |\n",
            "|    ep_rew_mean     | 86.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 268      |\n",
            "|    iterations      | 381      |\n",
            "|    time_elapsed    | 2907     |\n",
            "|    total_timesteps | 780288   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 485          |\n",
            "|    ep_rew_mean          | 84.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 268          |\n",
            "|    iterations           | 382          |\n",
            "|    time_elapsed         | 2908         |\n",
            "|    total_timesteps      | 782336       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052950075 |\n",
            "|    clip_fraction        | 0.0582       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.563       |\n",
            "|    explained_variance   | 0.865        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 26           |\n",
            "|    n_updates            | 3810         |\n",
            "|    policy_gradient_loss | -0.0032      |\n",
            "|    value_loss           | 89.4         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 486          |\n",
            "|    ep_rew_mean          | 76           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 269          |\n",
            "|    iterations           | 383          |\n",
            "|    time_elapsed         | 2910         |\n",
            "|    total_timesteps      | 784384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060143564 |\n",
            "|    clip_fraction        | 0.0612       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.65        |\n",
            "|    explained_variance   | 0.878        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 54.6         |\n",
            "|    n_updates            | 3820         |\n",
            "|    policy_gradient_loss | -0.00675     |\n",
            "|    value_loss           | 71.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=785000, episode_reward=108.48 +/- 105.76\n",
            "Episode length: 567.34 +/- 176.49\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 567          |\n",
            "|    mean_reward          | 108          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 785000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051407004 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.587       |\n",
            "|    explained_variance   | 0.804        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18           |\n",
            "|    n_updates            | 3830         |\n",
            "|    policy_gradient_loss | -0.00317     |\n",
            "|    value_loss           | 149          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 492      |\n",
            "|    ep_rew_mean     | 78.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 268      |\n",
            "|    iterations      | 384      |\n",
            "|    time_elapsed    | 2924     |\n",
            "|    total_timesteps | 786432   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 502         |\n",
            "|    ep_rew_mean          | 80.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 269         |\n",
            "|    iterations           | 385         |\n",
            "|    time_elapsed         | 2925        |\n",
            "|    total_timesteps      | 788480      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007829988 |\n",
            "|    clip_fraction        | 0.1         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 0.821       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 41          |\n",
            "|    n_updates            | 3840        |\n",
            "|    policy_gradient_loss | -0.00307    |\n",
            "|    value_loss           | 49.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=790000, episode_reward=111.71 +/- 124.01\n",
            "Episode length: 496.62 +/- 145.92\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 497         |\n",
            "|    mean_reward          | 112         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 790000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004398076 |\n",
            "|    clip_fraction        | 0.0461      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.589      |\n",
            "|    explained_variance   | 0.88        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 13.1        |\n",
            "|    n_updates            | 3850        |\n",
            "|    policy_gradient_loss | -0.00294    |\n",
            "|    value_loss           | 71          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 501      |\n",
            "|    ep_rew_mean     | 79.5     |\n",
            "| time/              |          |\n",
            "|    fps             | 269      |\n",
            "|    iterations      | 386      |\n",
            "|    time_elapsed    | 2937     |\n",
            "|    total_timesteps | 790528   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 503          |\n",
            "|    ep_rew_mean          | 84.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 269          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 2938         |\n",
            "|    total_timesteps      | 792576       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035710419 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.646       |\n",
            "|    explained_variance   | 0.687        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 108          |\n",
            "|    n_updates            | 3860         |\n",
            "|    policy_gradient_loss | -0.00249     |\n",
            "|    value_loss           | 146          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 507         |\n",
            "|    ep_rew_mean          | 84.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 270         |\n",
            "|    iterations           | 388         |\n",
            "|    time_elapsed         | 2939        |\n",
            "|    total_timesteps      | 794624      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004833649 |\n",
            "|    clip_fraction        | 0.0424      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.628      |\n",
            "|    explained_variance   | 0.647       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25.9        |\n",
            "|    n_updates            | 3870        |\n",
            "|    policy_gradient_loss | -0.00198    |\n",
            "|    value_loss           | 85.6        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=795000, episode_reward=78.28 +/- 116.91\n",
            "Episode length: 525.40 +/- 202.74\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 525         |\n",
            "|    mean_reward          | 78.3        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 795000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004208913 |\n",
            "|    clip_fraction        | 0.0467      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.608      |\n",
            "|    explained_variance   | 0.881       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.8        |\n",
            "|    n_updates            | 3880        |\n",
            "|    policy_gradient_loss | -0.00177    |\n",
            "|    value_loss           | 79.2        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 511      |\n",
            "|    ep_rew_mean     | 90       |\n",
            "| time/              |          |\n",
            "|    fps             | 269      |\n",
            "|    iterations      | 389      |\n",
            "|    time_elapsed    | 2952     |\n",
            "|    total_timesteps | 796672   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 511          |\n",
            "|    ep_rew_mean          | 90.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 270          |\n",
            "|    iterations           | 390          |\n",
            "|    time_elapsed         | 2954         |\n",
            "|    total_timesteps      | 798720       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0083928015 |\n",
            "|    clip_fraction        | 0.078        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0.795        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 18           |\n",
            "|    n_updates            | 3890         |\n",
            "|    policy_gradient_loss | -0.00141     |\n",
            "|    value_loss           | 117          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=800000, episode_reward=92.12 +/- 120.61\n",
            "Episode length: 499.38 +/- 164.33\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 499          |\n",
            "|    mean_reward          | 92.1         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 800000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056880154 |\n",
            "|    clip_fraction        | 0.074        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.588       |\n",
            "|    explained_variance   | 0.851        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 155          |\n",
            "|    n_updates            | 3900         |\n",
            "|    policy_gradient_loss | -0.00314     |\n",
            "|    value_loss           | 103          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 516      |\n",
            "|    ep_rew_mean     | 88.4     |\n",
            "| time/              |          |\n",
            "|    fps             | 269      |\n",
            "|    iterations      | 391      |\n",
            "|    time_elapsed    | 2966     |\n",
            "|    total_timesteps | 800768   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 532          |\n",
            "|    ep_rew_mean          | 92           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 270          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 2968         |\n",
            "|    total_timesteps      | 802816       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033320207 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.506       |\n",
            "|    explained_variance   | 0.846        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.1         |\n",
            "|    n_updates            | 3910         |\n",
            "|    policy_gradient_loss | -0.00181     |\n",
            "|    value_loss           | 60.4         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 531         |\n",
            "|    ep_rew_mean          | 91.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 270         |\n",
            "|    iterations           | 393         |\n",
            "|    time_elapsed         | 2970        |\n",
            "|    total_timesteps      | 804864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005429939 |\n",
            "|    clip_fraction        | 0.0533      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.507      |\n",
            "|    explained_variance   | 0.734       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.9        |\n",
            "|    n_updates            | 3920        |\n",
            "|    policy_gradient_loss | -0.00145    |\n",
            "|    value_loss           | 79.3        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=805000, episode_reward=112.56 +/- 103.42\n",
            "Episode length: 512.44 +/- 147.83\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 512         |\n",
            "|    mean_reward          | 113         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 805000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019325852 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.613      |\n",
            "|    explained_variance   | 0.891       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.72        |\n",
            "|    n_updates            | 3930        |\n",
            "|    policy_gradient_loss | -0.00346    |\n",
            "|    value_loss           | 20.6        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 544      |\n",
            "|    ep_rew_mean     | 97.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 394      |\n",
            "|    time_elapsed    | 2983     |\n",
            "|    total_timesteps | 806912   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 542         |\n",
            "|    ep_rew_mean          | 95.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 270         |\n",
            "|    iterations           | 395         |\n",
            "|    time_elapsed         | 2985        |\n",
            "|    total_timesteps      | 808960      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013020676 |\n",
            "|    clip_fraction        | 0.134       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.63       |\n",
            "|    explained_variance   | 0.918       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.38        |\n",
            "|    n_updates            | 3940        |\n",
            "|    policy_gradient_loss | -0.00219    |\n",
            "|    value_loss           | 13.5        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=810000, episode_reward=102.77 +/- 110.23\n",
            "Episode length: 518.20 +/- 204.16\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 518         |\n",
            "|    mean_reward          | 103         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 810000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004746161 |\n",
            "|    clip_fraction        | 0.0593      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.683      |\n",
            "|    explained_variance   | 0.838       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.7        |\n",
            "|    n_updates            | 3950        |\n",
            "|    policy_gradient_loss | 0.000529    |\n",
            "|    value_loss           | 50.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 552      |\n",
            "|    ep_rew_mean     | 94.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 396      |\n",
            "|    time_elapsed    | 2997     |\n",
            "|    total_timesteps | 811008   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 552          |\n",
            "|    ep_rew_mean          | 94.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 271          |\n",
            "|    iterations           | 397          |\n",
            "|    time_elapsed         | 2999         |\n",
            "|    total_timesteps      | 813056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042946106 |\n",
            "|    clip_fraction        | 0.0272       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.633       |\n",
            "|    explained_variance   | 0.505        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 36.1         |\n",
            "|    n_updates            | 3960         |\n",
            "|    policy_gradient_loss | -0.00256     |\n",
            "|    value_loss           | 101          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=815000, episode_reward=122.78 +/- 113.23\n",
            "Episode length: 524.84 +/- 194.92\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 525        |\n",
            "|    mean_reward          | 123        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 815000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00597156 |\n",
            "|    clip_fraction        | 0.0563     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.582     |\n",
            "|    explained_variance   | 0.687      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13         |\n",
            "|    n_updates            | 3970       |\n",
            "|    policy_gradient_loss | -0.0036    |\n",
            "|    value_loss           | 98         |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 552      |\n",
            "|    ep_rew_mean     | 100      |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 398      |\n",
            "|    time_elapsed    | 3012     |\n",
            "|    total_timesteps | 815104   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 560         |\n",
            "|    ep_rew_mean          | 99.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 271         |\n",
            "|    iterations           | 399         |\n",
            "|    time_elapsed         | 3013        |\n",
            "|    total_timesteps      | 817152      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003813163 |\n",
            "|    clip_fraction        | 0.0305      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.651      |\n",
            "|    explained_variance   | 0.799       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.56        |\n",
            "|    n_updates            | 3980        |\n",
            "|    policy_gradient_loss | -0.00116    |\n",
            "|    value_loss           | 53.6        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 566          |\n",
            "|    ep_rew_mean          | 95.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 271          |\n",
            "|    iterations           | 400          |\n",
            "|    time_elapsed         | 3015         |\n",
            "|    total_timesteps      | 819200       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072191907 |\n",
            "|    clip_fraction        | 0.0868       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0.852        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.32         |\n",
            "|    n_updates            | 3990         |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    value_loss           | 50.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=820000, episode_reward=123.33 +/- 103.42\n",
            "Episode length: 530.38 +/- 188.20\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 530          |\n",
            "|    mean_reward          | 123          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 820000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0074557755 |\n",
            "|    clip_fraction        | 0.0931       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.689       |\n",
            "|    explained_variance   | 0.781        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 35.4         |\n",
            "|    n_updates            | 4000         |\n",
            "|    policy_gradient_loss | -0.00298     |\n",
            "|    value_loss           | 45           |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 573      |\n",
            "|    ep_rew_mean     | 98.8     |\n",
            "| time/              |          |\n",
            "|    fps             | 271      |\n",
            "|    iterations      | 401      |\n",
            "|    time_elapsed    | 3028     |\n",
            "|    total_timesteps | 821248   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 566         |\n",
            "|    ep_rew_mean          | 93.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 271         |\n",
            "|    iterations           | 402         |\n",
            "|    time_elapsed         | 3029        |\n",
            "|    total_timesteps      | 823296      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004807807 |\n",
            "|    clip_fraction        | 0.0543      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.59       |\n",
            "|    explained_variance   | 0.901       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.7        |\n",
            "|    n_updates            | 4010        |\n",
            "|    policy_gradient_loss | -0.00163    |\n",
            "|    value_loss           | 40.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=825000, episode_reward=127.56 +/- 115.30\n",
            "Episode length: 556.18 +/- 167.35\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 556          |\n",
            "|    mean_reward          | 128          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 825000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038724355 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | 0.837        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.48         |\n",
            "|    n_updates            | 4020         |\n",
            "|    policy_gradient_loss | -0.000643    |\n",
            "|    value_loss           | 58.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 568      |\n",
            "|    ep_rew_mean     | 96.6     |\n",
            "| time/              |          |\n",
            "|    fps             | 271      |\n",
            "|    iterations      | 403      |\n",
            "|    time_elapsed    | 3042     |\n",
            "|    total_timesteps | 825344   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 581          |\n",
            "|    ep_rew_mean          | 96.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 271          |\n",
            "|    iterations           | 404          |\n",
            "|    time_elapsed         | 3043         |\n",
            "|    total_timesteps      | 827392       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054823225 |\n",
            "|    clip_fraction        | 0.0645       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.582       |\n",
            "|    explained_variance   | 0.942        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.9          |\n",
            "|    n_updates            | 4030         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 21.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 571         |\n",
            "|    ep_rew_mean          | 99.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 272         |\n",
            "|    iterations           | 405         |\n",
            "|    time_elapsed         | 3045        |\n",
            "|    total_timesteps      | 829440      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028162789 |\n",
            "|    clip_fraction        | 0.0663      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.561      |\n",
            "|    explained_variance   | 0.75        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 86.7        |\n",
            "|    n_updates            | 4040        |\n",
            "|    policy_gradient_loss | -0.0102     |\n",
            "|    value_loss           | 92.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=830000, episode_reward=84.13 +/- 132.41\n",
            "Episode length: 453.12 +/- 146.85\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 453          |\n",
            "|    mean_reward          | 84.1         |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 830000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070666093 |\n",
            "|    clip_fraction        | 0.0551       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.618       |\n",
            "|    explained_variance   | 0.85         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.53         |\n",
            "|    n_updates            | 4050         |\n",
            "|    policy_gradient_loss | -0.000521    |\n",
            "|    value_loss           | 50.6         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 586      |\n",
            "|    ep_rew_mean     | 104      |\n",
            "| time/              |          |\n",
            "|    fps             | 272      |\n",
            "|    iterations      | 406      |\n",
            "|    time_elapsed    | 3055     |\n",
            "|    total_timesteps | 831488   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 580          |\n",
            "|    ep_rew_mean          | 102          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 272          |\n",
            "|    iterations           | 407          |\n",
            "|    time_elapsed         | 3056         |\n",
            "|    total_timesteps      | 833536       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060380893 |\n",
            "|    clip_fraction        | 0.0592       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.524       |\n",
            "|    explained_variance   | 0.598        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 28.8         |\n",
            "|    n_updates            | 4060         |\n",
            "|    policy_gradient_loss | -0.00236     |\n",
            "|    value_loss           | 58.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=835000, episode_reward=143.17 +/- 102.86\n",
            "Episode length: 502.54 +/- 128.28\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 503         |\n",
            "|    mean_reward          | 143         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 835000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006864786 |\n",
            "|    clip_fraction        | 0.0521      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0.355       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 19.9        |\n",
            "|    n_updates            | 4070        |\n",
            "|    policy_gradient_loss | -0.00108    |\n",
            "|    value_loss           | 214         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 580      |\n",
            "|    ep_rew_mean     | 108      |\n",
            "| time/              |          |\n",
            "|    fps             | 272      |\n",
            "|    iterations      | 408      |\n",
            "|    time_elapsed    | 3068     |\n",
            "|    total_timesteps | 835584   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 581          |\n",
            "|    ep_rew_mean          | 112          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 272          |\n",
            "|    iterations           | 409          |\n",
            "|    time_elapsed         | 3069         |\n",
            "|    total_timesteps      | 837632       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048427237 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.647       |\n",
            "|    explained_variance   | 0.76         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 20.3         |\n",
            "|    n_updates            | 4080         |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    value_loss           | 125          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 576          |\n",
            "|    ep_rew_mean          | 117          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 273          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 3070         |\n",
            "|    total_timesteps      | 839680       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066149468 |\n",
            "|    clip_fraction        | 0.0567       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.626       |\n",
            "|    explained_variance   | 0.91         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.97         |\n",
            "|    n_updates            | 4090         |\n",
            "|    policy_gradient_loss | -0.00306     |\n",
            "|    value_loss           | 42.3         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=840000, episode_reward=124.01 +/- 117.98\n",
            "Episode length: 504.22 +/- 182.79\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 504          |\n",
            "|    mean_reward          | 124          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 840000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033267124 |\n",
            "|    clip_fraction        | 0.0329       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.584       |\n",
            "|    explained_variance   | 0.887        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 167          |\n",
            "|    n_updates            | 4100         |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    value_loss           | 90.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 580      |\n",
            "|    ep_rew_mean     | 125      |\n",
            "| time/              |          |\n",
            "|    fps             | 273      |\n",
            "|    iterations      | 411      |\n",
            "|    time_elapsed    | 3082     |\n",
            "|    total_timesteps | 841728   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 581          |\n",
            "|    ep_rew_mean          | 127          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 273          |\n",
            "|    iterations           | 412          |\n",
            "|    time_elapsed         | 3083         |\n",
            "|    total_timesteps      | 843776       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0072397576 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.635       |\n",
            "|    explained_variance   | 0.95         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.43         |\n",
            "|    n_updates            | 4110         |\n",
            "|    policy_gradient_loss | -0.0061      |\n",
            "|    value_loss           | 22.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=845000, episode_reward=150.45 +/- 97.64\n",
            "Episode length: 466.98 +/- 164.44\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 467         |\n",
            "|    mean_reward          | 150         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 845000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005632403 |\n",
            "|    clip_fraction        | 0.0624      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.62       |\n",
            "|    explained_variance   | 0.949       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.1        |\n",
            "|    n_updates            | 4120        |\n",
            "|    policy_gradient_loss | -0.00247    |\n",
            "|    value_loss           | 46          |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 570      |\n",
            "|    ep_rew_mean     | 130      |\n",
            "| time/              |          |\n",
            "|    fps             | 273      |\n",
            "|    iterations      | 413      |\n",
            "|    time_elapsed    | 3094     |\n",
            "|    total_timesteps | 845824   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 566          |\n",
            "|    ep_rew_mean          | 127          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 273          |\n",
            "|    iterations           | 414          |\n",
            "|    time_elapsed         | 3095         |\n",
            "|    total_timesteps      | 847872       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022957805 |\n",
            "|    clip_fraction        | 0.0311       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.499       |\n",
            "|    explained_variance   | 0.826        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 33.9         |\n",
            "|    n_updates            | 4130         |\n",
            "|    policy_gradient_loss | -4.59e-05    |\n",
            "|    value_loss           | 85.8         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 558         |\n",
            "|    ep_rew_mean          | 131         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 274         |\n",
            "|    iterations           | 415         |\n",
            "|    time_elapsed         | 3096        |\n",
            "|    total_timesteps      | 849920      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007326929 |\n",
            "|    clip_fraction        | 0.0729      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0.887       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.22        |\n",
            "|    n_updates            | 4140        |\n",
            "|    policy_gradient_loss | -0.00412    |\n",
            "|    value_loss           | 70.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=850000, episode_reward=121.53 +/- 112.18\n",
            "Episode length: 508.64 +/- 177.29\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 509         |\n",
            "|    mean_reward          | 122         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 850000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006026768 |\n",
            "|    clip_fraction        | 0.0691      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.495      |\n",
            "|    explained_variance   | 0.836       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 24.5        |\n",
            "|    n_updates            | 4150        |\n",
            "|    policy_gradient_loss | -0.0031     |\n",
            "|    value_loss           | 64.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 571      |\n",
            "|    ep_rew_mean     | 130      |\n",
            "| time/              |          |\n",
            "|    fps             | 274      |\n",
            "|    iterations      | 416      |\n",
            "|    time_elapsed    | 3108     |\n",
            "|    total_timesteps | 851968   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 572         |\n",
            "|    ep_rew_mean          | 130         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 274         |\n",
            "|    iterations           | 417         |\n",
            "|    time_elapsed         | 3109        |\n",
            "|    total_timesteps      | 854016      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008454487 |\n",
            "|    clip_fraction        | 0.0979      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.648      |\n",
            "|    explained_variance   | 0.97        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.37        |\n",
            "|    n_updates            | 4160        |\n",
            "|    policy_gradient_loss | -0.00637    |\n",
            "|    value_loss           | 14          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=855000, episode_reward=124.99 +/- 108.45\n",
            "Episode length: 478.34 +/- 215.10\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 478         |\n",
            "|    mean_reward          | 125         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 855000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011608664 |\n",
            "|    clip_fraction        | 0.117       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.658      |\n",
            "|    explained_variance   | 0.857       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.28        |\n",
            "|    n_updates            | 4170        |\n",
            "|    policy_gradient_loss | -0.00564    |\n",
            "|    value_loss           | 57.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 577      |\n",
            "|    ep_rew_mean     | 133      |\n",
            "| time/              |          |\n",
            "|    fps             | 274      |\n",
            "|    iterations      | 418      |\n",
            "|    time_elapsed    | 3120     |\n",
            "|    total_timesteps | 856064   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 582         |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 274         |\n",
            "|    iterations           | 419         |\n",
            "|    time_elapsed         | 3121        |\n",
            "|    total_timesteps      | 858112      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005721128 |\n",
            "|    clip_fraction        | 0.0791      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.528      |\n",
            "|    explained_variance   | 0.862       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.2        |\n",
            "|    n_updates            | 4180        |\n",
            "|    policy_gradient_loss | -0.000343   |\n",
            "|    value_loss           | 37.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=860000, episode_reward=128.67 +/- 110.27\n",
            "Episode length: 453.48 +/- 158.82\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 453         |\n",
            "|    mean_reward          | 129         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 860000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009161206 |\n",
            "|    clip_fraction        | 0.138       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.562      |\n",
            "|    explained_variance   | 0.658       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 22          |\n",
            "|    n_updates            | 4190        |\n",
            "|    policy_gradient_loss | -0.00316    |\n",
            "|    value_loss           | 23.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 578      |\n",
            "|    ep_rew_mean     | 133      |\n",
            "| time/              |          |\n",
            "|    fps             | 274      |\n",
            "|    iterations      | 420      |\n",
            "|    time_elapsed    | 3131     |\n",
            "|    total_timesteps | 860160   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 574         |\n",
            "|    ep_rew_mean          | 135         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 275         |\n",
            "|    iterations           | 421         |\n",
            "|    time_elapsed         | 3133        |\n",
            "|    total_timesteps      | 862208      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009050168 |\n",
            "|    clip_fraction        | 0.0646      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.484      |\n",
            "|    explained_variance   | 0.807       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.59        |\n",
            "|    n_updates            | 4200        |\n",
            "|    policy_gradient_loss | -0.0023     |\n",
            "|    value_loss           | 72.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 575         |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 275         |\n",
            "|    iterations           | 422         |\n",
            "|    time_elapsed         | 3135        |\n",
            "|    total_timesteps      | 864256      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007224287 |\n",
            "|    clip_fraction        | 0.0326      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.595      |\n",
            "|    explained_variance   | 0.629       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 32.1        |\n",
            "|    n_updates            | 4210        |\n",
            "|    policy_gradient_loss | -0.000901   |\n",
            "|    value_loss           | 64.7        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=865000, episode_reward=127.17 +/- 125.25\n",
            "Episode length: 513.26 +/- 170.26\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 513          |\n",
            "|    mean_reward          | 127          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 865000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0130462535 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.602       |\n",
            "|    explained_variance   | 0.777        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 16.3         |\n",
            "|    n_updates            | 4220         |\n",
            "|    policy_gradient_loss | -0.00314     |\n",
            "|    value_loss           | 24.8         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 569      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 275      |\n",
            "|    iterations      | 423      |\n",
            "|    time_elapsed    | 3147     |\n",
            "|    total_timesteps | 866304   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 561          |\n",
            "|    ep_rew_mean          | 136          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 275          |\n",
            "|    iterations           | 424          |\n",
            "|    time_elapsed         | 3148         |\n",
            "|    total_timesteps      | 868352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054516615 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0.666        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 94.1         |\n",
            "|    n_updates            | 4230         |\n",
            "|    policy_gradient_loss | -0.00188     |\n",
            "|    value_loss           | 130          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=870000, episode_reward=137.11 +/- 111.76\n",
            "Episode length: 467.84 +/- 174.07\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 468          |\n",
            "|    mean_reward          | 137          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 870000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0075661857 |\n",
            "|    clip_fraction        | 0.0443       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.58        |\n",
            "|    explained_variance   | 0.93         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.8          |\n",
            "|    n_updates            | 4240         |\n",
            "|    policy_gradient_loss | -0.00144     |\n",
            "|    value_loss           | 15.1         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 562      |\n",
            "|    ep_rew_mean     | 135      |\n",
            "| time/              |          |\n",
            "|    fps             | 275      |\n",
            "|    iterations      | 425      |\n",
            "|    time_elapsed    | 3159     |\n",
            "|    total_timesteps | 870400   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 545          |\n",
            "|    ep_rew_mean          | 135          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 276          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 3160         |\n",
            "|    total_timesteps      | 872448       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047558965 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.573       |\n",
            "|    explained_variance   | 0.7          |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.3         |\n",
            "|    n_updates            | 4250         |\n",
            "|    policy_gradient_loss | -0.00223     |\n",
            "|    value_loss           | 133          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 545          |\n",
            "|    ep_rew_mean          | 136          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 276          |\n",
            "|    iterations           | 427          |\n",
            "|    time_elapsed         | 3162         |\n",
            "|    total_timesteps      | 874496       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035696784 |\n",
            "|    clip_fraction        | 0.0391       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | 0.896        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 15.1         |\n",
            "|    n_updates            | 4260         |\n",
            "|    policy_gradient_loss | -0.00277     |\n",
            "|    value_loss           | 35.5         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=875000, episode_reward=131.72 +/- 103.06\n",
            "Episode length: 536.18 +/- 196.81\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 536        |\n",
            "|    mean_reward          | 132        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 875000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00658481 |\n",
            "|    clip_fraction        | 0.085      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.582     |\n",
            "|    explained_variance   | 0.646      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 21.8       |\n",
            "|    n_updates            | 4270       |\n",
            "|    policy_gradient_loss | -0.00237   |\n",
            "|    value_loss           | 118        |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 552      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 276      |\n",
            "|    iterations      | 428      |\n",
            "|    time_elapsed    | 3174     |\n",
            "|    total_timesteps | 876544   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 563        |\n",
            "|    ep_rew_mean          | 131        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 276        |\n",
            "|    iterations           | 429        |\n",
            "|    time_elapsed         | 3176       |\n",
            "|    total_timesteps      | 878592     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00878717 |\n",
            "|    clip_fraction        | 0.0925     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.589     |\n",
            "|    explained_variance   | 0.762      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 20.2       |\n",
            "|    n_updates            | 4280       |\n",
            "|    policy_gradient_loss | -0.000624  |\n",
            "|    value_loss           | 45.8       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=880000, episode_reward=141.65 +/- 90.88\n",
            "Episode length: 471.54 +/- 167.96\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 472         |\n",
            "|    mean_reward          | 142         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 880000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007178472 |\n",
            "|    clip_fraction        | 0.0453      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.6        |\n",
            "|    explained_variance   | 0.787       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.74        |\n",
            "|    n_updates            | 4290        |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    value_loss           | 67.8        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 567      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 276      |\n",
            "|    iterations      | 430      |\n",
            "|    time_elapsed    | 3187     |\n",
            "|    total_timesteps | 880640   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 563         |\n",
            "|    ep_rew_mean          | 134         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 276         |\n",
            "|    iterations           | 431         |\n",
            "|    time_elapsed         | 3189        |\n",
            "|    total_timesteps      | 882688      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011489483 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.569      |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.91        |\n",
            "|    n_updates            | 4300        |\n",
            "|    policy_gradient_loss | -0.00332    |\n",
            "|    value_loss           | 48.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 563         |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 277         |\n",
            "|    iterations           | 432         |\n",
            "|    time_elapsed         | 3190        |\n",
            "|    total_timesteps      | 884736      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005204973 |\n",
            "|    clip_fraction        | 0.0387      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.614      |\n",
            "|    explained_variance   | 0.699       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 21.5        |\n",
            "|    n_updates            | 4310        |\n",
            "|    policy_gradient_loss | -0.000186   |\n",
            "|    value_loss           | 58.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=885000, episode_reward=114.45 +/- 122.56\n",
            "Episode length: 552.96 +/- 248.15\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 553          |\n",
            "|    mean_reward          | 114          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 885000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0066067018 |\n",
            "|    clip_fraction        | 0.0756       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.603       |\n",
            "|    explained_variance   | 0.875        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.25         |\n",
            "|    n_updates            | 4320         |\n",
            "|    policy_gradient_loss | -0.00555     |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 568      |\n",
            "|    ep_rew_mean     | 132      |\n",
            "| time/              |          |\n",
            "|    fps             | 276      |\n",
            "|    iterations      | 433      |\n",
            "|    time_elapsed    | 3204     |\n",
            "|    total_timesteps | 886784   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 560         |\n",
            "|    ep_rew_mean          | 132         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 277         |\n",
            "|    iterations           | 434         |\n",
            "|    time_elapsed         | 3206        |\n",
            "|    total_timesteps      | 888832      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005517734 |\n",
            "|    clip_fraction        | 0.0495      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.56       |\n",
            "|    explained_variance   | 0.883       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.7        |\n",
            "|    n_updates            | 4330        |\n",
            "|    policy_gradient_loss | -0.00209    |\n",
            "|    value_loss           | 56.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=890000, episode_reward=139.82 +/- 101.07\n",
            "Episode length: 492.76 +/- 165.38\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 493          |\n",
            "|    mean_reward          | 140          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 890000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030881797 |\n",
            "|    clip_fraction        | 0.0381       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.541       |\n",
            "|    explained_variance   | 0.695        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 155          |\n",
            "|    n_updates            | 4340         |\n",
            "|    policy_gradient_loss | -0.00189     |\n",
            "|    value_loss           | 114          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 560      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 276      |\n",
            "|    iterations      | 435      |\n",
            "|    time_elapsed    | 3218     |\n",
            "|    total_timesteps | 890880   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 568         |\n",
            "|    ep_rew_mean          | 139         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 277         |\n",
            "|    iterations           | 436         |\n",
            "|    time_elapsed         | 3220        |\n",
            "|    total_timesteps      | 892928      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007157425 |\n",
            "|    clip_fraction        | 0.0733      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.565      |\n",
            "|    explained_variance   | 0.89        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.83        |\n",
            "|    n_updates            | 4350        |\n",
            "|    policy_gradient_loss | -0.00561    |\n",
            "|    value_loss           | 40.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 564         |\n",
            "|    ep_rew_mean          | 140         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 277         |\n",
            "|    iterations           | 437         |\n",
            "|    time_elapsed         | 3221        |\n",
            "|    total_timesteps      | 894976      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004712962 |\n",
            "|    clip_fraction        | 0.0715      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.505      |\n",
            "|    explained_variance   | 0.873       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 30.1        |\n",
            "|    n_updates            | 4360        |\n",
            "|    policy_gradient_loss | -0.00545    |\n",
            "|    value_loss           | 39.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=895000, episode_reward=128.20 +/- 103.55\n",
            "Episode length: 455.10 +/- 212.58\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 455         |\n",
            "|    mean_reward          | 128         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 895000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009576447 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.547      |\n",
            "|    explained_variance   | 0.704       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 43.2        |\n",
            "|    n_updates            | 4370        |\n",
            "|    policy_gradient_loss | -0.0026     |\n",
            "|    value_loss           | 109         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 576      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 277      |\n",
            "|    iterations      | 438      |\n",
            "|    time_elapsed    | 3232     |\n",
            "|    total_timesteps | 897024   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 576          |\n",
            "|    ep_rew_mean          | 131          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 278          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 3233         |\n",
            "|    total_timesteps      | 899072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0085212495 |\n",
            "|    clip_fraction        | 0.131        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.601       |\n",
            "|    explained_variance   | 0.601        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.86         |\n",
            "|    n_updates            | 4380         |\n",
            "|    policy_gradient_loss | -0.00378     |\n",
            "|    value_loss           | 73.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=900000, episode_reward=149.54 +/- 99.01\n",
            "Episode length: 460.32 +/- 138.61\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 460         |\n",
            "|    mean_reward          | 150         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 900000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009955919 |\n",
            "|    clip_fraction        | 0.0659      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.576      |\n",
            "|    explained_variance   | 0.875       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.71        |\n",
            "|    n_updates            | 4390        |\n",
            "|    policy_gradient_loss | -0.000265   |\n",
            "|    value_loss           | 33.3        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 575      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 277      |\n",
            "|    iterations      | 440      |\n",
            "|    time_elapsed    | 3244     |\n",
            "|    total_timesteps | 901120   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 577          |\n",
            "|    ep_rew_mean          | 140          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 278          |\n",
            "|    iterations           | 441          |\n",
            "|    time_elapsed         | 3246         |\n",
            "|    total_timesteps      | 903168       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054654544 |\n",
            "|    clip_fraction        | 0.071        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.491       |\n",
            "|    explained_variance   | 0.825        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 12.1         |\n",
            "|    n_updates            | 4400         |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    value_loss           | 55.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=905000, episode_reward=138.63 +/- 110.93\n",
            "Episode length: 505.74 +/- 198.19\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 506         |\n",
            "|    mean_reward          | 139         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 905000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007402366 |\n",
            "|    clip_fraction        | 0.0505      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.475      |\n",
            "|    explained_variance   | 0.778       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.92        |\n",
            "|    n_updates            | 4410        |\n",
            "|    policy_gradient_loss | -0.00328    |\n",
            "|    value_loss           | 70.4        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 576      |\n",
            "|    ep_rew_mean     | 147      |\n",
            "| time/              |          |\n",
            "|    fps             | 277      |\n",
            "|    iterations      | 442      |\n",
            "|    time_elapsed    | 3258     |\n",
            "|    total_timesteps | 905216   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 581         |\n",
            "|    ep_rew_mean          | 144         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 278         |\n",
            "|    iterations           | 443         |\n",
            "|    time_elapsed         | 3260        |\n",
            "|    total_timesteps      | 907264      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004775813 |\n",
            "|    clip_fraction        | 0.0513      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.537      |\n",
            "|    explained_variance   | 0.841       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.7        |\n",
            "|    n_updates            | 4420        |\n",
            "|    policy_gradient_loss | -0.00155    |\n",
            "|    value_loss           | 49.8        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 582         |\n",
            "|    ep_rew_mean          | 142         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 278         |\n",
            "|    iterations           | 444         |\n",
            "|    time_elapsed         | 3262        |\n",
            "|    total_timesteps      | 909312      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007672528 |\n",
            "|    clip_fraction        | 0.0539      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.489      |\n",
            "|    explained_variance   | 0.792       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 26.9        |\n",
            "|    n_updates            | 4430        |\n",
            "|    policy_gradient_loss | -0.00295    |\n",
            "|    value_loss           | 54.9        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=910000, episode_reward=143.26 +/- 95.71\n",
            "Episode length: 445.12 +/- 156.09\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 445         |\n",
            "|    mean_reward          | 143         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 910000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006392713 |\n",
            "|    clip_fraction        | 0.0952      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.507      |\n",
            "|    explained_variance   | 0.685       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.7        |\n",
            "|    n_updates            | 4440        |\n",
            "|    policy_gradient_loss | 0.00177     |\n",
            "|    value_loss           | 32.2        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 577      |\n",
            "|    ep_rew_mean     | 146      |\n",
            "| time/              |          |\n",
            "|    fps             | 278      |\n",
            "|    iterations      | 445      |\n",
            "|    time_elapsed    | 3272     |\n",
            "|    total_timesteps | 911360   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 576        |\n",
            "|    ep_rew_mean          | 144        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 278        |\n",
            "|    iterations           | 446        |\n",
            "|    time_elapsed         | 3274       |\n",
            "|    total_timesteps      | 913408     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01596944 |\n",
            "|    clip_fraction        | 0.0763     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.502     |\n",
            "|    explained_variance   | 0.85       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.84       |\n",
            "|    n_updates            | 4450       |\n",
            "|    policy_gradient_loss | -0.00526   |\n",
            "|    value_loss           | 31.7       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=915000, episode_reward=131.06 +/- 108.21\n",
            "Episode length: 469.92 +/- 176.38\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 470         |\n",
            "|    mean_reward          | 131         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 915000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004803739 |\n",
            "|    clip_fraction        | 0.0639      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.551      |\n",
            "|    explained_variance   | 0.964       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.08        |\n",
            "|    n_updates            | 4460        |\n",
            "|    policy_gradient_loss | -0.000546   |\n",
            "|    value_loss           | 8.69        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 566      |\n",
            "|    ep_rew_mean     | 143      |\n",
            "| time/              |          |\n",
            "|    fps             | 278      |\n",
            "|    iterations      | 447      |\n",
            "|    time_elapsed    | 3285     |\n",
            "|    total_timesteps | 915456   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 566         |\n",
            "|    ep_rew_mean          | 143         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 279         |\n",
            "|    iterations           | 448         |\n",
            "|    time_elapsed         | 3286        |\n",
            "|    total_timesteps      | 917504      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021945115 |\n",
            "|    clip_fraction        | 0.0691      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.484      |\n",
            "|    explained_variance   | 0.73        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 40.6        |\n",
            "|    n_updates            | 4470        |\n",
            "|    policy_gradient_loss | -0.00379    |\n",
            "|    value_loss           | 110         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 556          |\n",
            "|    ep_rew_mean          | 142          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 279          |\n",
            "|    iterations           | 449          |\n",
            "|    time_elapsed         | 3287         |\n",
            "|    total_timesteps      | 919552       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057460284 |\n",
            "|    clip_fraction        | 0.078        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.536       |\n",
            "|    explained_variance   | 0.808        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.63         |\n",
            "|    n_updates            | 4480         |\n",
            "|    policy_gradient_loss | -0.00178     |\n",
            "|    value_loss           | 39.6         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=920000, episode_reward=136.40 +/- 106.09\n",
            "Episode length: 476.86 +/- 172.99\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 477          |\n",
            "|    mean_reward          | 136          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 920000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027558578 |\n",
            "|    clip_fraction        | 0.0489       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.586       |\n",
            "|    explained_variance   | 0.862        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.98         |\n",
            "|    n_updates            | 4490         |\n",
            "|    policy_gradient_loss | 0.000675     |\n",
            "|    value_loss           | 39.4         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 558      |\n",
            "|    ep_rew_mean     | 143      |\n",
            "| time/              |          |\n",
            "|    fps             | 279      |\n",
            "|    iterations      | 450      |\n",
            "|    time_elapsed    | 3298     |\n",
            "|    total_timesteps | 921600   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 562          |\n",
            "|    ep_rew_mean          | 142          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 279          |\n",
            "|    iterations           | 451          |\n",
            "|    time_elapsed         | 3300         |\n",
            "|    total_timesteps      | 923648       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033596205 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.504       |\n",
            "|    explained_variance   | 0.801        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.8         |\n",
            "|    n_updates            | 4500         |\n",
            "|    policy_gradient_loss | -0.00168     |\n",
            "|    value_loss           | 53.1         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=925000, episode_reward=130.29 +/- 108.31\n",
            "Episode length: 455.78 +/- 157.45\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 456          |\n",
            "|    mean_reward          | 130          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 925000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055446317 |\n",
            "|    clip_fraction        | 0.101        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.613       |\n",
            "|    explained_variance   | 0.897        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 22.5         |\n",
            "|    n_updates            | 4510         |\n",
            "|    policy_gradient_loss | -0.00484     |\n",
            "|    value_loss           | 48.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 570      |\n",
            "|    ep_rew_mean     | 139      |\n",
            "| time/              |          |\n",
            "|    fps             | 279      |\n",
            "|    iterations      | 452      |\n",
            "|    time_elapsed    | 3310     |\n",
            "|    total_timesteps | 925696   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 567          |\n",
            "|    ep_rew_mean          | 134          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 280          |\n",
            "|    iterations           | 453          |\n",
            "|    time_elapsed         | 3311         |\n",
            "|    total_timesteps      | 927744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017580601 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.489       |\n",
            "|    explained_variance   | 0.293        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.23         |\n",
            "|    n_updates            | 4520         |\n",
            "|    policy_gradient_loss | -0.00405     |\n",
            "|    value_loss           | 157          |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 564         |\n",
            "|    ep_rew_mean          | 135         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 280         |\n",
            "|    iterations           | 454         |\n",
            "|    time_elapsed         | 3312        |\n",
            "|    total_timesteps      | 929792      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002841732 |\n",
            "|    clip_fraction        | 0.0245      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.497      |\n",
            "|    explained_variance   | 0.784       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 15          |\n",
            "|    n_updates            | 4530        |\n",
            "|    policy_gradient_loss | -0.00138    |\n",
            "|    value_loss           | 98.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=930000, episode_reward=166.85 +/- 76.83\n",
            "Episode length: 472.40 +/- 142.18\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 472          |\n",
            "|    mean_reward          | 167          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 930000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054118237 |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.513       |\n",
            "|    explained_variance   | 0.63         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.8         |\n",
            "|    n_updates            | 4540         |\n",
            "|    policy_gradient_loss | -0.00221     |\n",
            "|    value_loss           | 199          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 552      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 280      |\n",
            "|    iterations      | 455      |\n",
            "|    time_elapsed    | 3323     |\n",
            "|    total_timesteps | 931840   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 541          |\n",
            "|    ep_rew_mean          | 138          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 280          |\n",
            "|    iterations           | 456          |\n",
            "|    time_elapsed         | 3325         |\n",
            "|    total_timesteps      | 933888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024283053 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.523       |\n",
            "|    explained_variance   | 0.808        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 13.2         |\n",
            "|    n_updates            | 4550         |\n",
            "|    policy_gradient_loss | -0.000415    |\n",
            "|    value_loss           | 88.4         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=935000, episode_reward=121.42 +/- 108.55\n",
            "Episode length: 511.86 +/- 192.73\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 512         |\n",
            "|    mean_reward          | 121         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 935000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005779178 |\n",
            "|    clip_fraction        | 0.0506      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.562      |\n",
            "|    explained_variance   | 0.815       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37          |\n",
            "|    n_updates            | 4560        |\n",
            "|    policy_gradient_loss | -0.00121    |\n",
            "|    value_loss           | 106         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 539      |\n",
            "|    ep_rew_mean     | 136      |\n",
            "| time/              |          |\n",
            "|    fps             | 280      |\n",
            "|    iterations      | 457      |\n",
            "|    time_elapsed    | 3338     |\n",
            "|    total_timesteps | 935936   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 540         |\n",
            "|    ep_rew_mean          | 137         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 280         |\n",
            "|    iterations           | 458         |\n",
            "|    time_elapsed         | 3339        |\n",
            "|    total_timesteps      | 937984      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006364221 |\n",
            "|    clip_fraction        | 0.0917      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.544      |\n",
            "|    explained_variance   | 0.855       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 16.5        |\n",
            "|    n_updates            | 4570        |\n",
            "|    policy_gradient_loss | -0.00209    |\n",
            "|    value_loss           | 41          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=940000, episode_reward=122.14 +/- 106.33\n",
            "Episode length: 465.08 +/- 145.84\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 465         |\n",
            "|    mean_reward          | 122         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 940000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004078185 |\n",
            "|    clip_fraction        | 0.0982      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.558      |\n",
            "|    explained_variance   | 0.774       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.37        |\n",
            "|    n_updates            | 4580        |\n",
            "|    policy_gradient_loss | 0.000323    |\n",
            "|    value_loss           | 24.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 534      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 280      |\n",
            "|    iterations      | 459      |\n",
            "|    time_elapsed    | 3350     |\n",
            "|    total_timesteps | 940032   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 537          |\n",
            "|    ep_rew_mean          | 146          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 281          |\n",
            "|    iterations           | 460          |\n",
            "|    time_elapsed         | 3352         |\n",
            "|    total_timesteps      | 942080       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033642012 |\n",
            "|    clip_fraction        | 0.0437       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.502       |\n",
            "|    explained_variance   | 0.844        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17.7         |\n",
            "|    n_updates            | 4590         |\n",
            "|    policy_gradient_loss | -0.000922    |\n",
            "|    value_loss           | 33.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 545          |\n",
            "|    ep_rew_mean          | 144          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 281          |\n",
            "|    iterations           | 461          |\n",
            "|    time_elapsed         | 3353         |\n",
            "|    total_timesteps      | 944128       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035975277 |\n",
            "|    clip_fraction        | 0.0516       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.45        |\n",
            "|    explained_variance   | 0.832        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 17.5         |\n",
            "|    n_updates            | 4600         |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    value_loss           | 34.2         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=945000, episode_reward=122.04 +/- 103.39\n",
            "Episode length: 507.10 +/- 213.51\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 507          |\n",
            "|    mean_reward          | 122          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 945000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026116343 |\n",
            "|    clip_fraction        | 0.0444       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.419       |\n",
            "|    explained_variance   | 0.848        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 27.3         |\n",
            "|    n_updates            | 4610         |\n",
            "|    policy_gradient_loss | -0.00116     |\n",
            "|    value_loss           | 46           |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 540      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 281      |\n",
            "|    iterations      | 462      |\n",
            "|    time_elapsed    | 3365     |\n",
            "|    total_timesteps | 946176   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 541          |\n",
            "|    ep_rew_mean          | 140          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 281          |\n",
            "|    iterations           | 463          |\n",
            "|    time_elapsed         | 3367         |\n",
            "|    total_timesteps      | 948224       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059812265 |\n",
            "|    clip_fraction        | 0.0592       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.485       |\n",
            "|    explained_variance   | 0.755        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.68         |\n",
            "|    n_updates            | 4620         |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    value_loss           | 90           |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=950000, episode_reward=131.84 +/- 113.76\n",
            "Episode length: 475.38 +/- 138.81\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 475          |\n",
            "|    mean_reward          | 132          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 950000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039049522 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.513       |\n",
            "|    explained_variance   | 0.81         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 3.58         |\n",
            "|    n_updates            | 4630         |\n",
            "|    policy_gradient_loss | -0.000852    |\n",
            "|    value_loss           | 40.3         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 557      |\n",
            "|    ep_rew_mean     | 140      |\n",
            "| time/              |          |\n",
            "|    fps             | 281      |\n",
            "|    iterations      | 464      |\n",
            "|    time_elapsed    | 3378     |\n",
            "|    total_timesteps | 950272   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 539         |\n",
            "|    ep_rew_mean          | 145         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 281         |\n",
            "|    iterations           | 465         |\n",
            "|    time_elapsed         | 3380        |\n",
            "|    total_timesteps      | 952320      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018753575 |\n",
            "|    clip_fraction        | 0.0559      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.416      |\n",
            "|    explained_variance   | 0.864       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.15        |\n",
            "|    n_updates            | 4640        |\n",
            "|    policy_gradient_loss | -0.000471   |\n",
            "|    value_loss           | 24.2        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 537         |\n",
            "|    ep_rew_mean          | 140         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 282         |\n",
            "|    iterations           | 466         |\n",
            "|    time_elapsed         | 3381        |\n",
            "|    total_timesteps      | 954368      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004042741 |\n",
            "|    clip_fraction        | 0.0372      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.496      |\n",
            "|    explained_variance   | 0.752       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 167         |\n",
            "|    n_updates            | 4650        |\n",
            "|    policy_gradient_loss | -0.0018     |\n",
            "|    value_loss           | 105         |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=955000, episode_reward=135.29 +/- 97.76\n",
            "Episode length: 469.30 +/- 141.52\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 469         |\n",
            "|    mean_reward          | 135         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 955000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005146065 |\n",
            "|    clip_fraction        | 0.0482      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.505      |\n",
            "|    explained_variance   | 0.687       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 78.9        |\n",
            "|    n_updates            | 4660        |\n",
            "|    policy_gradient_loss | -0.00132    |\n",
            "|    value_loss           | 164         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 538      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 281      |\n",
            "|    iterations      | 467      |\n",
            "|    time_elapsed    | 3392     |\n",
            "|    total_timesteps | 956416   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 550         |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 282         |\n",
            "|    iterations           | 468         |\n",
            "|    time_elapsed         | 3394        |\n",
            "|    total_timesteps      | 958464      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002454901 |\n",
            "|    clip_fraction        | 0.0248      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.448      |\n",
            "|    explained_variance   | 0.633       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 37          |\n",
            "|    n_updates            | 4670        |\n",
            "|    policy_gradient_loss | -0.00105    |\n",
            "|    value_loss           | 96.1        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=960000, episode_reward=124.98 +/- 110.36\n",
            "Episode length: 498.40 +/- 191.45\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 498          |\n",
            "|    mean_reward          | 125          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 960000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0049129715 |\n",
            "|    clip_fraction        | 0.0947       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.455       |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.68         |\n",
            "|    n_updates            | 4680         |\n",
            "|    policy_gradient_loss | 0.000328     |\n",
            "|    value_loss           | 51.9         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 555      |\n",
            "|    ep_rew_mean     | 133      |\n",
            "| time/              |          |\n",
            "|    fps             | 281      |\n",
            "|    iterations      | 469      |\n",
            "|    time_elapsed    | 3406     |\n",
            "|    total_timesteps | 960512   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 554          |\n",
            "|    ep_rew_mean          | 136          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 282          |\n",
            "|    iterations           | 470          |\n",
            "|    time_elapsed         | 3407         |\n",
            "|    total_timesteps      | 962560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070082666 |\n",
            "|    clip_fraction        | 0.0602       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.526       |\n",
            "|    explained_variance   | 0.748        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.01         |\n",
            "|    n_updates            | 4690         |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    value_loss           | 17.5         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 545         |\n",
            "|    ep_rew_mean          | 135         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 282         |\n",
            "|    iterations           | 471         |\n",
            "|    time_elapsed         | 3408        |\n",
            "|    total_timesteps      | 964608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006560647 |\n",
            "|    clip_fraction        | 0.0687      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.503      |\n",
            "|    explained_variance   | 0.739       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.78        |\n",
            "|    n_updates            | 4700        |\n",
            "|    policy_gradient_loss | -0.00145    |\n",
            "|    value_loss           | 32          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=965000, episode_reward=154.92 +/- 94.55\n",
            "Episode length: 482.60 +/- 160.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 483         |\n",
            "|    mean_reward          | 155         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 965000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009032013 |\n",
            "|    clip_fraction        | 0.0993      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.44       |\n",
            "|    explained_variance   | 0.648       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 33.8        |\n",
            "|    n_updates            | 4710        |\n",
            "|    policy_gradient_loss | -0.00218    |\n",
            "|    value_loss           | 104         |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 559      |\n",
            "|    ep_rew_mean     | 133      |\n",
            "| time/              |          |\n",
            "|    fps             | 282      |\n",
            "|    iterations      | 472      |\n",
            "|    time_elapsed    | 3420     |\n",
            "|    total_timesteps | 966656   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 560          |\n",
            "|    ep_rew_mean          | 130          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 283          |\n",
            "|    iterations           | 473          |\n",
            "|    time_elapsed         | 3422         |\n",
            "|    total_timesteps      | 968704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044070687 |\n",
            "|    clip_fraction        | 0.0926       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.539       |\n",
            "|    explained_variance   | 0.904        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2          |\n",
            "|    n_updates            | 4720         |\n",
            "|    policy_gradient_loss | -0.000146    |\n",
            "|    value_loss           | 9.89         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=970000, episode_reward=147.72 +/- 100.12\n",
            "Episode length: 469.08 +/- 187.70\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 469         |\n",
            "|    mean_reward          | 148         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 970000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009909008 |\n",
            "|    clip_fraction        | 0.106       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.499      |\n",
            "|    explained_variance   | 0.808       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.49        |\n",
            "|    n_updates            | 4730        |\n",
            "|    policy_gradient_loss | -0.00265    |\n",
            "|    value_loss           | 65.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 560      |\n",
            "|    ep_rew_mean     | 134      |\n",
            "| time/              |          |\n",
            "|    fps             | 282      |\n",
            "|    iterations      | 474      |\n",
            "|    time_elapsed    | 3434     |\n",
            "|    total_timesteps | 970752   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 565         |\n",
            "|    ep_rew_mean          | 134         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 475         |\n",
            "|    time_elapsed         | 3436        |\n",
            "|    total_timesteps      | 972800      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002312357 |\n",
            "|    clip_fraction        | 0.0339      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.472      |\n",
            "|    explained_variance   | 0.844       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 25          |\n",
            "|    n_updates            | 4740        |\n",
            "|    policy_gradient_loss | -0.0011     |\n",
            "|    value_loss           | 27.7        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 573         |\n",
            "|    ep_rew_mean          | 133         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 476         |\n",
            "|    time_elapsed         | 3437        |\n",
            "|    total_timesteps      | 974848      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004884462 |\n",
            "|    clip_fraction        | 0.0465      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.474      |\n",
            "|    explained_variance   | 0.816       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.6        |\n",
            "|    n_updates            | 4750        |\n",
            "|    policy_gradient_loss | -0.000838   |\n",
            "|    value_loss           | 25          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=975000, episode_reward=147.16 +/- 105.72\n",
            "Episode length: 475.86 +/- 173.47\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 476          |\n",
            "|    mean_reward          | 147          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 975000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070897215 |\n",
            "|    clip_fraction        | 0.0797       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.476       |\n",
            "|    explained_variance   | 0.877        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 2.27         |\n",
            "|    n_updates            | 4760         |\n",
            "|    policy_gradient_loss | -0.000567    |\n",
            "|    value_loss           | 15.5         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 574      |\n",
            "|    ep_rew_mean     | 138      |\n",
            "| time/              |          |\n",
            "|    fps             | 283      |\n",
            "|    iterations      | 477      |\n",
            "|    time_elapsed    | 3448     |\n",
            "|    total_timesteps | 976896   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 580         |\n",
            "|    ep_rew_mean          | 138         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 283         |\n",
            "|    iterations           | 478         |\n",
            "|    time_elapsed         | 3450        |\n",
            "|    total_timesteps      | 978944      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005967048 |\n",
            "|    clip_fraction        | 0.0513      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.492      |\n",
            "|    explained_variance   | 0.881       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.87        |\n",
            "|    n_updates            | 4770        |\n",
            "|    policy_gradient_loss | -0.00105    |\n",
            "|    value_loss           | 26.4        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=980000, episode_reward=166.14 +/- 104.65\n",
            "Episode length: 444.72 +/- 125.20\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 445         |\n",
            "|    mean_reward          | 166         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 980000      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011863565 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.574      |\n",
            "|    explained_variance   | 0.837       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.43        |\n",
            "|    n_updates            | 4780        |\n",
            "|    policy_gradient_loss | 0.00216     |\n",
            "|    value_loss           | 8.84        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 580      |\n",
            "|    ep_rew_mean     | 139      |\n",
            "| time/              |          |\n",
            "|    fps             | 283      |\n",
            "|    iterations      | 479      |\n",
            "|    time_elapsed    | 3460     |\n",
            "|    total_timesteps | 980992   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 575          |\n",
            "|    ep_rew_mean          | 144          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 283          |\n",
            "|    iterations           | 480          |\n",
            "|    time_elapsed         | 3462         |\n",
            "|    total_timesteps      | 983040       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037857164 |\n",
            "|    clip_fraction        | 0.0528       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.473       |\n",
            "|    explained_variance   | 0.85         |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 24           |\n",
            "|    n_updates            | 4790         |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    value_loss           | 34.9         |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=985000, episode_reward=150.82 +/- 109.11\n",
            "Episode length: 463.70 +/- 165.46\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 464          |\n",
            "|    mean_reward          | 151          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 985000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050930902 |\n",
            "|    clip_fraction        | 0.0435       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.495       |\n",
            "|    explained_variance   | 0.867        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.53         |\n",
            "|    n_updates            | 4800         |\n",
            "|    policy_gradient_loss | -0.00407     |\n",
            "|    value_loss           | 34.3         |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 577      |\n",
            "|    ep_rew_mean     | 154      |\n",
            "| time/              |          |\n",
            "|    fps             | 283      |\n",
            "|    iterations      | 481      |\n",
            "|    time_elapsed    | 3472     |\n",
            "|    total_timesteps | 985088   |\n",
            "---------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 582        |\n",
            "|    ep_rew_mean          | 157        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 284        |\n",
            "|    iterations           | 482        |\n",
            "|    time_elapsed         | 3474       |\n",
            "|    total_timesteps      | 987136     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00329812 |\n",
            "|    clip_fraction        | 0.0461     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.455     |\n",
            "|    explained_variance   | 0.888      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.96       |\n",
            "|    n_updates            | 4810       |\n",
            "|    policy_gradient_loss | -0.00321   |\n",
            "|    value_loss           | 28.3       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 582         |\n",
            "|    ep_rew_mean          | 151         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 284         |\n",
            "|    iterations           | 483         |\n",
            "|    time_elapsed         | 3475        |\n",
            "|    total_timesteps      | 989184      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008892249 |\n",
            "|    clip_fraction        | 0.0794      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.502      |\n",
            "|    explained_variance   | 0.739       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 33.5        |\n",
            "|    n_updates            | 4820        |\n",
            "|    policy_gradient_loss | -0.00482    |\n",
            "|    value_loss           | 64.8        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=990000, episode_reward=154.57 +/- 95.78\n",
            "Episode length: 520.44 +/- 200.23\n",
            "------------------------------------------\n",
            "| eval/                   |              |\n",
            "|    mean_ep_length       | 520          |\n",
            "|    mean_reward          | 155          |\n",
            "| time/                   |              |\n",
            "|    total_timesteps      | 990000       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021562257 |\n",
            "|    clip_fraction        | 0.0308       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.44        |\n",
            "|    explained_variance   | 0.644        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 43.5         |\n",
            "|    n_updates            | 4830         |\n",
            "|    policy_gradient_loss | -0.000596    |\n",
            "|    value_loss           | 152          |\n",
            "------------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 585      |\n",
            "|    ep_rew_mean     | 145      |\n",
            "| time/              |          |\n",
            "|    fps             | 284      |\n",
            "|    iterations      | 484      |\n",
            "|    time_elapsed    | 3488     |\n",
            "|    total_timesteps | 991232   |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 593         |\n",
            "|    ep_rew_mean          | 148         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 284         |\n",
            "|    iterations           | 485         |\n",
            "|    time_elapsed         | 3490        |\n",
            "|    total_timesteps      | 993280      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005531282 |\n",
            "|    clip_fraction        | 0.0421      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.323      |\n",
            "|    explained_variance   | 0.833       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.13        |\n",
            "|    n_updates            | 4840        |\n",
            "|    policy_gradient_loss | -0.000659   |\n",
            "|    value_loss           | 44          |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=995000, episode_reward=170.98 +/- 87.31\n",
            "Episode length: 488.36 +/- 150.44\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 488        |\n",
            "|    mean_reward          | 171        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 995000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01075518 |\n",
            "|    clip_fraction        | 0.0851     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.524     |\n",
            "|    explained_variance   | 0.58       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.13       |\n",
            "|    n_updates            | 4850       |\n",
            "|    policy_gradient_loss | -0.00106   |\n",
            "|    value_loss           | 41.1       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 586      |\n",
            "|    ep_rew_mean     | 150      |\n",
            "| time/              |          |\n",
            "|    fps             | 284      |\n",
            "|    iterations      | 486      |\n",
            "|    time_elapsed    | 3503     |\n",
            "|    total_timesteps | 995328   |\n",
            "---------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 586          |\n",
            "|    ep_rew_mean          | 153          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 284          |\n",
            "|    iterations           | 487          |\n",
            "|    time_elapsed         | 3504         |\n",
            "|    total_timesteps      | 997376       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060831206 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.444       |\n",
            "|    explained_variance   | 0.583        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.58         |\n",
            "|    n_updates            | 4860         |\n",
            "|    policy_gradient_loss | -0.000442    |\n",
            "|    value_loss           | 46.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 589          |\n",
            "|    ep_rew_mean          | 153          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 285          |\n",
            "|    iterations           | 488          |\n",
            "|    time_elapsed         | 3506         |\n",
            "|    total_timesteps      | 999424       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030663195 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.392       |\n",
            "|    explained_variance   | 0.543        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 19.6         |\n",
            "|    n_updates            | 4870         |\n",
            "|    policy_gradient_loss | -0.00198     |\n",
            "|    value_loss           | 106          |\n",
            "------------------------------------------\n",
            "Eval num_timesteps=1000000, episode_reward=155.19 +/- 102.16\n",
            "Episode length: 499.38 +/- 143.81\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 499         |\n",
            "|    mean_reward          | 155         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 1000000     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010482125 |\n",
            "|    clip_fraction        | 0.0647      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.469      |\n",
            "|    explained_variance   | 0.915       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.73        |\n",
            "|    n_updates            | 4880        |\n",
            "|    policy_gradient_loss | -0.000653   |\n",
            "|    value_loss           | 16.2        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 593      |\n",
            "|    ep_rew_mean     | 149      |\n",
            "| time/              |          |\n",
            "|    fps             | 284      |\n",
            "|    iterations      | 489      |\n",
            "|    time_elapsed    | 3518     |\n",
            "|    total_timesteps | 1001472  |\n",
            "---------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x79e20e4a7890>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train model on the environment\n",
        "TRAINING_TIMESTEPS = 1_000_000\n",
        "model.learn(total_timesteps=TRAINING_TIMESTEPS, callback=[eval_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6bSCsyCOYbVW",
        "outputId": "ee81a478-36d3-4245-8d0d-058e6e0a4693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode finished after 602 steps (terminated)\n",
            "Final Step: 602\n",
            "Number of Frames: 602\n"
          ]
        }
      ],
      "source": [
        "MAX_STEPS = 1_000\n",
        "\n",
        "observation, info = env.reset(seed=42)\n",
        "frames = []\n",
        "step_count = 0\n",
        "\n",
        "# for step in range(MAX_STEPS):\n",
        "while True:\n",
        "    frame = env.render()\n",
        "    frames.append(frame)\n",
        "\n",
        "    action, _ = model.predict(observation, deterministic=True)\n",
        "    observation, reward, terminated, truncated, info = env.step(action)\n",
        "    step_count += 1\n",
        "\n",
        "    if terminated or truncated:\n",
        "        print(f\"Episode finished after {step_count} steps ({\"truncated\" if truncated else \"terminated\"})\")\n",
        "        break\n",
        "\n",
        "env.close()\n",
        "\n",
        "print(f\"Final Step: {step_count}\")\n",
        "print(f\"Number of Frames: {len(frames)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "SAvZXQ3UKiF8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video guardado como ../videos/lunarlander_ppo.mp4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "rm: cannot remove '../videos/lunarlander_ppo_compressed.mp4': No such file or directory\n",
            "ffmpeg version n7.1 Copyright (c) 2000-2024 the FFmpeg developers\n",
            "  built with gcc 14.2.1 (GCC) 20250207\n",
            "  configuration: --prefix=/usr --disable-debug --disable-static --disable-stripping --enable-amf --enable-avisynth --enable-cuda-llvm --enable-lto --enable-fontconfig --enable-frei0r --enable-gmp --enable-gnutls --enable-gpl --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libdav1d --enable-libdrm --enable-libdvdnav --enable-libdvdread --enable-libfreetype --enable-libfribidi --enable-libglslang --enable-libgsm --enable-libharfbuzz --enable-libiec61883 --enable-libjack --enable-libjxl --enable-libmodplug --enable-libmp3lame --enable-libopencore_amrnb --enable-libopencore_amrwb --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libplacebo --enable-libpulse --enable-librav1e --enable-librsvg --enable-librubberband --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libsvtav1 --enable-libtheora --enable-libv4l2 --enable-libvidstab --enable-libvmaf --enable-libvorbis --enable-libvpl --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxcb --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-nvdec --enable-nvenc --enable-opencl --enable-opengl --enable-shared --enable-vapoursynth --enable-version3 --enable-vulkan\n",
            "  libavutil      59. 39.100 / 59. 39.100\n",
            "  libavcodec     61. 19.100 / 61. 19.100\n",
            "  libavformat    61.  7.100 / 61.  7.100\n",
            "  libavdevice    61.  3.100 / 61.  3.100\n",
            "  libavfilter    10.  4.100 / 10.  4.100\n",
            "  libswscale      8.  3.100 /  8.  3.100\n",
            "  libswresample   5.  3.100 /  5.  3.100\n",
            "  libpostproc    58.  3.100 / 58.  3.100\n",
            "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from '../videos/lunarlander_ppo.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf59.27.100\n",
            "  Duration: 00:00:20.07, start: 0.000000, bitrate: 354 kb/s\n",
            "  Stream #0:0[0x1](und): Video: mpeg4 (Simple Profile) (mp4v / 0x7634706D), yuv420p, 600x400 [SAR 1:1 DAR 3:2], 353 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
            "      Metadata:\n",
            "        handler_name    : VideoHandler\n",
            "        vendor_id       : [0][0][0][0]\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mpeg4 (native) -> h264 (libx264))\n",
            "Press [q] to stop, [?] for help\n",
            "[libx264 @ 0x593a4eebbc00] using SAR=1/1\n",
            "[libx264 @ 0x593a4eebbc00] using cpu capabilities: MMX2 SSE2Fast SSSE3 SSE4.2 AVX FMA3 BMI2 AVX2\n",
            "[libx264 @ 0x593a4eebbc00] profile High, level 3.0, 4:2:0, 8-bit\n",
            "[libx264 @ 0x593a4eebbc00] 264 - core 164 r3108 31e19f9 - H.264/MPEG-4 AVC codec - Copyleft 2003-2023 - http://www.videolan.org/x264.html - options: cabac=1 ref=3 deblock=1:0:0 analyse=0x3:0x113 me=hex subme=7 psy=1 psy_rd=1.00:0.00 mixed_ref=1 me_range=16 chroma_me=1 trellis=1 8x8dct=1 cqm=0 deadzone=21,11 fast_pskip=1 chroma_qp_offset=-2 threads=12 lookahead_threads=2 sliced_threads=0 nr=0 decimate=1 interlaced=0 bluray_compat=0 constrained_intra=0 bframes=3 b_pyramid=2 b_adapt=1 b_bias=0 direct=1 weightb=1 open_gop=0 weightp=2 keyint=250 keyint_min=25 scenecut=40 intra_refresh=0 rc_lookahead=40 rc=crf mbtree=1 crf=23.0 qcomp=0.60 qpmin=0 qpmax=69 qpstep=4 ip_ratio=1.40 aq=1:1.00\n",
            "Output #0, mp4, to '../videos/lunarlander_ppo_compressed.mp4':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2mp41\n",
            "    encoder         : Lavf61.7.100\n",
            "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(tv, progressive), 600x400 [SAR 1:1 DAR 3:2], q=2-31, 30 fps, 15360 tbn (default)\n",
            "      Metadata:\n",
            "        handler_name    : VideoHandler\n",
            "        vendor_id       : [0][0][0][0]\n",
            "        encoder         : Lavc61.19.100 libx264\n",
            "      Side data:\n",
            "        cpb: bitrate max/min/avg: 0/0/0 buffer size: 0 vbv_delay: N/A\n",
            "[out#0/mp4 @ 0x593a4eede940] video:125KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 6.274203%\n",
            "frame=  602 fps=0.0 q=-1.0 Lsize=     133KiB time=00:00:20.00 bitrate=  54.3kbits/s speed=85.2x    \n",
            "[libx264 @ 0x593a4eebbc00] frame I:3     Avg QP: 7.20  size:  2406\n",
            "[libx264 @ 0x593a4eebbc00] frame P:154   Avg QP:17.41  size:   309\n",
            "[libx264 @ 0x593a4eebbc00] frame B:445   Avg QP:21.06  size:   163\n",
            "[libx264 @ 0x593a4eebbc00] consecutive B-frames:  0.7%  0.7%  5.0% 93.7%\n",
            "[libx264 @ 0x593a4eebbc00] mb I  I16..4: 91.3%  2.9%  5.8%\n",
            "[libx264 @ 0x593a4eebbc00] mb P  I16..4:  0.3%  0.5%  0.2%  P16..4:  1.5%  0.5%  0.2%  0.0%  0.0%    skip:96.7%\n",
            "[libx264 @ 0x593a4eebbc00] mb B  I16..4:  0.1%  0.1%  0.1%  B16..8:  2.7%  0.3%  0.1%  direct: 0.1%  skip:96.5%  L0:55.8% L1:42.4% BI: 1.7%\n",
            "[libx264 @ 0x593a4eebbc00] 8x8 transform intra:22.8% inter:18.2%\n",
            "[libx264 @ 0x593a4eebbc00] coded y,uvDC,uvAC intra: 8.4% 18.8% 16.0% inter: 0.3% 0.5% 0.4%\n",
            "[libx264 @ 0x593a4eebbc00] i16 v,h,dc,p: 85% 10%  5%  0%\n",
            "[libx264 @ 0x593a4eebbc00] i8 v,h,dc,ddl,ddr,vr,hd,vl,hu:  7%  6% 86%  0%  0%  0%  0%  0%  0%\n",
            "[libx264 @ 0x593a4eebbc00] i4 v,h,dc,ddl,ddr,vr,hd,vl,hu: 13% 13% 62%  2%  2%  2%  3%  1%  1%\n",
            "[libx264 @ 0x593a4eebbc00] i8c dc,h,v,p: 83% 10%  7%  0%\n",
            "[libx264 @ 0x593a4eebbc00] Weighted P-Frames: Y:0.0% UV:0.0%\n",
            "[libx264 @ 0x593a4eebbc00] ref P L0: 56.6%  2.4% 24.8% 16.3%\n",
            "[libx264 @ 0x593a4eebbc00] ref B L0: 67.2% 27.8%  5.0%\n",
            "[libx264 @ 0x593a4eebbc00] ref B L1: 91.2%  8.8%\n",
            "[libx264 @ 0x593a4eebbc00] kb/s:50.69\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<video width=800 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "import os\n",
        "\n",
        "# Create a video from the frames\n",
        "video_filename = \"../videos/lunarlander_ppo.mp4\"\n",
        "compressed_path = \"../videos/lunarlander_ppo_compressed.mp4\"\n",
        "height, width, _ = frames[0].shape\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "video = cv2.VideoWriter(video_filename, fourcc, 30.0, (width, height))\n",
        "\n",
        "for frame in frames:\n",
        "    video.write(\n",
        "        cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
        "    )\n",
        "video.release()\n",
        "\n",
        "print(f\"Video guardado como {video_filename}\")\n",
        "\n",
        "os.system(f\"rm {compressed_path}\")\n",
        "# Compressed video path\n",
        "os.system(f\"ffmpeg -i {video_filename} -vcodec libx264 {compressed_path}\")\n",
        "os.system(f\"rm {video_filename}\")\n",
        "os.system(f\"mv {compressed_path} {video_filename}\")\n",
        "\n",
        "# Show video\n",
        "mp4 = open(video_filename, \"rb\").read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\n",
        "    \"\"\"\n",
        "<video width=800 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\"\"\"\n",
        "    % data_url\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deep-reinforcement-learning-gymnasium-u3px5S1O-py3.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
